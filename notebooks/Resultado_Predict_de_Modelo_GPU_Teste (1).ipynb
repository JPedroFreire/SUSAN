{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O5MU04ou6jyp",
        "outputId": "503eec8f-7ab8-4f7f-efae-080ffd0aec64"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.2.2-py3-none-any.whl (750 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m750.8/750.8 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.8.0.76)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.1)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.31.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.11.4)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.2.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.17.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Collecting thop>=0.1.1 (from ultralytics)\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.0.3)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.2.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.13.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, thop, ultralytics\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 thop-0.1.1.post2209072238 ultralytics-8.2.2\n"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Y4x43LdjAkj",
        "outputId": "903f99f5-9910-4911-b00d-df9322b4dcb7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vn2FUF0mdhMW"
      },
      "outputs": [],
      "source": [
        "from distutils.dir_util import copy_tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c33NI4XHdksF",
        "outputId": "9dcb5ac9-b682-44cc-cdff-2c360d81fd24"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['/content/Dataset_Violence_Video/readme.md',\n",
              " '/content/Dataset_Violence_Video/.gitignore',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/action-class-occurrences.csv',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent-action-classes.csv',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/nonviolent-action-classes.csv',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam1/25.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam1/7.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam1/113.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam1/104.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam1/61.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam1/63.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam1/16.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam1/13.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam1/32.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam1/65.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam1/52.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam1/1.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam1/75.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam1/67.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam1/115.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam1/21.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam1/15.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam1/30.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam1/70.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam1/48.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam1/33.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam1/29.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam1/34.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam1/12.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam1/28.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam1/105.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam1/51.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam1/40.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam1/79.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam1/20.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam1/47.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam1/36.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam1/4.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam1/45.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam1/100.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam1/74.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam1/54.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam1/38.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam1/66.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam1/26.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam1/60.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam1/3.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam1/59.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam1/107.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam1/69.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam1/37.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam1/27.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam1/102.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam1/2.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam1/39.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam1/68.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam1/111.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam1/31.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam1/49.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam1/23.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam1/55.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam1/101.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam1/19.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam1/58.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam1/41.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam1/6.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam1/11.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam1/57.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam1/10.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam1/106.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam1/22.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam1/44.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam1/42.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam1/5.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam1/112.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam1/24.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam1/56.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam1/64.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam1/108.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam1/43.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam1/103.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam1/53.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam1/78.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam1/18.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam1/76.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam1/73.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam1/114.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam1/77.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam1/17.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam1/62.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam1/109.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam1/50.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam1/72.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam1/46.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam1/35.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam1/110.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam1/71.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam1/14.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam1/93.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam1/81.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam1/83.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam1/87.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam1/8.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam1/97.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam1/99.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam1/86.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam1/9.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam1/89.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam1/88.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam1/92.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam1/80.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam1/98.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam1/90.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam1/95.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam1/96.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam1/85.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam1/94.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam1/91.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam1/84.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam1/82.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam2/32.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam2/17.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam2/28.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam2/6.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam2/62.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam2/113.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam2/18.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam2/30.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam2/1.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam2/65.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam2/41.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam2/87.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam2/89.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam2/105.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam2/13.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam2/111.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam2/49.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam2/47.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam2/3.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam2/4.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam2/75.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam2/2.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam2/44.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam2/101.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam2/50.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam2/42.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam2/24.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam2/14.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam2/38.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam2/26.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam2/100.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam2/109.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam2/46.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam2/86.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam2/107.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam2/72.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam2/5.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam2/79.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam2/21.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam2/36.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam2/108.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam2/91.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam2/58.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam2/9.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam2/31.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam2/112.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam2/71.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam2/74.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam2/110.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam2/85.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam2/82.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam2/23.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam2/8.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam2/39.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam2/43.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam2/84.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam2/27.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam2/103.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam2/77.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam2/106.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam2/45.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam2/35.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam2/70.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam2/7.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam2/12.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam2/11.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam2/68.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam2/15.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam2/80.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam2/78.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam2/51.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam2/67.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam2/59.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam2/61.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam2/60.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam2/56.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam2/76.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam2/20.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam2/64.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam2/34.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam2/54.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam2/90.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam2/33.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam2/66.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam2/29.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam2/37.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam2/63.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam2/40.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam2/22.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam2/73.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam2/104.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam2/102.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam2/115.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam2/25.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam2/53.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam2/92.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam2/88.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam2/10.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam2/83.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam2/81.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam2/114.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam2/16.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam2/19.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam2/48.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam2/57.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam2/69.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam2/52.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam2/55.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam2/98.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam2/95.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam2/93.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam2/99.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam2/96.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam2/97.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam2/94.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/non-violent/cam2/2.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/non-violent/cam2/23.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/non-violent/cam2/10.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/non-violent/cam2/14.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/non-violent/cam2/12.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/non-violent/cam2/13.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/non-violent/cam2/17.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/non-violent/cam2/19.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/non-violent/cam2/21.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/non-violent/cam2/18.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/non-violent/cam2/15.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/non-violent/cam2/11.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/non-violent/cam2/16.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/non-violent/cam2/1.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/non-violent/cam2/20.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/non-violent/cam2/22.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/non-violent/cam2/51.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/non-violent/cam2/31.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/non-violent/cam2/39.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/non-violent/cam2/41.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/non-violent/cam2/60.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/non-violent/cam2/34.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/non-violent/cam2/5.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/non-violent/cam2/3.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/non-violent/cam2/8.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/non-violent/cam2/40.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/non-violent/cam2/37.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/non-violent/cam2/33.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/non-violent/cam2/47.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/non-violent/cam2/44.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/non-violent/cam2/59.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/non-violent/cam2/57.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/non-violent/cam2/58.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/non-violent/cam2/36.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/non-violent/cam2/35.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/non-violent/cam2/53.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/non-violent/cam2/7.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/non-violent/cam2/48.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/non-violent/cam2/45.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/non-violent/cam2/28.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/non-violent/cam2/42.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/non-violent/cam2/9.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/non-violent/cam2/4.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/non-violent/cam2/25.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/non-violent/cam2/27.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/non-violent/cam2/30.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/non-violent/cam2/29.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/non-violent/cam2/24.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/non-violent/cam2/52.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/non-violent/cam2/26.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/non-violent/cam2/43.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/non-violent/cam2/54.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/non-violent/cam2/32.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/non-violent/cam2/6.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/non-violent/cam2/55.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/non-violent/cam2/50.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/non-violent/cam2/49.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/non-violent/cam2/46.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/non-violent/cam2/56.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/non-violent/cam2/38.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/non-violent/cam1/47.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/non-violent/cam1/12.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/non-violent/cam1/38.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/non-violent/cam1/28.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/non-violent/cam1/16.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/non-violent/cam1/29.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/non-violent/cam1/7.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/non-violent/cam1/23.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/non-violent/cam1/20.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/non-violent/cam1/56.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/non-violent/cam1/57.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/non-violent/cam1/30.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/non-violent/cam1/45.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/non-violent/cam1/17.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/non-violent/cam1/42.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/non-violent/cam1/32.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/non-violent/cam1/14.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/non-violent/cam1/40.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/non-violent/cam1/35.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/non-violent/cam1/11.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/non-violent/cam1/50.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/non-violent/cam1/1.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/non-violent/cam1/55.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/non-violent/cam1/15.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/non-violent/cam1/19.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/non-violent/cam1/46.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/non-violent/cam1/10.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/non-violent/cam1/34.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/non-violent/cam1/48.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/non-violent/cam1/59.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/non-violent/cam1/33.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/non-violent/cam1/13.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/non-violent/cam1/41.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/non-violent/cam1/60.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/non-violent/cam1/6.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/non-violent/cam1/22.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/non-violent/cam1/26.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/non-violent/cam1/44.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/non-violent/cam1/39.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/non-violent/cam1/25.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/non-violent/cam1/49.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/non-violent/cam1/21.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/non-violent/cam1/37.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/non-violent/cam1/51.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/non-violent/cam1/58.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/non-violent/cam1/9.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/non-violent/cam1/3.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/non-violent/cam1/43.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/non-violent/cam1/18.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/non-violent/cam1/2.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/non-violent/cam1/24.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/non-violent/cam1/54.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/non-violent/cam1/36.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/non-violent/cam1/53.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/non-violent/cam1/31.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/non-violent/cam1/8.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/non-violent/cam1/4.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/non-violent/cam1/27.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/non-violent/cam1/5.mp4',\n",
              " '/content/Dataset_Violence_Video/violence-detection-dataset/non-violent/cam1/52.mp4']"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "copy_tree('/content/drive/MyDrive/Dataset_Violence_Video/', '/content/Dataset_Violence_Video/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qEX13wN1kkNX"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "import os\n",
        "import math\n",
        "from ultralytics import YOLO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jNHZ9LbFtaJp",
        "outputId": "1dfacf73-3535-4d14-caa9-a20e085fdbc1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cam2: 98.mp4\n",
            "cam2: 79.mp4\n",
            "cam2: 34.mp4\n",
            "cam2: 102.mp4\n",
            "cam2: 85.mp4\n",
            "cam2: 23.mp4\n",
            "cam2: 87.mp4\n",
            "cam2: 9.mp4\n",
            "cam2: 83.mp4\n",
            "cam2: 108.mp4\n",
            "cam2: 12.mp4\n",
            "cam2: 66.mp4\n",
            "cam2: 99.mp4\n",
            "cam2: 8.mp4\n",
            "cam2: 105.mp4\n",
            "cam2: 104.mp4\n",
            "cam2: 68.mp4\n",
            "cam2: 57.mp4\n",
            "cam2: 10.mp4\n",
            "cam2: 107.mp4\n",
            "cam2: 45.mp4\n",
            "cam2: 6.mp4\n",
            "cam2: 54.mp4\n",
            "cam2: 86.mp4\n",
            "cam2: 109.mp4\n",
            "cam2: 31.mp4\n",
            "cam2: 33.mp4\n",
            "cam2: 22.mp4\n",
            "cam2: 46.mp4\n",
            "cam2: 106.mp4\n",
            "cam2: 29.mp4\n",
            "cam2: 30.mp4\n",
            "cam2: 71.mp4\n",
            "cam2: 24.mp4\n",
            "cam2: 18.mp4\n",
            "cam2: 55.mp4\n",
            "cam2: 97.mp4\n",
            "cam2: 81.mp4\n",
            "cam2: 72.mp4\n",
            "cam2: 17.mp4\n",
            "cam2: 76.mp4\n",
            "cam2: 88.mp4\n",
            "cam2: 35.mp4\n",
            "cam2: 78.mp4\n",
            "cam2: 89.mp4\n",
            "cam2: 84.mp4\n",
            "cam2: 25.mp4\n",
            "cam2: 61.mp4\n",
            "cam2: 69.mp4\n",
            "cam2: 5.mp4\n",
            "cam2: 56.mp4\n",
            "cam2: 111.mp4\n",
            "cam2: 2.mp4\n",
            "cam2: 32.mp4\n",
            "cam2: 59.mp4\n",
            "cam2: 70.mp4\n",
            "cam2: 4.mp4\n",
            "cam2: 40.mp4\n",
            "cam2: 47.mp4\n",
            "cam2: 62.mp4\n",
            "cam2: 75.mp4\n",
            "cam2: 95.mp4\n",
            "cam2: 20.mp4\n",
            "cam2: 74.mp4\n",
            "cam2: 7.mp4\n",
            "cam2: 101.mp4\n",
            "cam2: 73.mp4\n",
            "cam2: 60.mp4\n",
            "cam2: 43.mp4\n",
            "cam2: 112.mp4\n",
            "cam2: 13.mp4\n",
            "cam2: 16.mp4\n",
            "cam2: 65.mp4\n",
            "cam2: 58.mp4\n",
            "cam2: 11.mp4\n",
            "cam2: 94.mp4\n",
            "cam2: 103.mp4\n",
            "cam2: 67.mp4\n",
            "cam2: 41.mp4\n",
            "cam2: 90.mp4\n",
            "cam2: 14.mp4\n",
            "cam2: 3.mp4\n",
            "cam2: 110.mp4\n",
            "cam2: 64.mp4\n",
            "cam2: 42.mp4\n",
            "cam2: 51.mp4\n",
            "cam2: 93.mp4\n",
            "cam2: 44.mp4\n",
            "cam2: 113.mp4\n",
            "cam2: 49.mp4\n",
            "cam2: 77.mp4\n",
            "cam2: 21.mp4\n",
            "cam2: 50.mp4\n",
            "cam2: 115.mp4\n",
            "cam2: 38.mp4\n",
            "cam2: 63.mp4\n",
            "cam2: 100.mp4\n",
            "cam2: 80.mp4\n",
            "cam2: 48.mp4\n",
            "cam2: 15.mp4\n",
            "cam2: 92.mp4\n",
            "cam2: 96.mp4\n",
            "cam2: 1.mp4\n",
            "cam2: 19.mp4\n",
            "cam2: 36.mp4\n",
            "cam2: 114.mp4\n",
            "cam2: 26.mp4\n",
            "cam2: 53.mp4\n",
            "cam2: 82.mp4\n",
            "cam2: 37.mp4\n",
            "cam2: 28.mp4\n",
            "cam2: 91.mp4\n",
            "cam2: 27.mp4\n",
            "cam2: 39.mp4\n",
            "cam2: 52.mp4\n",
            "cam1: 98.mp4\n",
            "cam1: 79.mp4\n",
            "cam1: 34.mp4\n",
            "cam1: 102.mp4\n",
            "cam1: 85.mp4\n",
            "cam1: 23.mp4\n",
            "cam1: 87.mp4\n",
            "cam1: 9.mp4\n",
            "cam1: 83.mp4\n",
            "cam1: 108.mp4\n",
            "cam1: 12.mp4\n",
            "cam1: 66.mp4\n",
            "cam1: 99.mp4\n",
            "cam1: 8.mp4\n",
            "cam1: 105.mp4\n",
            "cam1: 104.mp4\n",
            "cam1: 68.mp4\n",
            "cam1: 57.mp4\n",
            "cam1: 10.mp4\n",
            "cam1: 107.mp4\n",
            "cam1: 45.mp4\n",
            "cam1: 6.mp4\n",
            "cam1: 54.mp4\n",
            "cam1: 86.mp4\n",
            "cam1: 109.mp4\n",
            "cam1: 31.mp4\n",
            "cam1: 33.mp4\n",
            "cam1: 22.mp4\n",
            "cam1: 46.mp4\n",
            "cam1: 106.mp4\n",
            "cam1: 29.mp4\n",
            "cam1: 30.mp4\n",
            "cam1: 71.mp4\n",
            "cam1: 24.mp4\n",
            "cam1: 18.mp4\n",
            "cam1: 55.mp4\n",
            "cam1: 97.mp4\n",
            "cam1: 81.mp4\n",
            "cam1: 72.mp4\n",
            "cam1: 17.mp4\n",
            "cam1: 76.mp4\n",
            "cam1: 88.mp4\n",
            "cam1: 35.mp4\n",
            "cam1: 78.mp4\n",
            "cam1: 89.mp4\n",
            "cam1: 84.mp4\n",
            "cam1: 25.mp4\n",
            "cam1: 61.mp4\n",
            "cam1: 69.mp4\n",
            "cam1: 5.mp4\n",
            "cam1: 56.mp4\n",
            "cam1: 111.mp4\n",
            "cam1: 2.mp4\n",
            "cam1: 32.mp4\n",
            "cam1: 59.mp4\n",
            "cam1: 70.mp4\n",
            "cam1: 4.mp4\n",
            "cam1: 40.mp4\n",
            "cam1: 47.mp4\n",
            "cam1: 62.mp4\n",
            "cam1: 75.mp4\n",
            "cam1: 95.mp4\n",
            "cam1: 20.mp4\n",
            "cam1: 74.mp4\n",
            "cam1: 7.mp4\n",
            "cam1: 101.mp4\n",
            "cam1: 73.mp4\n",
            "cam1: 60.mp4\n",
            "cam1: 43.mp4\n",
            "cam1: 112.mp4\n",
            "cam1: 13.mp4\n",
            "cam1: 16.mp4\n",
            "cam1: 65.mp4\n",
            "cam1: 58.mp4\n",
            "cam1: 11.mp4\n",
            "cam1: 94.mp4\n",
            "cam1: 103.mp4\n",
            "cam1: 67.mp4\n",
            "cam1: 41.mp4\n",
            "cam1: 90.mp4\n",
            "cam1: 14.mp4\n",
            "cam1: 3.mp4\n",
            "cam1: 110.mp4\n",
            "cam1: 64.mp4\n",
            "cam1: 42.mp4\n",
            "cam1: 51.mp4\n",
            "cam1: 93.mp4\n",
            "cam1: 44.mp4\n",
            "cam1: 113.mp4\n",
            "cam1: 49.mp4\n",
            "cam1: 77.mp4\n",
            "cam1: 21.mp4\n",
            "cam1: 50.mp4\n",
            "cam1: 115.mp4\n",
            "cam1: 38.mp4\n",
            "cam1: 63.mp4\n",
            "cam1: 100.mp4\n",
            "cam1: 80.mp4\n",
            "cam1: 48.mp4\n",
            "cam1: 15.mp4\n",
            "cam1: 92.mp4\n",
            "cam1: 96.mp4\n",
            "cam1: 1.mp4\n",
            "cam1: 19.mp4\n",
            "cam1: 36.mp4\n",
            "cam1: 114.mp4\n",
            "cam1: 26.mp4\n",
            "cam1: 53.mp4\n",
            "cam1: 82.mp4\n",
            "cam1: 37.mp4\n",
            "cam1: 28.mp4\n",
            "cam1: 91.mp4\n",
            "cam1: 27.mp4\n",
            "cam1: 39.mp4\n",
            "cam1: 52.mp4\n"
          ]
        }
      ],
      "source": [
        "#directory = '/content/drive/MyDrive/Dataset_Violence_Video/violence-detection-dataset/violent'\n",
        "directory = '/content/Dataset_Violence_Video/violence-detection-dataset/violent'\n",
        "for camnumber in os.listdir(directory):\n",
        "    for filename in os.listdir(directory+'/'+camnumber):\n",
        "      print(camnumber+': '+filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kS4tLBM-uebE",
        "outputId": "447c6e21-31f1-4d74-c527-78d31f4450ae"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['cam1', 'cam2']"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "os.listdir('/content/drive/MyDrive/Dataset_Violence_Video/violence-detection-dataset/violent')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "quNYleGy5fpe",
        "outputId": "48b94621-9b7b-4dd2-e11d-7a78573b3621"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "violent/cam2/98.mp4\n",
            "violent/cam2/79.mp4\n",
            "violent/cam2/34.mp4\n",
            "violent/cam2/102.mp4\n",
            "violent/cam2/85.mp4\n",
            "violent/cam2/23.mp4\n",
            "violent/cam2/87.mp4\n",
            "violent/cam2/9.mp4\n",
            "violent/cam2/83.mp4\n",
            "violent/cam2/108.mp4\n",
            "violent/cam2/12.mp4\n",
            "violent/cam2/66.mp4\n",
            "violent/cam2/99.mp4\n",
            "violent/cam2/8.mp4\n",
            "violent/cam2/105.mp4\n",
            "violent/cam2/104.mp4\n",
            "violent/cam2/68.mp4\n",
            "violent/cam2/57.mp4\n",
            "violent/cam2/10.mp4\n",
            "violent/cam2/107.mp4\n",
            "violent/cam2/45.mp4\n",
            "violent/cam2/6.mp4\n",
            "violent/cam2/54.mp4\n",
            "violent/cam2/86.mp4\n",
            "violent/cam2/109.mp4\n",
            "violent/cam2/31.mp4\n",
            "violent/cam2/33.mp4\n",
            "violent/cam2/22.mp4\n",
            "violent/cam2/46.mp4\n",
            "violent/cam2/106.mp4\n",
            "violent/cam2/29.mp4\n",
            "violent/cam2/30.mp4\n",
            "violent/cam2/71.mp4\n",
            "violent/cam2/24.mp4\n",
            "violent/cam2/18.mp4\n",
            "violent/cam2/55.mp4\n",
            "violent/cam2/97.mp4\n",
            "violent/cam2/81.mp4\n",
            "violent/cam2/72.mp4\n",
            "violent/cam2/17.mp4\n",
            "violent/cam2/76.mp4\n",
            "violent/cam2/88.mp4\n",
            "violent/cam2/35.mp4\n",
            "violent/cam2/78.mp4\n",
            "violent/cam2/89.mp4\n",
            "violent/cam2/84.mp4\n",
            "violent/cam2/25.mp4\n",
            "violent/cam2/61.mp4\n",
            "violent/cam2/69.mp4\n",
            "violent/cam2/5.mp4\n",
            "violent/cam2/56.mp4\n",
            "violent/cam2/111.mp4\n",
            "violent/cam2/2.mp4\n",
            "violent/cam2/32.mp4\n",
            "violent/cam2/59.mp4\n",
            "violent/cam2/70.mp4\n",
            "violent/cam2/4.mp4\n",
            "violent/cam2/40.mp4\n",
            "violent/cam2/47.mp4\n",
            "violent/cam2/62.mp4\n",
            "violent/cam2/75.mp4\n",
            "violent/cam2/95.mp4\n",
            "violent/cam2/20.mp4\n",
            "violent/cam2/74.mp4\n",
            "violent/cam2/7.mp4\n",
            "violent/cam2/101.mp4\n",
            "violent/cam2/73.mp4\n",
            "violent/cam2/60.mp4\n",
            "violent/cam2/43.mp4\n",
            "violent/cam2/112.mp4\n",
            "violent/cam2/13.mp4\n",
            "violent/cam2/16.mp4\n",
            "violent/cam2/65.mp4\n",
            "violent/cam2/58.mp4\n",
            "violent/cam2/11.mp4\n",
            "violent/cam2/94.mp4\n",
            "violent/cam2/103.mp4\n",
            "violent/cam2/67.mp4\n",
            "violent/cam2/41.mp4\n",
            "violent/cam2/90.mp4\n",
            "violent/cam2/14.mp4\n",
            "violent/cam2/3.mp4\n",
            "violent/cam2/110.mp4\n",
            "violent/cam2/64.mp4\n",
            "violent/cam2/42.mp4\n",
            "violent/cam2/51.mp4\n",
            "violent/cam2/93.mp4\n",
            "violent/cam2/44.mp4\n",
            "violent/cam2/113.mp4\n",
            "violent/cam2/49.mp4\n",
            "violent/cam2/77.mp4\n",
            "violent/cam2/21.mp4\n",
            "violent/cam2/50.mp4\n",
            "violent/cam2/115.mp4\n",
            "violent/cam2/38.mp4\n",
            "violent/cam2/63.mp4\n",
            "violent/cam2/100.mp4\n",
            "violent/cam2/80.mp4\n",
            "violent/cam2/48.mp4\n",
            "violent/cam2/15.mp4\n",
            "violent/cam2/92.mp4\n",
            "violent/cam2/96.mp4\n",
            "violent/cam2/1.mp4\n",
            "violent/cam2/19.mp4\n",
            "violent/cam2/36.mp4\n",
            "violent/cam2/114.mp4\n",
            "violent/cam2/26.mp4\n",
            "violent/cam2/53.mp4\n",
            "violent/cam2/82.mp4\n",
            "violent/cam2/37.mp4\n",
            "violent/cam2/28.mp4\n",
            "violent/cam2/91.mp4\n",
            "violent/cam2/27.mp4\n",
            "violent/cam2/39.mp4\n",
            "violent/cam2/52.mp4\n",
            "violent/cam1/98.mp4\n",
            "violent/cam1/79.mp4\n",
            "violent/cam1/34.mp4\n",
            "violent/cam1/102.mp4\n",
            "violent/cam1/85.mp4\n",
            "violent/cam1/23.mp4\n",
            "violent/cam1/87.mp4\n",
            "violent/cam1/9.mp4\n",
            "violent/cam1/83.mp4\n",
            "violent/cam1/108.mp4\n",
            "violent/cam1/12.mp4\n",
            "violent/cam1/66.mp4\n",
            "violent/cam1/99.mp4\n",
            "violent/cam1/8.mp4\n",
            "violent/cam1/105.mp4\n",
            "violent/cam1/104.mp4\n",
            "violent/cam1/68.mp4\n",
            "violent/cam1/57.mp4\n",
            "violent/cam1/10.mp4\n",
            "violent/cam1/107.mp4\n",
            "violent/cam1/45.mp4\n",
            "violent/cam1/6.mp4\n",
            "violent/cam1/54.mp4\n",
            "violent/cam1/86.mp4\n",
            "violent/cam1/109.mp4\n",
            "violent/cam1/31.mp4\n",
            "violent/cam1/33.mp4\n",
            "violent/cam1/22.mp4\n",
            "violent/cam1/46.mp4\n",
            "violent/cam1/106.mp4\n",
            "violent/cam1/29.mp4\n",
            "violent/cam1/30.mp4\n",
            "violent/cam1/71.mp4\n",
            "violent/cam1/24.mp4\n",
            "violent/cam1/18.mp4\n",
            "violent/cam1/55.mp4\n",
            "violent/cam1/97.mp4\n",
            "violent/cam1/81.mp4\n",
            "violent/cam1/72.mp4\n",
            "violent/cam1/17.mp4\n",
            "violent/cam1/76.mp4\n",
            "violent/cam1/88.mp4\n",
            "violent/cam1/35.mp4\n",
            "violent/cam1/78.mp4\n",
            "violent/cam1/89.mp4\n",
            "violent/cam1/84.mp4\n",
            "violent/cam1/25.mp4\n",
            "violent/cam1/61.mp4\n",
            "violent/cam1/69.mp4\n",
            "violent/cam1/5.mp4\n",
            "violent/cam1/56.mp4\n",
            "violent/cam1/111.mp4\n",
            "violent/cam1/2.mp4\n",
            "violent/cam1/32.mp4\n",
            "violent/cam1/59.mp4\n",
            "violent/cam1/70.mp4\n",
            "violent/cam1/4.mp4\n",
            "violent/cam1/40.mp4\n",
            "violent/cam1/47.mp4\n",
            "violent/cam1/62.mp4\n",
            "violent/cam1/75.mp4\n",
            "violent/cam1/95.mp4\n",
            "violent/cam1/20.mp4\n",
            "violent/cam1/74.mp4\n",
            "violent/cam1/7.mp4\n",
            "violent/cam1/101.mp4\n",
            "violent/cam1/73.mp4\n",
            "violent/cam1/60.mp4\n",
            "violent/cam1/43.mp4\n",
            "violent/cam1/112.mp4\n",
            "violent/cam1/13.mp4\n",
            "violent/cam1/16.mp4\n",
            "violent/cam1/65.mp4\n",
            "violent/cam1/58.mp4\n",
            "violent/cam1/11.mp4\n",
            "violent/cam1/94.mp4\n",
            "violent/cam1/103.mp4\n",
            "violent/cam1/67.mp4\n",
            "violent/cam1/41.mp4\n",
            "violent/cam1/90.mp4\n",
            "violent/cam1/14.mp4\n",
            "violent/cam1/3.mp4\n",
            "violent/cam1/110.mp4\n",
            "violent/cam1/64.mp4\n",
            "violent/cam1/42.mp4\n",
            "violent/cam1/51.mp4\n",
            "violent/cam1/93.mp4\n",
            "violent/cam1/44.mp4\n",
            "violent/cam1/113.mp4\n",
            "violent/cam1/49.mp4\n",
            "violent/cam1/77.mp4\n",
            "violent/cam1/21.mp4\n",
            "violent/cam1/50.mp4\n",
            "violent/cam1/115.mp4\n",
            "violent/cam1/38.mp4\n",
            "violent/cam1/63.mp4\n",
            "violent/cam1/100.mp4\n",
            "violent/cam1/80.mp4\n",
            "violent/cam1/48.mp4\n",
            "violent/cam1/15.mp4\n",
            "violent/cam1/92.mp4\n",
            "violent/cam1/96.mp4\n",
            "violent/cam1/1.mp4\n",
            "violent/cam1/19.mp4\n",
            "violent/cam1/36.mp4\n",
            "violent/cam1/114.mp4\n",
            "violent/cam1/26.mp4\n",
            "violent/cam1/53.mp4\n",
            "violent/cam1/82.mp4\n",
            "violent/cam1/37.mp4\n",
            "violent/cam1/28.mp4\n",
            "violent/cam1/91.mp4\n",
            "violent/cam1/27.mp4\n",
            "violent/cam1/39.mp4\n",
            "violent/cam1/52.mp4\n",
            "non-violent/cam2/34.mp4\n",
            "non-violent/cam2/23.mp4\n",
            "non-violent/cam2/9.mp4\n",
            "non-violent/cam2/12.mp4\n",
            "non-violent/cam2/8.mp4\n",
            "non-violent/cam2/57.mp4\n",
            "non-violent/cam2/10.mp4\n",
            "non-violent/cam2/45.mp4\n",
            "non-violent/cam2/6.mp4\n",
            "non-violent/cam2/54.mp4\n",
            "non-violent/cam2/31.mp4\n",
            "non-violent/cam2/33.mp4\n",
            "non-violent/cam2/22.mp4\n",
            "non-violent/cam2/46.mp4\n",
            "non-violent/cam2/29.mp4\n",
            "non-violent/cam2/30.mp4\n",
            "non-violent/cam2/24.mp4\n",
            "non-violent/cam2/18.mp4\n",
            "non-violent/cam2/55.mp4\n",
            "non-violent/cam2/17.mp4\n",
            "non-violent/cam2/35.mp4\n",
            "non-violent/cam2/25.mp4\n",
            "non-violent/cam2/5.mp4\n",
            "non-violent/cam2/56.mp4\n",
            "non-violent/cam2/2.mp4\n",
            "non-violent/cam2/32.mp4\n",
            "non-violent/cam2/59.mp4\n",
            "non-violent/cam2/4.mp4\n",
            "non-violent/cam2/40.mp4\n",
            "non-violent/cam2/47.mp4\n",
            "non-violent/cam2/20.mp4\n",
            "non-violent/cam2/7.mp4\n",
            "non-violent/cam2/60.mp4\n",
            "non-violent/cam2/43.mp4\n",
            "non-violent/cam2/13.mp4\n",
            "non-violent/cam2/16.mp4\n",
            "non-violent/cam2/58.mp4\n",
            "non-violent/cam2/11.mp4\n",
            "non-violent/cam2/41.mp4\n",
            "non-violent/cam2/14.mp4\n",
            "non-violent/cam2/3.mp4\n",
            "non-violent/cam2/42.mp4\n",
            "non-violent/cam2/51.mp4\n",
            "non-violent/cam2/44.mp4\n",
            "non-violent/cam2/49.mp4\n",
            "non-violent/cam2/21.mp4\n",
            "non-violent/cam2/50.mp4\n",
            "non-violent/cam2/38.mp4\n",
            "non-violent/cam2/48.mp4\n",
            "non-violent/cam2/15.mp4\n",
            "non-violent/cam2/1.mp4\n",
            "non-violent/cam2/19.mp4\n",
            "non-violent/cam2/36.mp4\n",
            "non-violent/cam2/26.mp4\n",
            "non-violent/cam2/53.mp4\n",
            "non-violent/cam2/37.mp4\n",
            "non-violent/cam2/28.mp4\n",
            "non-violent/cam2/27.mp4\n",
            "non-violent/cam2/39.mp4\n",
            "non-violent/cam2/52.mp4\n",
            "non-violent/cam1/34.mp4\n",
            "non-violent/cam1/23.mp4\n",
            "non-violent/cam1/9.mp4\n",
            "non-violent/cam1/12.mp4\n",
            "non-violent/cam1/8.mp4\n",
            "non-violent/cam1/57.mp4\n",
            "non-violent/cam1/10.mp4\n",
            "non-violent/cam1/45.mp4\n",
            "non-violent/cam1/6.mp4\n",
            "non-violent/cam1/54.mp4\n",
            "non-violent/cam1/31.mp4\n",
            "non-violent/cam1/33.mp4\n",
            "non-violent/cam1/22.mp4\n",
            "non-violent/cam1/46.mp4\n",
            "non-violent/cam1/29.mp4\n",
            "non-violent/cam1/30.mp4\n",
            "non-violent/cam1/24.mp4\n",
            "non-violent/cam1/18.mp4\n",
            "non-violent/cam1/55.mp4\n",
            "non-violent/cam1/17.mp4\n",
            "non-violent/cam1/35.mp4\n",
            "non-violent/cam1/25.mp4\n",
            "non-violent/cam1/5.mp4\n",
            "non-violent/cam1/56.mp4\n",
            "non-violent/cam1/2.mp4\n",
            "non-violent/cam1/32.mp4\n",
            "non-violent/cam1/59.mp4\n",
            "non-violent/cam1/4.mp4\n",
            "non-violent/cam1/40.mp4\n",
            "non-violent/cam1/47.mp4\n",
            "non-violent/cam1/20.mp4\n",
            "non-violent/cam1/7.mp4\n",
            "non-violent/cam1/60.mp4\n",
            "non-violent/cam1/43.mp4\n",
            "non-violent/cam1/13.mp4\n",
            "non-violent/cam1/16.mp4\n",
            "non-violent/cam1/58.mp4\n",
            "non-violent/cam1/11.mp4\n",
            "non-violent/cam1/41.mp4\n",
            "non-violent/cam1/14.mp4\n",
            "non-violent/cam1/3.mp4\n",
            "non-violent/cam1/42.mp4\n",
            "non-violent/cam1/51.mp4\n",
            "non-violent/cam1/44.mp4\n",
            "non-violent/cam1/49.mp4\n",
            "non-violent/cam1/21.mp4\n",
            "non-violent/cam1/50.mp4\n",
            "non-violent/cam1/38.mp4\n",
            "non-violent/cam1/48.mp4\n",
            "non-violent/cam1/15.mp4\n",
            "non-violent/cam1/1.mp4\n",
            "non-violent/cam1/19.mp4\n",
            "non-violent/cam1/36.mp4\n",
            "non-violent/cam1/26.mp4\n",
            "non-violent/cam1/53.mp4\n",
            "non-violent/cam1/37.mp4\n",
            "non-violent/cam1/28.mp4\n",
            "non-violent/cam1/27.mp4\n",
            "non-violent/cam1/39.mp4\n",
            "non-violent/cam1/52.mp4\n"
          ]
        }
      ],
      "source": [
        "def get_video_files(folder_path):\n",
        "    video_files = []\n",
        "\n",
        "    for root, dirs, files in os.walk(folder_path):\n",
        "        subfolder_list = root.split(os.path.sep)\n",
        "        v_nv = subfolder_list[-2]  \n",
        "        c1_c2 = subfolder_list[-1]  \n",
        "\n",
        "        video_files.extend([(v_nv, c1_c2, file) for file in files if file.lower().endswith(('.mp4', '.avi', '.mkv'))])\n",
        "\n",
        "    return video_files\n",
        "\n",
        "#folder_path = '/content/drive/MyDrive/Dataset_Violence_Video/violence-detection-dataset/'\n",
        "folder_path = '/content/Dataset_Violence_Video/violence-detection-dataset/'\n",
        "\n",
        "video_files_list = get_video_files(folder_path)\n",
        "\n",
        "\n",
        "for v_nv, c1_c2, video_file in video_files_list:\n",
        "    print(f\"{v_nv}/{c1_c2}/{video_file}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wc8JYKp_fj7x",
        "outputId": "0754ebca-9499-4a9a-af31-0c63d8b44324"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['', 'content', 'Dataset_Violence_Video', 'violence-detection-dataset', '']\n",
            "['', 'content', 'Dataset_Violence_Video', 'violence-detection-dataset', 'violent']\n",
            "['', 'content', 'Dataset_Violence_Video', 'violence-detection-dataset', 'violent', 'cam2']\n",
            "['', 'content', 'Dataset_Violence_Video', 'violence-detection-dataset', 'violent', 'cam1']\n",
            "['', 'content', 'Dataset_Violence_Video', 'violence-detection-dataset', 'non-violent']\n",
            "['', 'content', 'Dataset_Violence_Video', 'violence-detection-dataset', 'non-violent', 'cam2']\n",
            "['', 'content', 'Dataset_Violence_Video', 'violence-detection-dataset', 'non-violent', 'cam1']\n"
          ]
        }
      ],
      "source": [
        "for root, dirs, files in os.walk(folder_path):\n",
        "    subfolder_list = root.split(os.path.sep)\n",
        "    print(subfolder_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gFewx2zPqVSa"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
        "#from tensorflow.keras.applications.mobilenet_v2 import preprocess_input as preprocess_gender\n",
        "#from tensorflow.keras.applications.vgg16 import preprocess_input as preprocess_violence\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ewKfu8YKk0XS"
      },
      "outputs": [],
      "source": [
        "violence_model_path = '/content/drive/MyDrive/ModelWeights/Violence/vgg_model.keras'\n",
        "gender_model_path = '/content/drive/MyDrive/ModelWeights/Gender/vgg_model.keras'\n",
        "\n",
        "model_violence = tf.keras.saving.load_model(violence_model_path)\n",
        "model_gender = tf.keras.saving.load_model(gender_model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wKZ4lFZFk4wo"
      },
      "outputs": [],
      "source": [
        "def predict_violence(img_array):\n",
        "  img_array = tf.expand_dims(img_array, 0)\n",
        "  preprocess = preprocess_input(img_array)\n",
        "  prediction = model_violence.predict(preprocess)\n",
        "\n",
        "  return prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IH7Aa-Yg9dnf"
      },
      "outputs": [],
      "source": [
        "def predict_gender(img_list):\n",
        "  prediction = []\n",
        "  for img_array in img_list:\n",
        "    cast_img = tf.cast(img_array, tf.float32)\n",
        "    cast_img = tf.expand_dims(cast_img, 0)\n",
        "    preprocess = preprocess_input(cast_img)\n",
        "    prediction.append(model_gender.predict(preprocess))\n",
        "\n",
        "  return prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GKkFQlEfYPN5",
        "outputId": "cafdbdd4-c749-4094-df2b-84e59ba8c6e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov9c.pt to '../YOLO Weights/yolov9c.pt'...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 49.4M/49.4M [00:00<00:00, 246MB/s]\n"
          ]
        }
      ],
      "source": [
        "net = YOLO('../YOLO Weights/yolov9c.pt')\n",
        "\n",
        "def detect_humans(net, img):\n",
        "\n",
        "  bounding_boxes = []\n",
        "  cropped_people = []\n",
        "\n",
        "  results = net(img, stream=True)\n",
        "\n",
        "  for r in results:\n",
        "      for box in r.boxes:\n",
        "          x1, y1, x2, y2 = box.xyxy[0]\n",
        "          x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
        "          w, h = x2-x1, y2-y1\n",
        "\n",
        "          conf = math.ceil((box.conf[0]*100))/100\n",
        "          font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "          cls = int(box.cls[0])\n",
        "\n",
        "          if (cls == 0): \n",
        "            bounding_boxes.append([x1,y1,w,h])\n",
        "            cropped_people.append(img[y1:y1+h, x1:x1+w])\n",
        "\n",
        "  return (cropped_people, bounding_boxes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mNqQ-msEk8DJ"
      },
      "outputs": [],
      "source": [
        "def resize(img):\n",
        "  return tf.image.resize(img, (120,80), tf.image.ResizeMethod.NEAREST_NEIGHBOR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lancsjxHmwoy",
        "outputId": "18044597-149e-4bf5-b8d7-45d459b46ef8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "0: 384x640 4 persons, 182.6ms\n",
            "Speed: 14.6ms preprocess, 182.6ms inference, 2826.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "\n",
            "0: 384x640 4 persons, 27.5ms\n",
            "Speed: 3.6ms preprocess, 27.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "\n",
            "0: 384x640 4 persons, 22.8ms\n",
            "Speed: 3.9ms preprocess, 22.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "\n",
            "0: 384x640 4 persons, 29.3ms\n",
            "Speed: 3.0ms preprocess, 29.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "\n",
            "0: 384x640 4 persons, 31.9ms\n",
            "Speed: 3.0ms preprocess, 31.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "\n",
            "0: 384x640 4 persons, 1 remote, 29.1ms\n",
            "Speed: 3.2ms preprocess, 29.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "\n",
            "0: 384x640 4 persons, 31.7ms\n",
            "Speed: 3.1ms preprocess, 31.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "\n",
            "0: 384x640 4 persons, 31.7ms\n",
            "Speed: 3.0ms preprocess, 31.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "\n",
            "0: 384x640 4 persons, 31.7ms\n",
            "Speed: 2.9ms preprocess, 31.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "\n",
            "0: 384x640 4 persons, 31.8ms\n",
            "Speed: 2.9ms preprocess, 31.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "\n",
            "0: 384x640 4 persons, 31.7ms\n",
            "Speed: 3.0ms preprocess, 31.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "\n",
            "0: 384x640 4 persons, 31.7ms\n",
            "Speed: 2.9ms preprocess, 31.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "\n",
            "0: 384x640 4 persons, 31.7ms\n",
            "Speed: 2.9ms preprocess, 31.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "\n",
            "0: 384x640 4 persons, 31.8ms\n",
            "Speed: 3.0ms preprocess, 31.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "\n",
            "0: 384x640 4 persons, 33.6ms\n",
            "Speed: 3.2ms preprocess, 33.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "\n",
            "0: 384x640 4 persons, 31.7ms\n",
            "Speed: 3.1ms preprocess, 31.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "\n",
            "0: 384x640 4 persons, 31.8ms\n",
            "Speed: 3.3ms preprocess, 31.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "\n",
            "0: 384x640 4 persons, 31.9ms\n",
            "Speed: 3.1ms preprocess, 31.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "\n",
            "0: 384x640 4 persons, 31.7ms\n",
            "Speed: 3.0ms preprocess, 31.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "\n",
            "0: 384x640 4 persons, 31.7ms\n",
            "Speed: 5.9ms preprocess, 31.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "\n",
            "0: 384x640 4 persons, 31.7ms\n",
            "Speed: 5.3ms preprocess, 31.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "\n",
            "0: 384x640 4 persons, 31.7ms\n",
            "Speed: 3.2ms preprocess, 31.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "\n",
            "0: 384x640 4 persons, 32.3ms\n",
            "Speed: 2.9ms preprocess, 32.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "\n",
            "0: 384x640 4 persons, 31.9ms\n",
            "Speed: 3.2ms preprocess, 31.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "\n",
            "0: 384x640 4 persons, 31.7ms\n",
            "Speed: 2.9ms preprocess, 31.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "\n",
            "0: 384x640 4 persons, 33.0ms\n",
            "Speed: 6.5ms preprocess, 33.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "\n",
            "0: 384x640 4 persons, 31.7ms\n",
            "Speed: 3.1ms preprocess, 31.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "\n",
            "0: 384x640 4 persons, 31.7ms\n",
            "Speed: 3.0ms preprocess, 31.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "\n",
            "0: 384x640 4 persons, 33.1ms\n",
            "Speed: 3.2ms preprocess, 33.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "\n",
            "0: 384x640 4 persons, 33.6ms\n",
            "Speed: 3.0ms preprocess, 33.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "\n",
            "0: 384x640 4 persons, 36.1ms\n",
            "Speed: 3.0ms preprocess, 36.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "\n",
            "0: 384x640 4 persons, 1 baseball bat, 31.7ms\n",
            "Speed: 2.9ms preprocess, 31.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "\n",
            "0: 384x640 4 persons, 2 baseball bats, 34.1ms\n",
            "Speed: 6.8ms preprocess, 34.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "\n",
            "0: 384x640 4 persons, 1 baseball bat, 31.8ms\n",
            "Speed: 10.3ms preprocess, 31.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "\n",
            "0: 384x640 4 persons, 1 baseball bat, 31.7ms\n",
            "Speed: 3.0ms preprocess, 31.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "\n",
            "0: 384x640 4 persons, 1 baseball bat, 31.7ms\n",
            "Speed: 3.0ms preprocess, 31.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "\n",
            "0: 384x640 4 persons, 1 baseball bat, 33.5ms\n",
            "Speed: 3.0ms preprocess, 33.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "\n",
            "0: 384x640 4 persons, 1 baseball bat, 1 tennis racket, 32.0ms\n",
            "Speed: 3.1ms preprocess, 32.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "\n",
            "0: 384x640 4 persons, 1 baseball bat, 31.7ms\n",
            "Speed: 2.9ms preprocess, 31.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "\n",
            "0: 384x640 4 persons, 1 baseball bat, 31.8ms\n",
            "Speed: 3.4ms preprocess, 31.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "\n",
            "0: 384x640 4 persons, 31.7ms\n",
            "Speed: 3.4ms preprocess, 31.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "\n",
            "0: 384x640 4 persons, 1 tennis racket, 31.7ms\n",
            "Speed: 3.3ms preprocess, 31.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "\n",
            "0: 384x640 4 persons, 1 baseball bat, 31.7ms\n",
            "Speed: 3.0ms preprocess, 31.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "\n",
            "0: 384x640 4 persons, 1 tennis racket, 31.7ms\n",
            "Speed: 3.0ms preprocess, 31.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "\n",
            "0: 384x640 4 persons, 1 tennis racket, 31.7ms\n",
            "Speed: 5.5ms preprocess, 31.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "\n",
            "0: 384x640 4 persons, 31.7ms\n",
            "Speed: 3.1ms preprocess, 31.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "\n",
            "0: 384x640 4 persons, 31.7ms\n",
            "Speed: 3.0ms preprocess, 31.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "\n",
            "0: 384x640 4 persons, 31.7ms\n",
            "Speed: 3.0ms preprocess, 31.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "\n",
            "0: 384x640 4 persons, 31.7ms\n",
            "Speed: 3.3ms preprocess, 31.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "\n",
            "0: 384x640 4 persons, 31.7ms\n",
            "Speed: 3.1ms preprocess, 31.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "\n",
            "0: 384x640 4 persons, 1 baseball bat, 31.7ms\n",
            "Speed: 3.1ms preprocess, 31.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "\n",
            "0: 384x640 4 persons, 32.8ms\n",
            "Speed: 3.0ms preprocess, 32.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "\n",
            "0: 384x640 4 persons, 31.7ms\n",
            "Speed: 3.3ms preprocess, 31.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "\n",
            "0: 384x640 4 persons, 31.7ms\n",
            "Speed: 3.2ms preprocess, 31.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "\n",
            "0: 384x640 4 persons, 31.7ms\n",
            "Speed: 2.8ms preprocess, 31.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "\n",
            "0: 384x640 4 persons, 1 remote, 31.7ms\n",
            "Speed: 3.0ms preprocess, 31.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "\n",
            "0: 384x640 4 persons, 31.7ms\n",
            "Speed: 3.0ms preprocess, 31.7ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "\n",
            "0: 384x640 4 persons, 31.7ms\n",
            "Speed: 3.0ms preprocess, 31.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "\n",
            "0: 384x640 4 persons, 31.7ms\n",
            "Speed: 3.0ms preprocess, 31.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "\n",
            "0: 384x640 4 persons, 1 baseball bat, 32.0ms\n",
            "Speed: 3.1ms preprocess, 32.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "\n",
            "0: 384x640 4 persons, 31.7ms\n",
            "Speed: 3.0ms preprocess, 31.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "\n",
            "0: 384x640 4 persons, 31.7ms\n",
            "Speed: 8.8ms preprocess, 31.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "\n",
            "0: 384x640 4 persons, 1 remote, 31.8ms\n",
            "Speed: 3.0ms preprocess, 31.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "\n",
            "0: 384x640 4 persons, 31.7ms\n",
            "Speed: 4.8ms preprocess, 31.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "\n",
            "0: 384x640 4 persons, 31.7ms\n",
            "Speed: 2.9ms preprocess, 31.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "\n",
            "0: 384x640 4 persons, 31.8ms\n",
            "Speed: 3.0ms preprocess, 31.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "\n",
            "0: 384x640 4 persons, 1 baseball bat, 31.7ms\n",
            "Speed: 2.9ms preprocess, 31.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "\n",
            "0: 384x640 4 persons, 1 tennis racket, 31.8ms\n",
            "Speed: 3.1ms preprocess, 31.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "\n",
            "0: 384x640 4 persons, 31.7ms\n",
            "Speed: 3.0ms preprocess, 31.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "\n",
            "0: 384x640 4 persons, 31.7ms\n",
            "Speed: 3.2ms preprocess, 31.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "\n",
            "0: 384x640 4 persons, 1 remote, 31.7ms\n",
            "Speed: 2.9ms preprocess, 31.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "\n",
            "0: 384x640 4 persons, 1 frisbee, 1 remote, 31.7ms\n",
            "Speed: 3.4ms preprocess, 31.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "\n",
            "0: 384x640 4 persons, 1 remote, 31.8ms\n",
            "Speed: 3.0ms preprocess, 31.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "\n",
            "0: 384x640 4 persons, 31.7ms\n",
            "Speed: 3.0ms preprocess, 31.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "\n",
            "0: 384x640 4 persons, 31.7ms\n",
            "Speed: 3.8ms preprocess, 31.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "\n",
            "0: 384x640 4 persons, 32.0ms\n",
            "Speed: 3.5ms preprocess, 32.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "\n",
            "0: 384x640 4 persons, 1 umbrella, 34.3ms\n",
            "Speed: 3.0ms preprocess, 34.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "\n",
            "0: 384x640 4 persons, 1 tennis racket, 31.8ms\n",
            "Speed: 4.9ms preprocess, 31.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "\n",
            "0: 384x640 4 persons, 31.7ms\n",
            "Speed: 3.2ms preprocess, 31.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "\n",
            "0: 384x640 4 persons, 1 tennis racket, 31.8ms\n",
            "Speed: 3.0ms preprocess, 31.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "\n",
            "0: 384x640 4 persons, 31.7ms\n",
            "Speed: 2.8ms preprocess, 31.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "\n",
            "0: 384x640 4 persons, 32.0ms\n",
            "Speed: 3.1ms preprocess, 32.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "\n",
            "0: 384x640 4 persons, 2 remotes, 31.7ms\n",
            "Speed: 3.0ms preprocess, 31.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "\n",
            "0: 384x640 4 persons, 31.7ms\n",
            "Speed: 3.0ms preprocess, 31.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "\n",
            "0: 384x640 4 persons, 32.0ms\n",
            "Speed: 2.9ms preprocess, 32.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "\n",
            "0: 384x640 4 persons, 31.7ms\n",
            "Speed: 4.0ms preprocess, 31.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "\n",
            "0: 384x640 4 persons, 31.7ms\n",
            "Speed: 5.7ms preprocess, 31.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "\n",
            "0: 384x640 4 persons, 31.8ms\n",
            "Speed: 3.0ms preprocess, 31.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "\n",
            "0: 384x640 4 persons, 32.1ms\n",
            "Speed: 3.1ms preprocess, 32.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "\n",
            "0: 384x640 4 persons, 1 baseball bat, 31.7ms\n",
            "Speed: 3.2ms preprocess, 31.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "\n",
            "0: 384x640 4 persons, 1 tennis racket, 38.4ms\n",
            "Speed: 3.0ms preprocess, 38.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "\n",
            "0: 384x640 4 persons, 31.8ms\n",
            "Speed: 4.4ms preprocess, 31.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "\n",
            "0: 384x640 5 persons, 1 frisbee, 37.4ms\n",
            "Speed: 3.0ms preprocess, 37.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "\n",
            "0: 384x640 5 persons, 34.7ms\n",
            "Speed: 3.2ms preprocess, 34.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "\n",
            "0: 384x640 5 persons, 31.8ms\n",
            "Speed: 3.1ms preprocess, 31.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "\n",
            "0: 384x640 5 persons, 1 frisbee, 33.5ms\n",
            "Speed: 5.0ms preprocess, 33.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "\n",
            "0: 384x640 5 persons, 1 frisbee, 2 remotes, 34.1ms\n",
            "Speed: 4.6ms preprocess, 34.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "\n",
            "0: 384x640 5 persons, 1 frisbee, 1 remote, 31.7ms\n",
            "Speed: 3.3ms preprocess, 31.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "\n",
            "0: 384x640 5 persons, 1 remote, 31.7ms\n",
            "Speed: 3.0ms preprocess, 31.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "\n",
            "0: 384x640 5 persons, 31.7ms\n",
            "Speed: 2.9ms preprocess, 31.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "\n",
            "0: 384x640 5 persons, 31.7ms\n",
            "Speed: 3.0ms preprocess, 31.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "\n",
            "0: 384x640 5 persons, 1 remote, 31.8ms\n",
            "Speed: 2.9ms preprocess, 31.8ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "\n",
            "0: 384x640 4 persons, 1 remote, 31.7ms\n",
            "Speed: 6.1ms preprocess, 31.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "\n",
            "0: 384x640 4 persons, 1 remote, 32.6ms\n",
            "Speed: 3.0ms preprocess, 32.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "\n",
            "0: 384x640 4 persons, 1 remote, 31.8ms\n",
            "Speed: 3.1ms preprocess, 31.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "\n",
            "0: 384x640 5 persons, 1 remote, 31.7ms\n",
            "Speed: 3.1ms preprocess, 31.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "\n",
            "0: 384x640 5 persons, 31.8ms\n",
            "Speed: 2.9ms preprocess, 31.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "\n",
            "0: 384x640 4 persons, 31.7ms\n",
            "Speed: 3.0ms preprocess, 31.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "\n",
            "0: 384x640 5 persons, 1 remote, 31.7ms\n",
            "Speed: 3.0ms preprocess, 31.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "\n",
            "0: 384x640 5 persons, 1 remote, 31.9ms\n",
            "Speed: 3.0ms preprocess, 31.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "\n",
            "0: 384x640 4 persons, 34.0ms\n",
            "Speed: 3.1ms preprocess, 34.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "\n",
            "0: 384x640 4 persons, 1 tennis racket, 31.7ms\n",
            "Speed: 2.9ms preprocess, 31.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "\n",
            "0: 384x640 4 persons, 1 tennis racket, 31.7ms\n",
            "Speed: 2.9ms preprocess, 31.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "\n",
            "0: 384x640 4 persons, 31.7ms\n",
            "Speed: 3.0ms preprocess, 31.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "\n",
            "0: 384x640 5 persons, 31.7ms\n",
            "Speed: 3.2ms preprocess, 31.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "\n",
            "0: 384x640 4 persons, 31.7ms\n",
            "Speed: 3.1ms preprocess, 31.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "\n",
            "0: 384x640 5 persons, 39.9ms\n",
            "Speed: 3.0ms preprocess, 39.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "\n",
            "0: 384x640 5 persons, 33.3ms\n",
            "Speed: 3.0ms preprocess, 33.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "\n",
            "0: 384x640 5 persons, 33.4ms\n",
            "Speed: 5.0ms preprocess, 33.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "\n",
            "0: 384x640 5 persons, 31.7ms\n",
            "Speed: 3.0ms preprocess, 31.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "\n",
            "0: 384x640 5 persons, 54.5ms\n",
            "Speed: 6.0ms preprocess, 54.5ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "\n",
            "0: 384x640 4 persons, 31.8ms\n",
            "Speed: 3.3ms preprocess, 31.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "\n",
            "0: 384x640 4 persons, 1 remote, 31.8ms\n",
            "Speed: 3.3ms preprocess, 31.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "\n",
            "0: 384x640 4 persons, 31.7ms\n",
            "Speed: 4.9ms preprocess, 31.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "\n",
            "0: 384x640 5 persons, 31.8ms\n",
            "Speed: 2.9ms preprocess, 31.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "\n",
            "0: 384x640 5 persons, 31.7ms\n",
            "Speed: 3.0ms preprocess, 31.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "\n",
            "0: 384x640 4 persons, 31.7ms\n",
            "Speed: 5.3ms preprocess, 31.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "\n",
            "0: 384x640 4 persons, 1 baseball bat, 31.7ms\n",
            "Speed: 3.4ms preprocess, 31.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "\n",
            "0: 384x640 3 persons, 1 tennis racket, 31.7ms\n",
            "Speed: 2.9ms preprocess, 31.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "\n",
            "0: 384x640 4 persons, 31.7ms\n",
            "Speed: 3.0ms preprocess, 31.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "\n",
            "0: 384x640 4 persons, 1 toilet, 1 remote, 33.0ms\n",
            "Speed: 3.1ms preprocess, 33.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "\n",
            "0: 384x640 4 persons, 1 toilet, 31.7ms\n",
            "Speed: 3.2ms preprocess, 31.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "\n",
            "0: 384x640 5 persons, 1 toilet, 35.5ms\n",
            "Speed: 3.0ms preprocess, 35.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "\n",
            "0: 384x640 4 persons, 1 toilet, 1 remote, 32.0ms\n",
            "Speed: 3.1ms preprocess, 32.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "\n",
            "0: 384x640 4 persons, 1 toilet, 31.7ms\n",
            "Speed: 4.8ms preprocess, 31.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "\n",
            "0: 384x640 4 persons, 1 toilet, 31.7ms\n",
            "Speed: 3.0ms preprocess, 31.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "\n",
            "0: 384x640 4 persons, 1 toilet, 1 remote, 31.7ms\n",
            "Speed: 3.0ms preprocess, 31.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "\n",
            "0: 384x640 5 persons, 1 toilet, 31.8ms\n",
            "Speed: 3.0ms preprocess, 31.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "\n",
            "0: 384x640 5 persons, 1 baseball bat, 1 toilet, 31.7ms\n",
            "Speed: 5.6ms preprocess, 31.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "\n",
            "0: 384x640 5 persons, 1 baseball bat, 1 toilet, 34.6ms\n",
            "Speed: 3.3ms preprocess, 34.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "\n",
            "0: 384x640 5 persons, 1 baseball bat, 1 toilet, 31.7ms\n",
            "Speed: 8.4ms preprocess, 31.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "\n",
            "0: 384x640 4 persons, 1 toilet, 31.7ms\n",
            "Speed: 3.9ms preprocess, 31.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "\n",
            "0: 384x640 5 persons, 1 toilet, 34.6ms\n",
            "Speed: 4.4ms preprocess, 34.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "\n",
            "0: 384x640 4 persons, 1 toilet, 32.0ms\n",
            "Speed: 3.5ms preprocess, 32.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "\n",
            "0: 384x640 4 persons, 1 toilet, 37.3ms\n",
            "Speed: 3.0ms preprocess, 37.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "\n",
            "0: 384x640 4 persons, 1 toilet, 1 remote, 33.9ms\n",
            "Speed: 3.1ms preprocess, 33.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "\n",
            "0: 384x640 4 persons, 1 remote, 32.7ms\n",
            "Speed: 3.9ms preprocess, 32.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "\n",
            "0: 384x640 4 persons, 1 remote, 32.4ms\n",
            "Speed: 3.0ms preprocess, 32.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "\n",
            "0: 384x640 4 persons, 1 remote, 31.8ms\n",
            "Speed: 2.9ms preprocess, 31.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "\n",
            "0: 384x640 4 persons, 1 remote, 31.7ms\n",
            "Speed: 3.0ms preprocess, 31.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "\n",
            "0: 384x640 4 persons, 1 remote, 31.7ms\n",
            "Speed: 3.0ms preprocess, 31.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "\n",
            "0: 384x640 4 persons, 37.9ms\n",
            "Speed: 5.2ms preprocess, 37.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "\n",
            "0: 384x640 4 persons, 1 remote, 31.7ms\n",
            "Speed: 4.8ms preprocess, 31.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "\n",
            "0: 384x640 4 persons, 1 remote, 34.7ms\n",
            "Speed: 3.0ms preprocess, 34.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "\n",
            "0: 384x640 4 persons, 1 remote, 31.8ms\n",
            "Speed: 3.2ms preprocess, 31.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "\n",
            "0: 384x640 4 persons, 31.7ms\n",
            "Speed: 2.9ms preprocess, 31.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "\n",
            "0: 384x640 4 persons, 1 frisbee, 34.6ms\n",
            "Speed: 2.9ms preprocess, 34.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "\n",
            "0: 384x640 4 persons, 32.0ms\n",
            "Speed: 3.4ms preprocess, 32.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "\n",
            "0: 384x640 4 persons, 31.8ms\n",
            "Speed: 3.1ms preprocess, 31.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "\n",
            "0: 384x640 4 persons, 1 toilet, 31.8ms\n",
            "Speed: 3.1ms preprocess, 31.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "\n",
            "0: 384x640 4 persons, 31.7ms\n",
            "Speed: 4.9ms preprocess, 31.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "\n",
            "0: 384x640 4 persons, 1 frisbee, 31.8ms\n",
            "Speed: 3.2ms preprocess, 31.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "\n",
            "0: 384x640 4 persons, 1 frisbee, 1 toilet, 31.7ms\n",
            "Speed: 5.5ms preprocess, 31.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "\n",
            "0: 384x640 4 persons, 1 frisbee, 1 toilet, 31.7ms\n",
            "Speed: 2.5ms preprocess, 31.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "\n",
            "0: 384x640 4 persons, 1 toilet, 31.7ms\n",
            "Speed: 3.1ms preprocess, 31.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "\n",
            "0: 384x640 4 persons, 1 baseball bat, 1 toilet, 31.7ms\n",
            "Speed: 4.1ms preprocess, 31.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "\n",
            "0: 384x640 4 persons, 1 baseball bat, 1 toilet, 31.7ms\n",
            "Speed: 3.1ms preprocess, 31.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "\n",
            "0: 384x640 4 persons, 1 baseball bat, 1 toilet, 31.7ms\n",
            "Speed: 3.0ms preprocess, 31.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "\n",
            "0: 384x640 4 persons, 1 toilet, 31.8ms\n",
            "Speed: 3.5ms preprocess, 31.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "\n",
            "0: 384x640 4 persons, 1 toilet, 31.8ms\n",
            "Speed: 3.0ms preprocess, 31.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "\n",
            "0: 384x640 4 persons, 1 toilet, 1 remote, 31.7ms\n",
            "Speed: 2.7ms preprocess, 31.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "\n",
            "0: 384x640 5 persons, 1 toilet, 3 remotes, 33.3ms\n",
            "Speed: 3.0ms preprocess, 33.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "\n",
            "0: 384x640 6 persons, 1 toilet, 31.7ms\n",
            "Speed: 3.5ms preprocess, 31.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "\n",
            "0: 384x640 5 persons, 31.7ms\n",
            "Speed: 3.3ms preprocess, 31.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "\n",
            "0: 384x640 4 persons, 36.8ms\n",
            "Speed: 3.1ms preprocess, 36.8ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "\n",
            "0: 384x640 5 persons, 34.4ms\n",
            "Speed: 4.6ms preprocess, 34.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "\n",
            "0: 384x640 4 persons, 34.8ms\n",
            "Speed: 3.2ms preprocess, 34.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "\n",
            "0: 384x640 4 persons, 1 remote, 32.4ms\n",
            "Speed: 4.4ms preprocess, 32.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "\n",
            "0: 384x640 4 persons, 1 remote, 31.7ms\n",
            "Speed: 3.5ms preprocess, 31.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "\n",
            "0: 384x640 4 persons, 1 remote, 31.7ms\n",
            "Speed: 3.0ms preprocess, 31.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "\n",
            "0: 384x640 4 persons, 1 remote, 31.7ms\n",
            "Speed: 7.2ms preprocess, 31.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "\n",
            "0: 384x640 4 persons, 1 remote, 31.7ms\n",
            "Speed: 3.2ms preprocess, 31.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "\n",
            "0: 384x640 4 persons, 31.8ms\n",
            "Speed: 3.3ms preprocess, 31.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "\n",
            "0: 384x640 4 persons, 35.7ms\n",
            "Speed: 3.1ms preprocess, 35.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "\n",
            "0: 384x640 6 persons, 33.7ms\n",
            "Speed: 3.0ms preprocess, 33.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "\n",
            "0: 384x640 5 persons, 31.7ms\n",
            "Speed: 3.0ms preprocess, 31.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "\n",
            "0: 384x640 7 persons, 2 remotes, 31.7ms\n",
            "Speed: 2.9ms preprocess, 31.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "\n",
            "0: 384x640 5 persons, 31.7ms\n",
            "Speed: 3.1ms preprocess, 31.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "\n",
            "0: 384x640 5 persons, 31.8ms\n",
            "Speed: 3.0ms preprocess, 31.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "\n",
            "0: 384x640 5 persons, 31.7ms\n",
            "Speed: 3.9ms preprocess, 31.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "\n",
            "0: 384x640 4 persons, 31.7ms\n",
            "Speed: 3.1ms preprocess, 31.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "\n",
            "0: 384x640 4 persons, 1 remote, 31.7ms\n",
            "Speed: 2.9ms preprocess, 31.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "\n",
            "0: 384x640 4 persons, 31.7ms\n",
            "Speed: 8.0ms preprocess, 31.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "\n",
            "0: 384x640 4 persons, 34.6ms\n",
            "Speed: 3.1ms preprocess, 34.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "\n",
            "0: 384x640 4 persons, 31.7ms\n",
            "Speed: 5.5ms preprocess, 31.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "\n",
            "0: 384x640 4 persons, 31.8ms\n",
            "Speed: 3.0ms preprocess, 31.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "\n",
            "0: 384x640 4 persons, 1 remote, 31.7ms\n",
            "Speed: 6.4ms preprocess, 31.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "\n",
            "0: 384x640 4 persons, 31.7ms\n",
            "Speed: 3.0ms preprocess, 31.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "\n",
            "0: 384x640 4 persons, 31.7ms\n",
            "Speed: 3.1ms preprocess, 31.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "\n",
            "0: 384x640 4 persons, 1 remote, 31.7ms\n",
            "Speed: 3.3ms preprocess, 31.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "\n",
            "0: 384x640 4 persons, 1 remote, 37.0ms\n",
            "Speed: 5.1ms preprocess, 37.0ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "\n",
            "0: 384x640 5 persons, 1 baseball bat, 36.1ms\n",
            "Speed: 3.1ms preprocess, 36.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "\n",
            "0: 384x640 4 persons, 31.8ms\n",
            "Speed: 3.2ms preprocess, 31.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "\n",
            "0: 384x640 4 persons, 1 baseball bat, 1 cell phone, 34.1ms\n",
            "Speed: 3.2ms preprocess, 34.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "\n",
            "0: 384x640 4 persons, 2 baseball bats, 31.8ms\n",
            "Speed: 5.9ms preprocess, 31.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "\n",
            "0: 384x640 4 persons, 1 baseball bat, 33.5ms\n",
            "Speed: 5.6ms preprocess, 33.5ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "\n",
            "0: 384x640 4 persons, 1 baseball bat, 53.1ms\n",
            "Speed: 2.9ms preprocess, 53.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "\n",
            "0: 384x640 4 persons, 1 baseball bat, 33.7ms\n",
            "Speed: 3.0ms preprocess, 33.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "\n",
            "0: 384x640 4 persons, 2 baseball bats, 31.7ms\n",
            "Speed: 3.1ms preprocess, 31.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "\n",
            "0: 384x640 4 persons, 1 remote, 31.7ms\n",
            "Speed: 5.2ms preprocess, 31.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "\n",
            "0: 384x640 4 persons, 31.7ms\n",
            "Speed: 3.0ms preprocess, 31.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "\n",
            "0: 384x640 4 persons, 31.8ms\n",
            "Speed: 3.8ms preprocess, 31.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "\n",
            "0: 384x640 4 persons, 31.7ms\n",
            "Speed: 3.1ms preprocess, 31.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "\n",
            "0: 384x640 4 persons, 36.9ms\n",
            "Speed: 7.3ms preprocess, 36.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "\n",
            "0: 384x640 4 persons, 31.7ms\n",
            "Speed: 3.0ms preprocess, 31.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "\n",
            "0: 384x640 4 persons, 31.7ms\n",
            "Speed: 3.4ms preprocess, 31.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "\n",
            "0: 384x640 4 persons, 1 remote, 31.8ms\n",
            "Speed: 3.0ms preprocess, 31.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "\n",
            "0: 384x640 4 persons, 31.8ms\n",
            "Speed: 3.2ms preprocess, 31.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "\n",
            "0: 384x640 4 persons, 1 baseball bat, 33.3ms\n",
            "Speed: 3.1ms preprocess, 33.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "\n",
            "0: 384x640 4 persons, 31.8ms\n",
            "Speed: 3.1ms preprocess, 31.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "\n",
            "0: 384x640 4 persons, 32.3ms\n",
            "Speed: 5.2ms preprocess, 32.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "\n",
            "0: 384x640 4 persons, 31.7ms\n",
            "Speed: 3.2ms preprocess, 31.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "\n",
            "0: 384x640 4 persons, 32.2ms\n",
            "Speed: 3.2ms preprocess, 32.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "\n",
            "0: 384x640 4 persons, 1 baseball bat, 31.8ms\n",
            "Speed: 3.0ms preprocess, 31.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "\n",
            "0: 384x640 4 persons, 31.7ms\n",
            "Speed: 3.9ms preprocess, 31.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "\n",
            "0: 384x640 4 persons, 31.7ms\n",
            "Speed: 3.0ms preprocess, 31.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "\n",
            "0: 384x640 4 persons, 31.7ms\n",
            "Speed: 2.6ms preprocess, 31.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "\n",
            "0: 384x640 4 persons, 31.8ms\n",
            "Speed: 2.9ms preprocess, 31.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "\n",
            "0: 384x640 4 persons, 1 remote, 31.7ms\n",
            "Speed: 5.2ms preprocess, 31.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "\n",
            "0: 384x640 4 persons, 1 remote, 31.9ms\n",
            "Speed: 3.2ms preprocess, 31.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "\n",
            "0: 384x640 4 persons, 1 remote, 34.2ms\n",
            "Speed: 5.2ms preprocess, 34.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "\n",
            "0: 384x640 4 persons, 31.7ms\n",
            "Speed: 7.8ms preprocess, 31.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "Stream end. Exiting.\n"
          ]
        }
      ],
      "source": [
        "#directory_root = '/content/drive/MyDrive/Dataset_Violence_Video/violence-detection-dataset/'\n",
        "directory_root = '/content/Dataset_Violence_Video/violence-detection-dataset/'\n",
        "\n",
        "video_cap = cv2.VideoCapture('/content/Dataset_Violence_Video/violence-detection-dataset/violent/cam1/23.mp4')\n",
        "\n",
        "df_violence_results = pd.DataFrame(columns=['video_name','label', 'camera', 'violence_prediction', 'has_female', 'violence_detected'])\n",
        "\n",
        "violence_count = 0\n",
        "female_number = 0\n",
        "max_people_on_screen = 0\n",
        "frame_count = 0\n",
        "people_on_screen = []\n",
        "predictions = []\n",
        "\n",
        "while video_cap.isOpened():\n",
        "    ret, frame = video_cap.read()\n",
        "\n",
        "    if not ret:\n",
        "      print(\"Stream end. Exiting.\")\n",
        "      break\n",
        "\n",
        "    crop, bounding_boxes = detect_humans(net, frame)\n",
        "\n",
        "    resized = list(map(resize, crop))\n",
        "    predictions_gender = predict_gender(resized)\n",
        "\n",
        "    resized = tf.image.resize(frame, (120,160), tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
        "    resized_cast = tf.cast(resized, tf.float32)\n",
        "    prediction_violence = predict_violence(resized_cast)\n",
        "\n",
        "    if(prediction_violence[0][1] > prediction_violence[0][0]):\n",
        "      violence_count += 1\n",
        "\n",
        "    for pred in predictions_gender:\n",
        "        if(pred[0][0] < pred[0][1]):\n",
        "            female_number += 1\n",
        "\n",
        "    people_on_screen.append(len(bounding_boxes))\n",
        "    frame_count += 1\n",
        "\n",
        "max_people_on_screen = np.argmax(np.bincount(people_on_screen))\n",
        "has_female = (female_number/max_people_on_screen) > (frame_count/2)\n",
        "violence_detected = violence_count > 10\n",
        "#1 = violence; 0 = non-violence\n",
        "classification = 1 if violence_detected and has_female else 0\n",
        "\n",
        "predictions.append(pd.Series(['23', 'violent', 'cam1', classification, has_female, violence_detected], index=df_violence_results.columns))\n",
        "\n",
        "video_cap.release()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rvBte4ZbCJhw",
        "outputId": "64ad52f6-8206-4c5f-d60a-4497304319cd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "232"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "violence_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EzAP3JIw-YH8",
        "outputId": "aeeb1dd7-1b45-4a86-9219-bbc2105309a3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[video_name                  23\n",
              " label                  violent\n",
              " camera                    cam1\n",
              " violence_prediction          0\n",
              " has_female               False\n",
              " violence_detected         True\n",
              " dtype: object]"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s1U8aaPqngR8",
        "outputId": "a95f1266-20b6-4404-b05c-83b310e4554a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "258"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "female_number"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ydmdzQHeizfR"
      },
      "outputs": [],
      "source": [
        "drive.flush_and_unmount()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8RT-kIB2FWFD",
        "outputId": "e6f614f4-8e8e-4690-d47a-aeaa6d241f06"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mA saída de streaming foi truncada nas últimas 5000 linhas.\u001b[0m\n",
            "0: 384x640 3 persons, 31.0ms\n",
            "Speed: 2.9ms preprocess, 31.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "\n",
            "0: 384x640 4 persons, 31.1ms\n",
            "Speed: 3.1ms preprocess, 31.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.0ms\n",
            "Speed: 3.1ms preprocess, 31.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "\n",
            "0: 384x640 3 persons, 33.0ms\n",
            "Speed: 3.1ms preprocess, 33.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.1ms\n",
            "Speed: 4.6ms preprocess, 31.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.2ms\n",
            "Speed: 3.2ms preprocess, 31.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.1ms\n",
            "Speed: 3.0ms preprocess, 31.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "\n",
            "0: 384x640 3 persons, 37.4ms\n",
            "Speed: 4.5ms preprocess, 37.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.1ms\n",
            "Speed: 3.0ms preprocess, 31.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "\n",
            "0: 384x640 3 persons, 1 cell phone, 31.1ms\n",
            "Speed: 3.0ms preprocess, 31.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.6ms\n",
            "Speed: 3.2ms preprocess, 31.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "\n",
            "0: 384x640 3 persons, 33.6ms\n",
            "Speed: 3.1ms preprocess, 33.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.1ms\n",
            "Speed: 4.6ms preprocess, 31.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.1ms\n",
            "Speed: 2.7ms preprocess, 31.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.1ms\n",
            "Speed: 3.0ms preprocess, 31.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "\n",
            "0: 384x640 3 persons, 33.4ms\n",
            "Speed: 5.6ms preprocess, 33.4ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.1ms\n",
            "Speed: 2.9ms preprocess, 31.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "\n",
            "0: 384x640 2 persons, 37.3ms\n",
            "Speed: 2.9ms preprocess, 37.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.1ms\n",
            "Speed: 4.6ms preprocess, 31.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.0ms\n",
            "Speed: 5.3ms preprocess, 31.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "\n",
            "0: 384x640 4 persons, 36.0ms\n",
            "Speed: 3.0ms preprocess, 36.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 66ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.0ms\n",
            "Speed: 3.1ms preprocess, 31.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "\n",
            "0: 384x640 3 persons, 1 remote, 31.1ms\n",
            "Speed: 2.9ms preprocess, 31.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "\n",
            "0: 384x640 3 persons, 1 remote, 31.0ms\n",
            "Speed: 2.9ms preprocess, 31.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "\n",
            "0: 384x640 3 persons, 1 remote, 31.1ms\n",
            "Speed: 2.9ms preprocess, 31.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.1ms\n",
            "Speed: 2.9ms preprocess, 31.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.1ms\n",
            "Speed: 3.3ms preprocess, 31.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "Stream end. Exiting.\n",
            "\n",
            "0: 384x640 3 persons, 2 remotes, 31.1ms\n",
            "Speed: 3.6ms preprocess, 31.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "\n",
            "0: 384x640 3 persons, 1 remote, 31.5ms\n",
            "Speed: 3.1ms preprocess, 31.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "\n",
            "0: 384x640 3 persons, 1 remote, 37.5ms\n",
            "Speed: 2.8ms preprocess, 37.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "\n",
            "0: 384x640 3 persons, 1 remote, 31.1ms\n",
            "Speed: 4.6ms preprocess, 31.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "\n",
            "0: 384x640 3 persons, 1 remote, 31.1ms\n",
            "Speed: 3.0ms preprocess, 31.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "\n",
            "0: 384x640 3 persons, 1 remote, 31.0ms\n",
            "Speed: 3.0ms preprocess, 31.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "\n",
            "0: 384x640 3 persons, 1 remote, 33.6ms\n",
            "Speed: 3.1ms preprocess, 33.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "\n",
            "0: 384x640 3 persons, 1 remote, 31.1ms\n",
            "Speed: 9.4ms preprocess, 31.1ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "\n",
            "0: 384x640 3 persons, 1 remote, 33.9ms\n",
            "Speed: 3.6ms preprocess, 33.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "\n",
            "0: 384x640 3 persons, 1 remote, 31.4ms\n",
            "Speed: 3.1ms preprocess, 31.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "\n",
            "0: 384x640 3 persons, 1 remote, 34.5ms\n",
            "Speed: 5.8ms preprocess, 34.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "\n",
            "0: 384x640 3 persons, 1 remote, 34.6ms\n",
            "Speed: 2.8ms preprocess, 34.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "\n",
            "0: 384x640 3 persons, 1 remote, 35.6ms\n",
            "Speed: 2.9ms preprocess, 35.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "\n",
            "0: 384x640 3 persons, 1 remote, 32.1ms\n",
            "Speed: 3.1ms preprocess, 32.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "\n",
            "0: 384x640 3 persons, 1 remote, 31.0ms\n",
            "Speed: 3.4ms preprocess, 31.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "\n",
            "0: 384x640 3 persons, 1 remote, 31.0ms\n",
            "Speed: 6.7ms preprocess, 31.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.1ms\n",
            "Speed: 3.3ms preprocess, 31.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "\n",
            "0: 384x640 3 persons, 32.9ms\n",
            "Speed: 3.1ms preprocess, 32.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "\n",
            "0: 384x640 3 persons, 1 remote, 33.5ms\n",
            "Speed: 3.1ms preprocess, 33.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "\n",
            "0: 384x640 3 persons, 1 remote, 46.7ms\n",
            "Speed: 2.9ms preprocess, 46.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "\n",
            "0: 384x640 3 persons, 1 remote, 35.4ms\n",
            "Speed: 3.1ms preprocess, 35.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "\n",
            "0: 384x640 3 persons, 2 remotes, 40.0ms\n",
            "Speed: 7.0ms preprocess, 40.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "\n",
            "0: 384x640 3 persons, 2 remotes, 38.2ms\n",
            "Speed: 3.0ms preprocess, 38.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "\n",
            "0: 384x640 3 persons, 1 remote, 37.4ms\n",
            "Speed: 3.2ms preprocess, 37.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "\n",
            "0: 384x640 3 persons, 1 remote, 39.6ms\n",
            "Speed: 6.7ms preprocess, 39.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "\n",
            "0: 384x640 3 persons, 1 remote, 31.1ms\n",
            "Speed: 7.2ms preprocess, 31.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "\n",
            "0: 384x640 3 persons, 1 remote, 33.7ms\n",
            "Speed: 3.0ms preprocess, 33.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "\n",
            "0: 384x640 3 persons, 2 remotes, 40.5ms\n",
            "Speed: 2.6ms preprocess, 40.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.1ms\n",
            "Speed: 3.0ms preprocess, 31.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "\n",
            "0: 384x640 3 persons, 1 remote, 31.1ms\n",
            "Speed: 3.1ms preprocess, 31.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "\n",
            "0: 384x640 3 persons, 2 remotes, 37.1ms\n",
            "Speed: 3.0ms preprocess, 37.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "\n",
            "0: 384x640 3 persons, 1 remote, 31.0ms\n",
            "Speed: 4.6ms preprocess, 31.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "\n",
            "0: 384x640 3 persons, 32.9ms\n",
            "Speed: 3.0ms preprocess, 32.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "\n",
            "0: 384x640 3 persons, 33.7ms\n",
            "Speed: 5.1ms preprocess, 33.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "\n",
            "0: 384x640 3 persons, 1 remote, 35.2ms\n",
            "Speed: 3.8ms preprocess, 35.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "\n",
            "0: 384x640 3 persons, 2 remotes, 32.5ms\n",
            "Speed: 2.9ms preprocess, 32.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.0ms\n",
            "Speed: 3.1ms preprocess, 31.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "\n",
            "0: 384x640 3 persons, 1 baseball glove, 31.0ms\n",
            "Speed: 3.1ms preprocess, 31.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "\n",
            "0: 384x640 4 persons, 35.2ms\n",
            "Speed: 4.1ms preprocess, 35.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "\n",
            "0: 384x640 4 persons, 31.6ms\n",
            "Speed: 3.0ms preprocess, 31.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.1ms\n",
            "Speed: 2.9ms preprocess, 31.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.0ms\n",
            "Speed: 5.8ms preprocess, 31.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "\n",
            "0: 384x640 2 persons, 1 book, 31.0ms\n",
            "Speed: 3.2ms preprocess, 31.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.8ms\n",
            "Speed: 3.1ms preprocess, 31.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.1ms\n",
            "Speed: 3.0ms preprocess, 31.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.6ms\n",
            "Speed: 3.2ms preprocess, 31.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "\n",
            "0: 384x640 2 persons, 32.2ms\n",
            "Speed: 7.0ms preprocess, 32.2ms inference, 6.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "\n",
            "0: 384x640 3 persons, 1 handbag, 36.8ms\n",
            "Speed: 5.3ms preprocess, 36.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.1ms\n",
            "Speed: 5.4ms preprocess, 31.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.3ms\n",
            "Speed: 6.6ms preprocess, 31.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "\n",
            "0: 384x640 3 persons, 35.0ms\n",
            "Speed: 11.8ms preprocess, 35.0ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.1ms\n",
            "Speed: 7.1ms preprocess, 31.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.2ms\n",
            "Speed: 2.6ms preprocess, 31.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.1ms\n",
            "Speed: 3.5ms preprocess, 31.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "\n",
            "0: 384x640 2 persons, 52.5ms\n",
            "Speed: 3.5ms preprocess, 52.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "\n",
            "0: 384x640 2 persons, 33.1ms\n",
            "Speed: 3.0ms preprocess, 33.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "\n",
            "0: 384x640 2 persons, 32.0ms\n",
            "Speed: 2.9ms preprocess, 32.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "\n",
            "0: 384x640 2 persons, 46.6ms\n",
            "Speed: 3.0ms preprocess, 46.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "\n",
            "0: 384x640 2 persons, 32.4ms\n",
            "Speed: 3.1ms preprocess, 32.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "\n",
            "0: 384x640 2 persons, 33.3ms\n",
            "Speed: 3.1ms preprocess, 33.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.0ms\n",
            "Speed: 3.1ms preprocess, 31.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "\n",
            "0: 384x640 2 persons, 32.0ms\n",
            "Speed: 6.3ms preprocess, 32.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.0ms\n",
            "Speed: 10.1ms preprocess, 31.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "\n",
            "0: 384x640 2 persons, 32.7ms\n",
            "Speed: 6.1ms preprocess, 32.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.7ms\n",
            "Speed: 3.1ms preprocess, 31.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.1ms\n",
            "Speed: 3.2ms preprocess, 31.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.0ms\n",
            "Speed: 2.9ms preprocess, 31.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.0ms\n",
            "Speed: 4.4ms preprocess, 31.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.0ms\n",
            "Speed: 4.9ms preprocess, 31.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.0ms\n",
            "Speed: 4.4ms preprocess, 31.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "\n",
            "0: 384x640 3 persons, 33.1ms\n",
            "Speed: 3.7ms preprocess, 33.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.1ms\n",
            "Speed: 7.5ms preprocess, 31.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.2ms\n",
            "Speed: 2.9ms preprocess, 31.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.1ms\n",
            "Speed: 3.1ms preprocess, 31.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "\n",
            "0: 384x640 3 persons, 34.9ms\n",
            "Speed: 4.2ms preprocess, 34.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "\n",
            "0: 384x640 4 persons, 31.1ms\n",
            "Speed: 7.6ms preprocess, 31.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "\n",
            "0: 384x640 3 persons, 34.5ms\n",
            "Speed: 3.0ms preprocess, 34.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.1ms\n",
            "Speed: 3.0ms preprocess, 31.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.1ms\n",
            "Speed: 3.2ms preprocess, 31.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.0ms\n",
            "Speed: 4.0ms preprocess, 31.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.1ms\n",
            "Speed: 5.5ms preprocess, 31.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.1ms\n",
            "Speed: 3.0ms preprocess, 31.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.1ms\n",
            "Speed: 3.1ms preprocess, 31.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.1ms\n",
            "Speed: 3.2ms preprocess, 31.1ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.1ms\n",
            "Speed: 5.4ms preprocess, 31.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "\n",
            "0: 384x640 2 persons, 1 toilet, 33.6ms\n",
            "Speed: 4.8ms preprocess, 33.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "\n",
            "0: 384x640 2 persons, 1 toilet, 34.8ms\n",
            "Speed: 3.1ms preprocess, 34.8ms inference, 5.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "\n",
            "0: 384x640 2 persons, 35.9ms\n",
            "Speed: 5.2ms preprocess, 35.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "\n",
            "0: 384x640 2 persons, 39.8ms\n",
            "Speed: 3.0ms preprocess, 39.8ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "\n",
            "0: 384x640 2 persons, 35.2ms\n",
            "Speed: 4.8ms preprocess, 35.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.6ms\n",
            "Speed: 2.5ms preprocess, 31.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "\n",
            "0: 384x640 2 persons, 40.4ms\n",
            "Speed: 2.9ms preprocess, 40.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "\n",
            "0: 384x640 2 persons, 37.4ms\n",
            "Speed: 2.7ms preprocess, 37.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.0ms\n",
            "Speed: 3.1ms preprocess, 31.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "\n",
            "0: 384x640 3 persons, 32.3ms\n",
            "Speed: 5.1ms preprocess, 32.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "\n",
            "0: 384x640 2 persons, 33.7ms\n",
            "Speed: 3.0ms preprocess, 33.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.0ms\n",
            "Speed: 4.9ms preprocess, 31.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.0ms\n",
            "Speed: 3.0ms preprocess, 31.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "\n",
            "0: 384x640 2 persons, 34.7ms\n",
            "Speed: 3.0ms preprocess, 34.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "\n",
            "0: 384x640 2 persons, 1 remote, 31.1ms\n",
            "Speed: 3.2ms preprocess, 31.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.1ms\n",
            "Speed: 3.2ms preprocess, 31.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "\n",
            "0: 384x640 2 persons, 1 remote, 33.6ms\n",
            "Speed: 4.4ms preprocess, 33.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "\n",
            "0: 384x640 2 persons, 1 remote, 36.9ms\n",
            "Speed: 2.4ms preprocess, 36.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "\n",
            "0: 384x640 2 persons, 1 remote, 31.1ms\n",
            "Speed: 3.0ms preprocess, 31.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "\n",
            "0: 384x640 2 persons, 1 remote, 31.1ms\n",
            "Speed: 3.6ms preprocess, 31.1ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.1ms\n",
            "Speed: 3.4ms preprocess, 31.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "\n",
            "0: 384x640 2 persons, 32.6ms\n",
            "Speed: 3.2ms preprocess, 32.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.0ms\n",
            "Speed: 8.0ms preprocess, 31.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "\n",
            "0: 384x640 3 persons, 32.1ms\n",
            "Speed: 4.0ms preprocess, 32.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "\n",
            "0: 384x640 2 persons, 56.7ms\n",
            "Speed: 3.2ms preprocess, 56.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.0ms\n",
            "Speed: 3.2ms preprocess, 31.0ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.1ms\n",
            "Speed: 3.0ms preprocess, 31.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.0ms\n",
            "Speed: 3.1ms preprocess, 31.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.1ms\n",
            "Speed: 4.6ms preprocess, 31.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "\n",
            "0: 384x640 4 persons, 31.1ms\n",
            "Speed: 6.3ms preprocess, 31.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "\n",
            "0: 384x640 2 persons, 36.7ms\n",
            "Speed: 6.0ms preprocess, 36.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "\n",
            "0: 384x640 2 persons, 33.7ms\n",
            "Speed: 3.0ms preprocess, 33.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "\n",
            "0: 384x640 2 persons, 32.1ms\n",
            "Speed: 3.1ms preprocess, 32.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "\n",
            "0: 384x640 2 persons, 36.8ms\n",
            "Speed: 3.2ms preprocess, 36.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.1ms\n",
            "Speed: 3.1ms preprocess, 31.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "\n",
            "0: 384x640 3 persons, 32.1ms\n",
            "Speed: 5.0ms preprocess, 32.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.1ms\n",
            "Speed: 3.0ms preprocess, 31.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "\n",
            "0: 384x640 2 persons, 43.4ms\n",
            "Speed: 9.4ms preprocess, 43.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "\n",
            "0: 384x640 2 persons, 33.8ms\n",
            "Speed: 3.1ms preprocess, 33.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "\n",
            "0: 384x640 2 persons, 35.2ms\n",
            "Speed: 2.6ms preprocess, 35.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "\n",
            "0: 384x640 2 persons, 33.2ms\n",
            "Speed: 3.0ms preprocess, 33.2ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "\n",
            "0: 384x640 2 persons, 34.6ms\n",
            "Speed: 6.5ms preprocess, 34.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.5ms\n",
            "Speed: 10.6ms preprocess, 31.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "\n",
            "0: 384x640 2 persons, 35.5ms\n",
            "Speed: 2.8ms preprocess, 35.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.8ms\n",
            "Speed: 4.3ms preprocess, 31.8ms inference, 7.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.1ms\n",
            "Speed: 5.2ms preprocess, 31.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.1ms\n",
            "Speed: 5.8ms preprocess, 31.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.1ms\n",
            "Speed: 3.7ms preprocess, 31.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.0ms\n",
            "Speed: 3.1ms preprocess, 31.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "\n",
            "0: 384x640 3 persons, 38.4ms\n",
            "Speed: 2.9ms preprocess, 38.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "\n",
            "0: 384x640 3 persons, 32.1ms\n",
            "Speed: 3.3ms preprocess, 32.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.2ms\n",
            "Speed: 5.9ms preprocess, 31.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "\n",
            "0: 384x640 4 persons, 31.1ms\n",
            "Speed: 4.1ms preprocess, 31.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "\n",
            "0: 384x640 4 persons, 31.2ms\n",
            "Speed: 3.0ms preprocess, 31.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "\n",
            "0: 384x640 3 persons, 35.8ms\n",
            "Speed: 5.7ms preprocess, 35.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.1ms\n",
            "Speed: 3.3ms preprocess, 31.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.4ms\n",
            "Speed: 4.6ms preprocess, 31.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "\n",
            "0: 384x640 3 persons, 33.1ms\n",
            "Speed: 2.9ms preprocess, 33.1ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.0ms\n",
            "Speed: 5.7ms preprocess, 31.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.1ms\n",
            "Speed: 2.8ms preprocess, 31.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.0ms\n",
            "Speed: 3.1ms preprocess, 31.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.2ms\n",
            "Speed: 2.9ms preprocess, 31.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Stream end. Exiting.\n",
            "\n",
            "0: 384x640 2 persons, 31.3ms\n",
            "Speed: 3.1ms preprocess, 31.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.1ms\n",
            "Speed: 3.2ms preprocess, 31.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.0ms\n",
            "Speed: 2.9ms preprocess, 31.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.0ms\n",
            "Speed: 6.2ms preprocess, 31.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.0ms\n",
            "Speed: 3.2ms preprocess, 31.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.1ms\n",
            "Speed: 2.9ms preprocess, 31.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "\n",
            "0: 384x640 2 persons, 36.1ms\n",
            "Speed: 2.9ms preprocess, 36.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.1ms\n",
            "Speed: 4.2ms preprocess, 31.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.7ms\n",
            "Speed: 3.1ms preprocess, 31.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "\n",
            "0: 384x640 2 persons, 32.2ms\n",
            "Speed: 5.3ms preprocess, 32.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "\n",
            "0: 384x640 2 persons, 36.4ms\n",
            "Speed: 2.9ms preprocess, 36.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "\n",
            "0: 384x640 2 persons, 35.6ms\n",
            "Speed: 2.8ms preprocess, 35.6ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "\n",
            "0: 384x640 2 persons, 41.2ms\n",
            "Speed: 2.9ms preprocess, 41.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "\n",
            "0: 384x640 2 persons, 39.7ms\n",
            "Speed: 3.1ms preprocess, 39.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "\n",
            "0: 384x640 2 persons, 36.1ms\n",
            "Speed: 7.4ms preprocess, 36.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "\n",
            "0: 384x640 2 persons, 35.0ms\n",
            "Speed: 3.1ms preprocess, 35.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "\n",
            "0: 384x640 2 persons, 37.4ms\n",
            "Speed: 2.9ms preprocess, 37.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.1ms\n",
            "Speed: 3.2ms preprocess, 31.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "\n",
            "0: 384x640 2 persons, 34.8ms\n",
            "Speed: 3.1ms preprocess, 34.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.0ms\n",
            "Speed: 9.2ms preprocess, 31.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "\n",
            "0: 384x640 2 persons, 32.7ms\n",
            "Speed: 3.4ms preprocess, 32.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.1ms\n",
            "Speed: 3.1ms preprocess, 31.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "\n",
            "0: 384x640 2 persons, 32.7ms\n",
            "Speed: 3.0ms preprocess, 32.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.0ms\n",
            "Speed: 3.0ms preprocess, 31.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.1ms\n",
            "Speed: 5.1ms preprocess, 31.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.1ms\n",
            "Speed: 3.1ms preprocess, 31.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "\n",
            "0: 384x640 2 persons, 34.3ms\n",
            "Speed: 2.8ms preprocess, 34.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.9ms\n",
            "Speed: 3.0ms preprocess, 31.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.1ms\n",
            "Speed: 5.0ms preprocess, 31.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.1ms\n",
            "Speed: 2.9ms preprocess, 31.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "\n",
            "0: 384x640 2 persons, 32.1ms\n",
            "Speed: 2.9ms preprocess, 32.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.1ms\n",
            "Speed: 7.9ms preprocess, 31.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.1ms\n",
            "Speed: 5.1ms preprocess, 31.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.4ms\n",
            "Speed: 4.1ms preprocess, 31.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.9ms\n",
            "Speed: 10.0ms preprocess, 31.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "\n",
            "0: 384x640 3 persons, 35.1ms\n",
            "Speed: 3.3ms preprocess, 35.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.1ms\n",
            "Speed: 3.2ms preprocess, 31.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "\n",
            "0: 384x640 1 person, 32.0ms\n",
            "Speed: 4.0ms preprocess, 32.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "\n",
            "0: 384x640 2 persons, 44.0ms\n",
            "Speed: 7.4ms preprocess, 44.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "\n",
            "0: 384x640 1 person, 31.7ms\n",
            "Speed: 3.1ms preprocess, 31.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "\n",
            "0: 384x640 1 person, 31.0ms\n",
            "Speed: 3.2ms preprocess, 31.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "\n",
            "0: 384x640 1 person, 31.1ms\n",
            "Speed: 3.4ms preprocess, 31.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "\n",
            "0: 384x640 2 persons, 37.1ms\n",
            "Speed: 3.1ms preprocess, 37.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "\n",
            "0: 384x640 1 person, 31.4ms\n",
            "Speed: 3.2ms preprocess, 31.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "\n",
            "0: 384x640 1 person, 31.3ms\n",
            "Speed: 2.9ms preprocess, 31.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "\n",
            "0: 384x640 1 person, 31.1ms\n",
            "Speed: 2.8ms preprocess, 31.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.1ms\n",
            "Speed: 3.0ms preprocess, 31.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "\n",
            "0: 384x640 1 person, 31.1ms\n",
            "Speed: 6.1ms preprocess, 31.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "\n",
            "0: 384x640 1 person, 32.6ms\n",
            "Speed: 3.0ms preprocess, 32.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "\n",
            "0: 384x640 1 person, 35.9ms\n",
            "Speed: 2.8ms preprocess, 35.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "\n",
            "0: 384x640 1 person, 46.4ms\n",
            "Speed: 4.2ms preprocess, 46.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.4ms\n",
            "Speed: 4.7ms preprocess, 31.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "\n",
            "0: 384x640 2 persons, 35.0ms\n",
            "Speed: 2.9ms preprocess, 35.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "\n",
            "0: 384x640 1 person, 31.1ms\n",
            "Speed: 11.8ms preprocess, 31.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "\n",
            "0: 384x640 1 person, 31.1ms\n",
            "Speed: 2.9ms preprocess, 31.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "\n",
            "0: 384x640 1 person, 33.2ms\n",
            "Speed: 5.9ms preprocess, 33.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "\n",
            "0: 384x640 1 person, 33.8ms\n",
            "Speed: 3.3ms preprocess, 33.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "\n",
            "0: 384x640 1 person, 32.1ms\n",
            "Speed: 3.0ms preprocess, 32.1ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "\n",
            "0: 384x640 1 person, 32.4ms\n",
            "Speed: 4.8ms preprocess, 32.4ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "\n",
            "0: 384x640 1 person, 36.7ms\n",
            "Speed: 2.9ms preprocess, 36.7ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "\n",
            "0: 384x640 1 person, 31.2ms\n",
            "Speed: 5.4ms preprocess, 31.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "\n",
            "0: 384x640 1 person, 31.1ms\n",
            "Speed: 3.1ms preprocess, 31.1ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "\n",
            "0: 384x640 1 person, 31.0ms\n",
            "Speed: 4.2ms preprocess, 31.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "\n",
            "0: 384x640 1 person, 31.1ms\n",
            "Speed: 2.8ms preprocess, 31.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "\n",
            "0: 384x640 1 person, 31.0ms\n",
            "Speed: 3.0ms preprocess, 31.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "\n",
            "0: 384x640 1 person, 31.5ms\n",
            "Speed: 3.0ms preprocess, 31.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "\n",
            "0: 384x640 1 person, 38.4ms\n",
            "Speed: 2.9ms preprocess, 38.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "\n",
            "0: 384x640 1 person, 31.0ms\n",
            "Speed: 3.0ms preprocess, 31.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "\n",
            "0: 384x640 1 person, 31.0ms\n",
            "Speed: 4.4ms preprocess, 31.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "\n",
            "0: 384x640 1 person, 36.5ms\n",
            "Speed: 3.0ms preprocess, 36.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "\n",
            "0: 384x640 1 person, 32.1ms\n",
            "Speed: 3.0ms preprocess, 32.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "\n",
            "0: 384x640 1 person, 31.1ms\n",
            "Speed: 3.0ms preprocess, 31.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "\n",
            "0: 384x640 1 person, 31.1ms\n",
            "Speed: 3.0ms preprocess, 31.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "\n",
            "0: 384x640 1 person, 31.2ms\n",
            "Speed: 2.9ms preprocess, 31.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "\n",
            "0: 384x640 1 person, 31.1ms\n",
            "Speed: 9.2ms preprocess, 31.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "\n",
            "0: 384x640 1 person, 31.0ms\n",
            "Speed: 4.5ms preprocess, 31.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "\n",
            "0: 384x640 1 person, 31.1ms\n",
            "Speed: 2.9ms preprocess, 31.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "\n",
            "0: 384x640 1 person, 31.1ms\n",
            "Speed: 3.3ms preprocess, 31.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "\n",
            "0: 384x640 1 person, 33.9ms\n",
            "Speed: 7.7ms preprocess, 33.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "\n",
            "0: 384x640 1 person, 31.3ms\n",
            "Speed: 3.0ms preprocess, 31.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "\n",
            "0: 384x640 1 person, 31.2ms\n",
            "Speed: 3.1ms preprocess, 31.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "\n",
            "0: 384x640 1 person, 31.0ms\n",
            "Speed: 3.1ms preprocess, 31.0ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "\n",
            "0: 384x640 1 person, 34.4ms\n",
            "Speed: 3.3ms preprocess, 34.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "\n",
            "0: 384x640 1 person, 31.0ms\n",
            "Speed: 2.9ms preprocess, 31.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "\n",
            "0: 384x640 1 person, 31.0ms\n",
            "Speed: 4.7ms preprocess, 31.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "\n",
            "0: 384x640 1 person, 32.0ms\n",
            "Speed: 3.0ms preprocess, 32.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "\n",
            "0: 384x640 1 person, 31.0ms\n",
            "Speed: 2.5ms preprocess, 31.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "\n",
            "0: 384x640 1 person, 32.2ms\n",
            "Speed: 2.9ms preprocess, 32.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "\n",
            "0: 384x640 1 person, 31.1ms\n",
            "Speed: 3.2ms preprocess, 31.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "\n",
            "0: 384x640 1 person, 31.1ms\n",
            "Speed: 3.1ms preprocess, 31.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "\n",
            "0: 384x640 2 persons, 32.4ms\n",
            "Speed: 3.0ms preprocess, 32.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "\n",
            "0: 384x640 1 person, 37.4ms\n",
            "Speed: 2.9ms preprocess, 37.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.1ms\n",
            "Speed: 3.3ms preprocess, 31.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.1ms\n",
            "Speed: 3.1ms preprocess, 31.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "\n",
            "0: 384x640 2 persons, 34.4ms\n",
            "Speed: 3.1ms preprocess, 34.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.0ms\n",
            "Speed: 2.6ms preprocess, 31.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.1ms\n",
            "Speed: 3.1ms preprocess, 31.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.0ms\n",
            "Speed: 4.7ms preprocess, 31.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "\n",
            "0: 384x640 2 persons, 34.7ms\n",
            "Speed: 3.1ms preprocess, 34.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.8ms\n",
            "Speed: 4.0ms preprocess, 31.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.0ms\n",
            "Speed: 4.5ms preprocess, 31.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "\n",
            "0: 384x640 3 persons, 33.6ms\n",
            "Speed: 7.0ms preprocess, 33.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "\n",
            "0: 384x640 3 persons, 43.4ms\n",
            "Speed: 3.0ms preprocess, 43.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "\n",
            "0: 384x640 3 persons, 1 remote, 38.2ms\n",
            "Speed: 4.2ms preprocess, 38.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.1ms\n",
            "Speed: 3.3ms preprocess, 31.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.1ms\n",
            "Speed: 3.2ms preprocess, 31.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.5ms\n",
            "Speed: 3.1ms preprocess, 31.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.1ms\n",
            "Speed: 3.0ms preprocess, 31.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.6ms\n",
            "Speed: 6.3ms preprocess, 31.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "\n",
            "0: 384x640 2 persons, 1 chair, 31.0ms\n",
            "Speed: 3.9ms preprocess, 31.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "\n",
            "0: 384x640 3 persons, 1 chair, 33.2ms\n",
            "Speed: 4.8ms preprocess, 33.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "\n",
            "0: 384x640 2 persons, 1 chair, 32.9ms\n",
            "Speed: 3.0ms preprocess, 32.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "\n",
            "0: 384x640 2 persons, 1 chair, 32.2ms\n",
            "Speed: 3.0ms preprocess, 32.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "\n",
            "0: 384x640 2 persons, 1 chair, 31.1ms\n",
            "Speed: 4.8ms preprocess, 31.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "\n",
            "0: 384x640 2 persons, 1 chair, 32.1ms\n",
            "Speed: 3.1ms preprocess, 32.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "\n",
            "0: 384x640 2 persons, 1 chair, 34.4ms\n",
            "Speed: 5.2ms preprocess, 34.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.1ms\n",
            "Speed: 3.2ms preprocess, 31.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "\n",
            "0: 384x640 2 persons, 1 chair, 31.0ms\n",
            "Speed: 5.2ms preprocess, 31.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.0ms\n",
            "Speed: 3.3ms preprocess, 31.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "\n",
            "0: 384x640 2 persons, 32.9ms\n",
            "Speed: 3.6ms preprocess, 32.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.0ms\n",
            "Speed: 6.1ms preprocess, 31.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.0ms\n",
            "Speed: 2.9ms preprocess, 31.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "\n",
            "0: 384x640 2 persons, 37.5ms\n",
            "Speed: 3.1ms preprocess, 37.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.6ms\n",
            "Speed: 6.1ms preprocess, 31.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "\n",
            "0: 384x640 2 persons, 33.2ms\n",
            "Speed: 3.2ms preprocess, 33.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.0ms\n",
            "Speed: 3.0ms preprocess, 31.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "\n",
            "0: 384x640 2 persons, 32.2ms\n",
            "Speed: 11.7ms preprocess, 32.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.1ms\n",
            "Speed: 7.4ms preprocess, 31.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "\n",
            "0: 384x640 2 persons, 41.4ms\n",
            "Speed: 8.8ms preprocess, 41.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.1ms\n",
            "Speed: 3.9ms preprocess, 31.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.0ms\n",
            "Speed: 5.0ms preprocess, 31.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.8ms\n",
            "Speed: 3.0ms preprocess, 31.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "\n",
            "0: 384x640 2 persons, 34.2ms\n",
            "Speed: 3.0ms preprocess, 34.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "\n",
            "0: 384x640 2 persons, 44.0ms\n",
            "Speed: 3.5ms preprocess, 44.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.2ms\n",
            "Speed: 3.7ms preprocess, 31.2ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "\n",
            "0: 384x640 2 persons, 34.3ms\n",
            "Speed: 3.6ms preprocess, 34.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 70ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "\n",
            "0: 384x640 2 persons, 35.3ms\n",
            "Speed: 3.1ms preprocess, 35.3ms inference, 6.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.1ms\n",
            "Speed: 11.6ms preprocess, 31.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "\n",
            "0: 384x640 2 persons, 47.3ms\n",
            "Speed: 3.1ms preprocess, 47.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.1ms\n",
            "Speed: 3.2ms preprocess, 31.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.0ms\n",
            "Speed: 3.3ms preprocess, 31.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Stream end. Exiting.\n",
            "\n",
            "0: 384x640 3 persons, 1 remote, 33.2ms\n",
            "Speed: 12.5ms preprocess, 33.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "\n",
            "0: 384x640 3 persons, 1 remote, 33.8ms\n",
            "Speed: 3.6ms preprocess, 33.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "\n",
            "0: 384x640 3 persons, 1 remote, 33.6ms\n",
            "Speed: 3.1ms preprocess, 33.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "\n",
            "0: 384x640 3 persons, 1 remote, 31.0ms\n",
            "Speed: 3.0ms preprocess, 31.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "\n",
            "0: 384x640 3 persons, 1 remote, 31.0ms\n",
            "Speed: 4.4ms preprocess, 31.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "\n",
            "0: 384x640 3 persons, 1 remote, 32.3ms\n",
            "Speed: 6.2ms preprocess, 32.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "\n",
            "0: 384x640 3 persons, 36.4ms\n",
            "Speed: 3.3ms preprocess, 36.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "\n",
            "0: 384x640 3 persons, 1 frisbee, 1 remote, 32.7ms\n",
            "Speed: 3.0ms preprocess, 32.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "\n",
            "0: 384x640 3 persons, 1 remote, 31.7ms\n",
            "Speed: 3.0ms preprocess, 31.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "\n",
            "0: 384x640 3 persons, 2 remotes, 31.0ms\n",
            "Speed: 5.0ms preprocess, 31.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "\n",
            "0: 384x640 3 persons, 1 bottle, 1 remote, 40.1ms\n",
            "Speed: 3.2ms preprocess, 40.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.1ms\n",
            "Speed: 6.4ms preprocess, 31.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.0ms\n",
            "Speed: 5.1ms preprocess, 31.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "\n",
            "0: 384x640 3 persons, 1 remote, 31.1ms\n",
            "Speed: 6.1ms preprocess, 31.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "\n",
            "0: 384x640 3 persons, 1 remote, 31.1ms\n",
            "Speed: 2.9ms preprocess, 31.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "\n",
            "0: 384x640 3 persons, 1 remote, 31.0ms\n",
            "Speed: 3.0ms preprocess, 31.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "\n",
            "0: 384x640 3 persons, 33.6ms\n",
            "Speed: 5.2ms preprocess, 33.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "\n",
            "0: 384x640 3 persons, 1 baseball bat, 34.8ms\n",
            "Speed: 4.0ms preprocess, 34.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.1ms\n",
            "Speed: 3.2ms preprocess, 31.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.5ms\n",
            "Speed: 3.0ms preprocess, 31.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "\n",
            "0: 384x640 3 persons, 1 umbrella, 1 baseball bat, 31.0ms\n",
            "Speed: 3.1ms preprocess, 31.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "\n",
            "0: 384x640 3 persons, 1 baseball bat, 31.1ms\n",
            "Speed: 2.9ms preprocess, 31.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "\n",
            "0: 384x640 3 persons, 1 baseball bat, 1 remote, 31.1ms\n",
            "Speed: 3.0ms preprocess, 31.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "\n",
            "0: 384x640 3 persons, 1 baseball bat, 35.5ms\n",
            "Speed: 3.0ms preprocess, 35.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "\n",
            "0: 384x640 3 persons, 1 baseball bat, 31.1ms\n",
            "Speed: 3.0ms preprocess, 31.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "\n",
            "0: 384x640 3 persons, 1 book, 32.7ms\n",
            "Speed: 5.0ms preprocess, 32.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "\n",
            "0: 384x640 3 persons, 1 frisbee, 40.4ms\n",
            "Speed: 3.0ms preprocess, 40.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "\n",
            "0: 384x640 3 persons, 1 frisbee, 36.8ms\n",
            "Speed: 3.1ms preprocess, 36.8ms inference, 6.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "\n",
            "0: 384x640 3 persons, 1 frisbee, 31.0ms\n",
            "Speed: 4.9ms preprocess, 31.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "\n",
            "0: 384x640 3 persons, 1 book, 31.0ms\n",
            "Speed: 7.0ms preprocess, 31.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.5ms\n",
            "Speed: 3.1ms preprocess, 31.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "\n",
            "0: 384x640 3 persons, 32.1ms\n",
            "Speed: 2.8ms preprocess, 32.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "\n",
            "0: 384x640 3 persons, 33.2ms\n",
            "Speed: 3.0ms preprocess, 33.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "\n",
            "0: 384x640 3 persons, 32.7ms\n",
            "Speed: 3.2ms preprocess, 32.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "\n",
            "0: 384x640 3 persons, 33.9ms\n",
            "Speed: 2.9ms preprocess, 33.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.1ms\n",
            "Speed: 3.9ms preprocess, 31.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "\n",
            "0: 384x640 3 persons, 1 remote, 33.7ms\n",
            "Speed: 3.1ms preprocess, 33.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "\n",
            "0: 384x640 3 persons, 33.3ms\n",
            "Speed: 6.4ms preprocess, 33.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.1ms\n",
            "Speed: 3.2ms preprocess, 31.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.1ms\n",
            "Speed: 3.1ms preprocess, 31.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.1ms\n",
            "Speed: 4.1ms preprocess, 31.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.1ms\n",
            "Speed: 3.4ms preprocess, 31.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.2ms\n",
            "Speed: 3.5ms preprocess, 31.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "\n",
            "0: 384x640 3 persons, 32.6ms\n",
            "Speed: 3.4ms preprocess, 32.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.0ms\n",
            "Speed: 3.1ms preprocess, 31.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.1ms\n",
            "Speed: 3.8ms preprocess, 31.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "\n",
            "0: 384x640 3 persons, 35.5ms\n",
            "Speed: 3.0ms preprocess, 35.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.1ms\n",
            "Speed: 2.9ms preprocess, 31.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.6ms\n",
            "Speed: 3.0ms preprocess, 31.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "\n",
            "0: 384x640 3 persons, 32.5ms\n",
            "Speed: 3.1ms preprocess, 32.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "\n",
            "0: 384x640 3 persons, 36.6ms\n",
            "Speed: 3.1ms preprocess, 36.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "\n",
            "0: 384x640 3 persons, 1 remote, 32.2ms\n",
            "Speed: 10.3ms preprocess, 32.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.1ms\n",
            "Speed: 3.1ms preprocess, 31.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "\n",
            "0: 384x640 3 persons, 40.7ms\n",
            "Speed: 3.0ms preprocess, 40.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "\n",
            "0: 384x640 3 persons, 40.5ms\n",
            "Speed: 6.6ms preprocess, 40.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "\n",
            "0: 384x640 3 persons, 34.5ms\n",
            "Speed: 6.7ms preprocess, 34.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "\n",
            "0: 384x640 3 persons, 34.2ms\n",
            "Speed: 2.9ms preprocess, 34.2ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.5ms\n",
            "Speed: 3.0ms preprocess, 31.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "\n",
            "0: 384x640 3 persons, 1 remote, 31.0ms\n",
            "Speed: 2.8ms preprocess, 31.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "\n",
            "0: 384x640 3 persons, 1 remote, 31.1ms\n",
            "Speed: 4.8ms preprocess, 31.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "\n",
            "0: 384x640 3 persons, 2 remotes, 31.1ms\n",
            "Speed: 3.5ms preprocess, 31.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "\n",
            "0: 384x640 3 persons, 3 remotes, 31.1ms\n",
            "Speed: 3.4ms preprocess, 31.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "\n",
            "0: 384x640 3 persons, 2 remotes, 31.1ms\n",
            "Speed: 5.2ms preprocess, 31.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "\n",
            "0: 384x640 3 persons, 1 remote, 31.1ms\n",
            "Speed: 4.3ms preprocess, 31.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "\n",
            "0: 384x640 3 persons, 1 remote, 31.1ms\n",
            "Speed: 3.0ms preprocess, 31.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "\n",
            "0: 384x640 3 persons, 1 frisbee, 1 remote, 31.8ms\n",
            "Speed: 3.1ms preprocess, 31.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "\n",
            "0: 384x640 3 persons, 1 remote, 34.1ms\n",
            "Speed: 5.9ms preprocess, 34.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "\n",
            "0: 384x640 3 persons, 1 remote, 31.1ms\n",
            "Speed: 3.0ms preprocess, 31.1ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.1ms\n",
            "Speed: 2.8ms preprocess, 31.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.1ms\n",
            "Speed: 6.5ms preprocess, 31.1ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "\n",
            "0: 384x640 3 persons, 37.1ms\n",
            "Speed: 6.0ms preprocess, 37.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.1ms\n",
            "Speed: 3.1ms preprocess, 31.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "\n",
            "0: 384x640 3 persons, 32.3ms\n",
            "Speed: 3.6ms preprocess, 32.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "\n",
            "0: 384x640 3 persons, 1 remote, 31.0ms\n",
            "Speed: 4.2ms preprocess, 31.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "\n",
            "0: 384x640 3 persons, 1 remote, 42.5ms\n",
            "Speed: 3.1ms preprocess, 42.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.1ms\n",
            "Speed: 3.3ms preprocess, 31.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "\n",
            "0: 384x640 3 persons, 1 remote, 31.1ms\n",
            "Speed: 2.9ms preprocess, 31.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "\n",
            "0: 384x640 3 persons, 2 remotes, 31.1ms\n",
            "Speed: 2.8ms preprocess, 31.1ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "\n",
            "0: 384x640 3 persons, 1 remote, 31.4ms\n",
            "Speed: 2.9ms preprocess, 31.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "\n",
            "0: 384x640 3 persons, 33.3ms\n",
            "Speed: 4.7ms preprocess, 33.3ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "\n",
            "0: 384x640 3 persons, 34.5ms\n",
            "Speed: 3.0ms preprocess, 34.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.1ms\n",
            "Speed: 5.4ms preprocess, 31.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.1ms\n",
            "Speed: 3.1ms preprocess, 31.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "\n",
            "0: 384x640 3 persons, 47.9ms\n",
            "Speed: 2.9ms preprocess, 47.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "\n",
            "0: 384x640 3 persons, 35.1ms\n",
            "Speed: 4.9ms preprocess, 35.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "\n",
            "0: 384x640 3 persons, 38.7ms\n",
            "Speed: 3.9ms preprocess, 38.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 66ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "\n",
            "0: 384x640 3 persons, 37.8ms\n",
            "Speed: 4.8ms preprocess, 37.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "\n",
            "0: 384x640 4 persons, 31.1ms\n",
            "Speed: 3.1ms preprocess, 31.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.1ms\n",
            "Speed: 3.2ms preprocess, 31.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.1ms\n",
            "Speed: 3.5ms preprocess, 31.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.9ms\n",
            "Speed: 3.7ms preprocess, 31.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "\n",
            "0: 384x640 3 persons, 1 remote, 31.1ms\n",
            "Speed: 3.1ms preprocess, 31.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.1ms\n",
            "Speed: 3.6ms preprocess, 31.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.1ms\n",
            "Speed: 6.1ms preprocess, 31.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.1ms\n",
            "Speed: 3.3ms preprocess, 31.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "\n",
            "0: 384x640 3 persons, 1 remote, 31.0ms\n",
            "Speed: 2.9ms preprocess, 31.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "\n",
            "0: 384x640 3 persons, 1 remote, 31.1ms\n",
            "Speed: 3.0ms preprocess, 31.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "\n",
            "0: 384x640 4 persons, 31.3ms\n",
            "Speed: 5.0ms preprocess, 31.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.0ms\n",
            "Speed: 5.9ms preprocess, 31.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "\n",
            "0: 384x640 3 persons, 32.5ms\n",
            "Speed: 3.1ms preprocess, 32.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.0ms\n",
            "Speed: 5.0ms preprocess, 31.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.6ms\n",
            "Speed: 3.1ms preprocess, 31.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "\n",
            "0: 384x640 4 persons, 35.1ms\n",
            "Speed: 3.0ms preprocess, 35.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "\n",
            "0: 384x640 4 persons, 31.9ms\n",
            "Speed: 2.9ms preprocess, 31.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "\n",
            "0: 384x640 5 persons, 31.0ms\n",
            "Speed: 3.1ms preprocess, 31.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "\n",
            "0: 384x640 4 persons, 31.0ms\n",
            "Speed: 5.3ms preprocess, 31.0ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "\n",
            "0: 384x640 5 persons, 31.0ms\n",
            "Speed: 10.1ms preprocess, 31.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "\n",
            "0: 384x640 4 persons, 31.1ms\n",
            "Speed: 3.0ms preprocess, 31.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "\n",
            "0: 384x640 3 persons, 34.1ms\n",
            "Speed: 3.2ms preprocess, 34.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "\n",
            "0: 384x640 3 persons, 34.9ms\n",
            "Speed: 2.9ms preprocess, 34.9ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.6ms\n",
            "Speed: 2.9ms preprocess, 31.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 72ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.1ms\n",
            "Speed: 2.9ms preprocess, 31.1ms inference, 7.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.1ms\n",
            "Speed: 3.4ms preprocess, 31.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.4ms\n",
            "Speed: 4.8ms preprocess, 31.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "\n",
            "0: 384x640 3 persons, 36.6ms\n",
            "Speed: 3.0ms preprocess, 36.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.3ms\n",
            "Speed: 4.1ms preprocess, 31.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.1ms\n",
            "Speed: 4.4ms preprocess, 31.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "\n",
            "0: 384x640 3 persons, 1 umbrella, 31.4ms\n",
            "Speed: 3.1ms preprocess, 31.4ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "\n",
            "0: 384x640 3 persons, 33.9ms\n",
            "Speed: 3.1ms preprocess, 33.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "\n",
            "0: 384x640 3 persons, 35.5ms\n",
            "Speed: 3.0ms preprocess, 35.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "\n",
            "0: 384x640 3 persons, 1 book, 31.2ms\n",
            "Speed: 3.0ms preprocess, 31.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "\n",
            "0: 384x640 3 persons, 1 frisbee, 33.3ms\n",
            "Speed: 3.1ms preprocess, 33.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "\n",
            "0: 384x640 3 persons, 1 frisbee, 31.0ms\n",
            "Speed: 3.2ms preprocess, 31.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "\n",
            "0: 384x640 3 persons, 1 frisbee, 31.1ms\n",
            "Speed: 4.8ms preprocess, 31.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.1ms\n",
            "Speed: 3.1ms preprocess, 31.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.9ms\n",
            "Speed: 5.1ms preprocess, 31.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.1ms\n",
            "Speed: 3.0ms preprocess, 31.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.1ms\n",
            "Speed: 3.7ms preprocess, 31.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.0ms\n",
            "Speed: 3.5ms preprocess, 31.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "\n",
            "0: 384x640 3 persons, 48.4ms\n",
            "Speed: 3.2ms preprocess, 48.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.1ms\n",
            "Speed: 2.9ms preprocess, 31.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "Stream end. Exiting.\n",
            "\n",
            "0: 384x640 2 persons, 31.0ms\n",
            "Speed: 8.4ms preprocess, 31.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "\n",
            "0: 384x640 3 persons, 32.9ms\n",
            "Speed: 3.0ms preprocess, 32.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.0ms\n",
            "Speed: 3.1ms preprocess, 31.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.1ms\n",
            "Speed: 3.1ms preprocess, 31.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.1ms\n",
            "Speed: 3.7ms preprocess, 31.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "\n",
            "0: 384x640 2 persons, 32.1ms\n",
            "Speed: 3.0ms preprocess, 32.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.2ms\n",
            "Speed: 3.0ms preprocess, 31.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.1ms\n",
            "Speed: 3.2ms preprocess, 31.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.1ms\n",
            "Speed: 3.1ms preprocess, 31.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "\n",
            "0: 384x640 2 persons, 36.2ms\n",
            "Speed: 3.0ms preprocess, 36.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "\n",
            "0: 384x640 2 persons, 36.5ms\n",
            "Speed: 3.0ms preprocess, 36.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "\n",
            "0: 384x640 2 persons, 38.2ms\n",
            "Speed: 3.2ms preprocess, 38.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.8ms\n",
            "Speed: 3.0ms preprocess, 31.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "\n",
            "0: 384x640 2 persons, 33.2ms\n",
            "Speed: 2.9ms preprocess, 33.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "\n",
            "0: 384x640 2 persons, 35.9ms\n",
            "Speed: 3.6ms preprocess, 35.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "\n",
            "0: 384x640 2 persons, 33.2ms\n",
            "Speed: 7.0ms preprocess, 33.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.0ms\n",
            "Speed: 4.5ms preprocess, 31.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.1ms\n",
            "Speed: 2.9ms preprocess, 31.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "\n",
            "0: 384x640 2 persons, 37.5ms\n",
            "Speed: 3.0ms preprocess, 37.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.1ms\n",
            "Speed: 3.0ms preprocess, 31.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.0ms\n",
            "Speed: 2.8ms preprocess, 31.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.5ms\n",
            "Speed: 3.1ms preprocess, 31.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.4ms\n",
            "Speed: 3.2ms preprocess, 31.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.0ms\n",
            "Speed: 3.0ms preprocess, 31.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "\n",
            "0: 384x640 2 persons, 32.3ms\n",
            "Speed: 3.0ms preprocess, 32.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "\n",
            "0: 384x640 2 persons, 32.8ms\n",
            "Speed: 3.2ms preprocess, 32.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "\n",
            "0: 384x640 2 persons, 38.7ms\n",
            "Speed: 3.1ms preprocess, 38.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.1ms\n",
            "Speed: 7.4ms preprocess, 31.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.0ms\n",
            "Speed: 9.8ms preprocess, 31.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "\n",
            "0: 384x640 2 persons, 34.9ms\n",
            "Speed: 3.4ms preprocess, 34.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.1ms\n",
            "Speed: 10.3ms preprocess, 31.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.1ms\n",
            "Speed: 2.9ms preprocess, 31.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.2ms\n",
            "Speed: 3.1ms preprocess, 31.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.1ms\n",
            "Speed: 3.0ms preprocess, 31.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "\n",
            "0: 384x640 2 persons, 36.1ms\n",
            "Speed: 3.1ms preprocess, 36.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.1ms\n",
            "Speed: 6.3ms preprocess, 31.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.1ms\n",
            "Speed: 2.9ms preprocess, 31.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.0ms\n",
            "Speed: 3.1ms preprocess, 31.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "\n",
            "0: 384x640 2 persons, 38.5ms\n",
            "Speed: 3.1ms preprocess, 38.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.1ms\n",
            "Speed: 3.1ms preprocess, 31.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.1ms\n",
            "Speed: 4.1ms preprocess, 31.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.5ms\n",
            "Speed: 3.1ms preprocess, 31.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.1ms\n",
            "Speed: 3.2ms preprocess, 31.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "\n",
            "0: 384x640 2 persons, 33.6ms\n",
            "Speed: 3.0ms preprocess, 33.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.0ms\n",
            "Speed: 3.1ms preprocess, 31.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.9ms\n",
            "Speed: 3.3ms preprocess, 31.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.1ms\n",
            "Speed: 4.9ms preprocess, 31.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.0ms\n",
            "Speed: 4.2ms preprocess, 31.0ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "\n",
            "0: 384x640 2 persons, 37.9ms\n",
            "Speed: 3.0ms preprocess, 37.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.4ms\n",
            "Speed: 4.3ms preprocess, 31.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "\n",
            "0: 384x640 2 persons, 38.4ms\n",
            "Speed: 14.2ms preprocess, 38.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "\n",
            "0: 384x640 2 persons, 35.2ms\n",
            "Speed: 3.1ms preprocess, 35.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.1ms\n",
            "Speed: 4.9ms preprocess, 31.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "\n",
            "0: 384x640 2 persons, 33.1ms\n",
            "Speed: 2.9ms preprocess, 33.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "\n",
            "0: 384x640 2 persons, 38.8ms\n",
            "Speed: 6.1ms preprocess, 38.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "\n",
            "0: 384x640 2 persons, 32.7ms\n",
            "Speed: 6.1ms preprocess, 32.7ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.2ms\n",
            "Speed: 5.7ms preprocess, 31.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.0ms\n",
            "Speed: 3.1ms preprocess, 31.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "\n",
            "0: 384x640 3 persons, 35.1ms\n",
            "Speed: 3.3ms preprocess, 35.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.1ms\n",
            "Speed: 7.6ms preprocess, 31.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.1ms\n",
            "Speed: 3.2ms preprocess, 31.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.0ms\n",
            "Speed: 3.3ms preprocess, 31.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.1ms\n",
            "Speed: 8.1ms preprocess, 31.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "\n",
            "0: 384x640 2 persons, 33.6ms\n",
            "Speed: 3.7ms preprocess, 33.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.1ms\n",
            "Speed: 3.4ms preprocess, 31.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.1ms\n",
            "Speed: 3.1ms preprocess, 31.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "\n",
            "0: 384x640 2 persons, 1 cell phone, 31.4ms\n",
            "Speed: 3.2ms preprocess, 31.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.9ms\n",
            "Speed: 3.2ms preprocess, 31.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.1ms\n",
            "Speed: 3.3ms preprocess, 31.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.0ms\n",
            "Speed: 5.5ms preprocess, 31.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.9ms\n",
            "Speed: 3.2ms preprocess, 31.9ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.1ms\n",
            "Speed: 3.0ms preprocess, 31.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.1ms\n",
            "Speed: 4.1ms preprocess, 31.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.1ms\n",
            "Speed: 3.1ms preprocess, 31.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.1ms\n",
            "Speed: 3.3ms preprocess, 31.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.1ms\n",
            "Speed: 3.4ms preprocess, 31.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.1ms\n",
            "Speed: 3.4ms preprocess, 31.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "\n",
            "0: 384x640 2 persons, 32.0ms\n",
            "Speed: 3.9ms preprocess, 32.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "\n",
            "0: 384x640 2 persons, 32.6ms\n",
            "Speed: 3.1ms preprocess, 32.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "\n",
            "0: 384x640 2 persons, 33.1ms\n",
            "Speed: 3.0ms preprocess, 33.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "\n",
            "0: 384x640 2 persons, 34.6ms\n",
            "Speed: 3.1ms preprocess, 34.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.7ms\n",
            "Speed: 4.2ms preprocess, 31.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "\n",
            "0: 384x640 2 persons, 33.0ms\n",
            "Speed: 4.7ms preprocess, 33.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.2ms\n",
            "Speed: 3.3ms preprocess, 31.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.1ms\n",
            "Speed: 3.0ms preprocess, 31.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "\n",
            "0: 384x640 2 persons, 32.3ms\n",
            "Speed: 6.6ms preprocess, 32.3ms inference, 5.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.1ms\n",
            "Speed: 2.9ms preprocess, 31.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.7ms\n",
            "Speed: 2.8ms preprocess, 31.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.1ms\n",
            "Speed: 4.3ms preprocess, 31.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.8ms\n",
            "Speed: 2.8ms preprocess, 31.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "\n",
            "0: 384x640 2 persons, 34.7ms\n",
            "Speed: 3.1ms preprocess, 34.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "\n",
            "0: 384x640 2 persons, 40.7ms\n",
            "Speed: 3.0ms preprocess, 40.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.1ms\n",
            "Speed: 2.9ms preprocess, 31.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "\n",
            "0: 384x640 2 persons, 32.8ms\n",
            "Speed: 3.6ms preprocess, 32.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "\n",
            "0: 384x640 2 persons, 32.9ms\n",
            "Speed: 2.6ms preprocess, 32.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "\n",
            "0: 384x640 2 persons, 32.5ms\n",
            "Speed: 3.1ms preprocess, 32.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.7ms\n",
            "Speed: 3.1ms preprocess, 31.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "\n",
            "0: 384x640 3 persons, 34.5ms\n",
            "Speed: 2.8ms preprocess, 34.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.0ms\n",
            "Speed: 4.8ms preprocess, 31.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "\n",
            "0: 384x640 2 persons, 31.1ms\n",
            "Speed: 5.3ms preprocess, 31.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.0ms\n",
            "Speed: 4.1ms preprocess, 31.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.0ms\n",
            "Speed: 5.5ms preprocess, 31.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.5ms\n",
            "Speed: 3.6ms preprocess, 31.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "\n",
            "0: 384x640 3 persons, 33.2ms\n",
            "Speed: 3.1ms preprocess, 33.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.1ms\n",
            "Speed: 3.2ms preprocess, 31.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "\n",
            "0: 384x640 4 persons, 31.0ms\n",
            "Speed: 3.1ms preprocess, 31.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "\n",
            "0: 384x640 4 persons, 32.5ms\n",
            "Speed: 3.0ms preprocess, 32.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.1ms\n",
            "Speed: 3.0ms preprocess, 31.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.0ms\n",
            "Speed: 3.5ms preprocess, 31.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.1ms\n",
            "Speed: 3.0ms preprocess, 31.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "\n",
            "0: 384x640 4 persons, 35.8ms\n",
            "Speed: 3.0ms preprocess, 35.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "\n",
            "0: 384x640 4 persons, 32.5ms\n",
            "Speed: 2.9ms preprocess, 32.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "\n",
            "0: 384x640 3 persons, 33.5ms\n",
            "Speed: 2.9ms preprocess, 33.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.0ms\n",
            "Speed: 5.3ms preprocess, 31.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.1ms\n",
            "Speed: 3.1ms preprocess, 31.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.1ms\n",
            "Speed: 2.9ms preprocess, 31.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.0ms\n",
            "Speed: 2.8ms preprocess, 31.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.0ms\n",
            "Speed: 3.0ms preprocess, 31.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "\n",
            "0: 384x640 3 persons, 32.6ms\n",
            "Speed: 6.0ms preprocess, 32.6ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "\n",
            "0: 384x640 3 persons, 42.2ms\n",
            "Speed: 3.0ms preprocess, 42.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "\n",
            "0: 384x640 3 persons, 33.0ms\n",
            "Speed: 3.1ms preprocess, 33.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "\n",
            "0: 384x640 3 persons, 39.7ms\n",
            "Speed: 3.1ms preprocess, 39.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "\n",
            "0: 384x640 3 persons, 42.5ms\n",
            "Speed: 3.0ms preprocess, 42.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "\n",
            "0: 384x640 3 persons, 36.4ms\n",
            "Speed: 2.9ms preprocess, 36.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "\n",
            "0: 384x640 3 persons, 32.6ms\n",
            "Speed: 3.0ms preprocess, 32.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.0ms\n",
            "Speed: 3.7ms preprocess, 31.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.4ms\n",
            "Speed: 2.9ms preprocess, 31.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.0ms\n",
            "Speed: 3.2ms preprocess, 31.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.1ms\n",
            "Speed: 3.4ms preprocess, 31.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "\n",
            "0: 384x640 3 persons, 32.2ms\n",
            "Speed: 3.0ms preprocess, 32.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "\n",
            "0: 384x640 3 persons, 33.5ms\n",
            "Speed: 3.0ms preprocess, 33.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.0ms\n",
            "Speed: 3.0ms preprocess, 31.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "\n",
            "0: 384x640 3 persons, 32.9ms\n",
            "Speed: 3.1ms preprocess, 32.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.1ms\n",
            "Speed: 3.0ms preprocess, 31.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.0ms\n",
            "Speed: 2.9ms preprocess, 31.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.0ms\n",
            "Speed: 3.2ms preprocess, 31.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.0ms\n",
            "Speed: 6.2ms preprocess, 31.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.1ms\n",
            "Speed: 4.8ms preprocess, 31.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "\n",
            "0: 384x640 3 persons, 33.1ms\n",
            "Speed: 2.9ms preprocess, 33.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.1ms\n",
            "Speed: 7.6ms preprocess, 31.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.1ms\n",
            "Speed: 3.0ms preprocess, 31.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "\n",
            "0: 384x640 3 persons, 32.1ms\n",
            "Speed: 2.8ms preprocess, 32.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.1ms\n",
            "Speed: 4.6ms preprocess, 31.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.8ms\n",
            "Speed: 3.1ms preprocess, 31.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "\n",
            "0: 384x640 3 persons, 32.0ms\n",
            "Speed: 4.9ms preprocess, 32.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.1ms\n",
            "Speed: 3.0ms preprocess, 31.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "\n",
            "0: 384x640 3 persons, 32.4ms\n",
            "Speed: 2.9ms preprocess, 32.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.8ms\n",
            "Speed: 3.0ms preprocess, 31.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.0ms\n",
            "Speed: 2.9ms preprocess, 31.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "\n",
            "0: 384x640 3 persons, 33.3ms\n",
            "Speed: 2.9ms preprocess, 33.3ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.1ms\n",
            "Speed: 5.6ms preprocess, 31.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "\n",
            "0: 384x640 3 persons, 34.2ms\n",
            "Speed: 3.0ms preprocess, 34.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "\n",
            "0: 384x640 3 persons, 33.9ms\n",
            "Speed: 4.6ms preprocess, 33.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "\n",
            "0: 384x640 3 persons, 34.9ms\n",
            "Speed: 2.8ms preprocess, 34.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "\n",
            "0: 384x640 3 persons, 46.2ms\n",
            "Speed: 2.9ms preprocess, 46.2ms inference, 6.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "\n",
            "0: 384x640 3 persons, 57.3ms\n",
            "Speed: 3.7ms preprocess, 57.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.1ms\n",
            "Speed: 3.1ms preprocess, 31.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.1ms\n",
            "Speed: 3.0ms preprocess, 31.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.0ms\n",
            "Speed: 2.9ms preprocess, 31.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.1ms\n",
            "Speed: 2.9ms preprocess, 31.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.0ms\n",
            "Speed: 3.1ms preprocess, 31.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.1ms\n",
            "Speed: 3.1ms preprocess, 31.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "\n",
            "0: 384x640 3 persons, 36.3ms\n",
            "Speed: 3.2ms preprocess, 36.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.1ms\n",
            "Speed: 3.0ms preprocess, 31.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.0ms\n",
            "Speed: 3.1ms preprocess, 31.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.1ms\n",
            "Speed: 3.6ms preprocess, 31.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "\n",
            "0: 384x640 3 persons, 32.2ms\n",
            "Speed: 5.2ms preprocess, 32.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.0ms\n",
            "Speed: 3.2ms preprocess, 31.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.0ms\n",
            "Speed: 6.9ms preprocess, 31.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "\n",
            "0: 384x640 3 persons, 33.5ms\n",
            "Speed: 3.7ms preprocess, 33.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "\n",
            "0: 384x640 3 persons, 32.1ms\n",
            "Speed: 3.1ms preprocess, 32.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.1ms\n",
            "Speed: 5.3ms preprocess, 31.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "\n",
            "0: 384x640 3 persons, 32.1ms\n",
            "Speed: 3.1ms preprocess, 32.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "\n",
            "0: 384x640 3 persons, 38.6ms\n",
            "Speed: 4.0ms preprocess, 38.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.1ms\n",
            "Speed: 3.2ms preprocess, 31.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.0ms\n",
            "Speed: 5.0ms preprocess, 31.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "\n",
            "0: 384x640 4 persons, 31.1ms\n",
            "Speed: 3.1ms preprocess, 31.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "\n",
            "0: 384x640 4 persons, 31.0ms\n",
            "Speed: 2.8ms preprocess, 31.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "\n",
            "0: 384x640 4 persons, 37.9ms\n",
            "Speed: 3.5ms preprocess, 37.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "\n",
            "0: 384x640 4 persons, 44.8ms\n",
            "Speed: 2.8ms preprocess, 44.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "\n",
            "0: 384x640 3 persons, 38.2ms\n",
            "Speed: 3.0ms preprocess, 38.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "\n",
            "0: 384x640 4 persons, 31.3ms\n",
            "Speed: 3.0ms preprocess, 31.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "\n",
            "0: 384x640 4 persons, 31.8ms\n",
            "Speed: 4.6ms preprocess, 31.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.1ms\n",
            "Speed: 5.0ms preprocess, 31.1ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.1ms\n",
            "Speed: 6.3ms preprocess, 31.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.1ms\n",
            "Speed: 6.3ms preprocess, 31.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "\n",
            "0: 384x640 4 persons, 31.0ms\n",
            "Speed: 3.0ms preprocess, 31.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.1ms\n",
            "Speed: 5.1ms preprocess, 31.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.3ms\n",
            "Speed: 3.7ms preprocess, 31.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.0ms\n",
            "Speed: 2.9ms preprocess, 31.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.0ms\n",
            "Speed: 3.3ms preprocess, 31.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.0ms\n",
            "Speed: 3.0ms preprocess, 31.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "Stream end. Exiting.\n",
            "\n",
            "0: 384x640 3 persons, 31.1ms\n",
            "Speed: 3.2ms preprocess, 31.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.1ms\n",
            "Speed: 5.1ms preprocess, 31.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.1ms\n",
            "Speed: 3.0ms preprocess, 31.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.7ms\n",
            "Speed: 3.8ms preprocess, 31.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "\n",
            "0: 384x640 3 persons, 38.0ms\n",
            "Speed: 2.7ms preprocess, 38.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "\n",
            "0: 384x640 3 persons, 32.5ms\n",
            "Speed: 3.8ms preprocess, 32.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.1ms\n",
            "Speed: 4.6ms preprocess, 31.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "\n",
            "0: 384x640 4 persons, 31.1ms\n",
            "Speed: 3.4ms preprocess, 31.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.1ms\n",
            "Speed: 3.1ms preprocess, 31.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.1ms\n",
            "Speed: 5.1ms preprocess, 31.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.0ms\n",
            "Speed: 3.2ms preprocess, 31.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "\n",
            "0: 384x640 3 persons, 34.8ms\n",
            "Speed: 5.1ms preprocess, 34.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.1ms\n",
            "Speed: 3.3ms preprocess, 31.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "\n",
            "0: 384x640 3 persons, 38.3ms\n",
            "Speed: 3.2ms preprocess, 38.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.1ms\n",
            "Speed: 5.2ms preprocess, 31.1ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "\n",
            "0: 384x640 3 persons, 38.1ms\n",
            "Speed: 3.0ms preprocess, 38.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "\n",
            "0: 384x640 3 persons, 33.9ms\n",
            "Speed: 3.0ms preprocess, 33.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 74ms/step\n",
            "\n",
            "0: 384x640 3 persons, 32.1ms\n",
            "Speed: 3.1ms preprocess, 32.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "\n",
            "0: 384x640 3 persons, 45.1ms\n",
            "Speed: 4.8ms preprocess, 45.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "\n",
            "0: 384x640 3 persons, 32.6ms\n",
            "Speed: 3.0ms preprocess, 32.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "\n",
            "0: 384x640 3 persons, 33.1ms\n",
            "Speed: 3.0ms preprocess, 33.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "\n",
            "0: 384x640 3 persons, 34.7ms\n",
            "Speed: 3.1ms preprocess, 34.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.1ms\n",
            "Speed: 3.2ms preprocess, 31.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.1ms\n",
            "Speed: 3.3ms preprocess, 31.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "\n",
            "0: 384x640 3 persons, 35.4ms\n",
            "Speed: 3.0ms preprocess, 35.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.2ms\n",
            "Speed: 8.4ms preprocess, 31.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "\n",
            "0: 384x640 3 persons, 1 remote, 34.7ms\n",
            "Speed: 4.1ms preprocess, 34.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.0ms\n",
            "Speed: 9.9ms preprocess, 31.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.1ms\n",
            "Speed: 8.2ms preprocess, 31.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "\n",
            "0: 384x640 3 persons, 1 chair, 31.0ms\n",
            "Speed: 2.9ms preprocess, 31.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.1ms\n",
            "Speed: 5.1ms preprocess, 31.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "\n",
            "0: 384x640 3 persons, 33.8ms\n",
            "Speed: 3.1ms preprocess, 33.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.1ms\n",
            "Speed: 3.0ms preprocess, 31.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "\n",
            "0: 384x640 4 persons, 31.1ms\n",
            "Speed: 3.1ms preprocess, 31.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "\n",
            "0: 384x640 4 persons, 32.3ms\n",
            "Speed: 3.0ms preprocess, 32.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.7ms\n",
            "Speed: 3.0ms preprocess, 31.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "\n",
            "0: 384x640 3 persons, 32.1ms\n",
            "Speed: 3.1ms preprocess, 32.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "\n",
            "0: 384x640 4 persons, 35.4ms\n",
            "Speed: 3.1ms preprocess, 35.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.1ms\n",
            "Speed: 3.1ms preprocess, 31.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.0ms\n",
            "Speed: 3.0ms preprocess, 31.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.1ms\n",
            "Speed: 3.0ms preprocess, 31.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.4ms\n",
            "Speed: 4.9ms preprocess, 31.4ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "\n",
            "0: 384x640 3 persons, 43.9ms\n",
            "Speed: 2.6ms preprocess, 43.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "\n",
            "0: 384x640 3 persons, 37.1ms\n",
            "Speed: 2.9ms preprocess, 37.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "\n",
            "0: 384x640 3 persons, 36.3ms\n",
            "Speed: 6.1ms preprocess, 36.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "\n",
            "0: 384x640 3 persons, 34.0ms\n",
            "Speed: 4.6ms preprocess, 34.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "\n",
            "0: 384x640 3 persons, 44.2ms\n",
            "Speed: 13.0ms preprocess, 44.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "\n",
            "0: 384x640 3 persons, 37.7ms\n",
            "Speed: 3.1ms preprocess, 37.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.1ms\n",
            "Speed: 3.0ms preprocess, 31.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.1ms\n",
            "Speed: 3.1ms preprocess, 31.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.6ms\n",
            "Speed: 3.3ms preprocess, 31.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "\n",
            "0: 384x640 3 persons, 33.7ms\n",
            "Speed: 3.3ms preprocess, 33.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.1ms\n",
            "Speed: 4.6ms preprocess, 31.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.1ms\n",
            "Speed: 9.0ms preprocess, 31.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.1ms\n",
            "Speed: 3.1ms preprocess, 31.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.0ms\n",
            "Speed: 8.1ms preprocess, 31.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.1ms\n",
            "Speed: 3.0ms preprocess, 31.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.1ms\n",
            "Speed: 3.1ms preprocess, 31.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.1ms\n",
            "Speed: 3.2ms preprocess, 31.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "\n",
            "0: 384x640 3 persons, 32.6ms\n",
            "Speed: 4.1ms preprocess, 32.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "\n",
            "0: 384x640 3 persons, 1 chair, 31.0ms\n",
            "Speed: 4.7ms preprocess, 31.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "\n",
            "0: 384x640 3 persons, 32.7ms\n",
            "Speed: 4.7ms preprocess, 32.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.9ms\n",
            "Speed: 3.1ms preprocess, 31.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "\n",
            "0: 384x640 3 persons, 32.4ms\n",
            "Speed: 3.3ms preprocess, 32.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "\n",
            "0: 384x640 3 persons, 33.8ms\n",
            "Speed: 3.1ms preprocess, 33.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "\n",
            "0: 384x640 3 persons, 1 chair, 31.1ms\n",
            "Speed: 3.1ms preprocess, 31.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "\n",
            "0: 384x640 3 persons, 1 chair, 31.1ms\n",
            "Speed: 3.2ms preprocess, 31.1ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "\n",
            "0: 384x640 3 persons, 1 chair, 31.0ms\n",
            "Speed: 3.1ms preprocess, 31.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "\n",
            "0: 384x640 3 persons, 1 chair, 31.1ms\n",
            "Speed: 2.9ms preprocess, 31.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "\n",
            "0: 384x640 3 persons, 1 chair, 31.1ms\n",
            "Speed: 5.3ms preprocess, 31.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "\n",
            "0: 384x640 3 persons, 1 chair, 42.0ms\n",
            "Speed: 3.0ms preprocess, 42.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "\n",
            "0: 384x640 3 persons, 1 chair, 32.7ms\n",
            "Speed: 4.8ms preprocess, 32.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "\n",
            "0: 384x640 3 persons, 1 chair, 33.5ms\n",
            "Speed: 2.9ms preprocess, 33.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "\n",
            "0: 384x640 3 persons, 1 chair, 33.3ms\n",
            "Speed: 2.9ms preprocess, 33.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "\n",
            "0: 384x640 3 persons, 1 chair, 1 cell phone, 32.0ms\n",
            "Speed: 3.5ms preprocess, 32.0ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.8ms\n",
            "Speed: 2.9ms preprocess, 31.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "\n",
            "0: 384x640 3 persons, 1 chair, 34.4ms\n",
            "Speed: 3.3ms preprocess, 34.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.1ms\n",
            "Speed: 3.1ms preprocess, 31.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "\n",
            "0: 384x640 3 persons, 37.1ms\n",
            "Speed: 3.1ms preprocess, 37.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.0ms\n",
            "Speed: 4.8ms preprocess, 31.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.0ms\n",
            "Speed: 4.0ms preprocess, 31.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.0ms\n",
            "Speed: 3.2ms preprocess, 31.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "\n",
            "0: 384x640 3 persons, 36.1ms\n",
            "Speed: 2.9ms preprocess, 36.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "\n",
            "0: 384x640 3 persons, 1 chair, 31.1ms\n",
            "Speed: 3.6ms preprocess, 31.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.1ms\n",
            "Speed: 3.1ms preprocess, 31.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "\n",
            "0: 384x640 3 persons, 1 chair, 1 cell phone, 31.1ms\n",
            "Speed: 2.8ms preprocess, 31.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "\n",
            "0: 384x640 3 persons, 1 chair, 31.1ms\n",
            "Speed: 10.1ms preprocess, 31.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "\n",
            "0: 384x640 3 persons, 1 chair, 31.0ms\n",
            "Speed: 8.0ms preprocess, 31.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "\n",
            "0: 384x640 3 persons, 1 chair, 31.1ms\n",
            "Speed: 2.9ms preprocess, 31.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "\n",
            "0: 384x640 3 persons, 1 chair, 31.7ms\n",
            "Speed: 2.9ms preprocess, 31.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "\n",
            "0: 384x640 3 persons, 37.5ms\n",
            "Speed: 3.2ms preprocess, 37.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "\n",
            "0: 384x640 3 persons, 33.2ms\n",
            "Speed: 4.3ms preprocess, 33.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "\n",
            "0: 384x640 3 persons, 33.7ms\n",
            "Speed: 3.4ms preprocess, 33.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.1ms\n",
            "Speed: 3.3ms preprocess, 31.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.1ms\n",
            "Speed: 2.6ms preprocess, 31.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.1ms\n",
            "Speed: 5.4ms preprocess, 31.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.6ms\n",
            "Speed: 3.1ms preprocess, 31.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.1ms\n",
            "Speed: 2.9ms preprocess, 31.1ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "\n",
            "0: 384x640 3 persons, 33.1ms\n",
            "Speed: 3.0ms preprocess, 33.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "\n",
            "0: 384x640 3 persons, 32.2ms\n",
            "Speed: 3.0ms preprocess, 32.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "\n",
            "0: 384x640 3 persons, 33.8ms\n",
            "Speed: 3.0ms preprocess, 33.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "\n",
            "0: 384x640 4 persons, 31.0ms\n",
            "Speed: 8.0ms preprocess, 31.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "\n",
            "0: 384x640 4 persons, 31.5ms\n",
            "Speed: 3.8ms preprocess, 31.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "\n",
            "0: 384x640 3 persons, 39.0ms\n",
            "Speed: 2.9ms preprocess, 39.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "\n",
            "0: 384x640 3 persons, 34.3ms\n",
            "Speed: 3.0ms preprocess, 34.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.8ms\n",
            "Speed: 2.9ms preprocess, 31.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "\n",
            "0: 384x640 3 persons, 35.6ms\n",
            "Speed: 3.1ms preprocess, 35.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "\n",
            "0: 384x640 3 persons, 32.8ms\n",
            "Speed: 3.0ms preprocess, 32.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.1ms\n",
            "Speed: 3.1ms preprocess, 31.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "\n",
            "0: 384x640 3 persons, 33.7ms\n",
            "Speed: 3.7ms preprocess, 33.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.1ms\n",
            "Speed: 3.3ms preprocess, 31.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.1ms\n",
            "Speed: 9.1ms preprocess, 31.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.3ms\n",
            "Speed: 3.1ms preprocess, 31.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.0ms\n",
            "Speed: 3.1ms preprocess, 31.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.1ms\n",
            "Speed: 5.0ms preprocess, 31.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "\n",
            "0: 384x640 3 persons, 34.3ms\n",
            "Speed: 3.0ms preprocess, 34.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.0ms\n",
            "Speed: 3.0ms preprocess, 31.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.1ms\n",
            "Speed: 3.2ms preprocess, 31.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "\n",
            "0: 384x640 3 persons, 31.1ms\n",
            "Speed: 3.1ms preprocess, 31.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "Stream end. Exiting.\n"
          ]
        }
      ],
      "source": [
        "#directory_root = '/content/drive/MyDrive/Dataset_Violence_Video/violence-detection-dataset/'\n",
        "directory_root = '/content/Dataset_Violence_Video/violence-detection-dataset/'\n",
        "\n",
        "df_violence_results = pd.DataFrame(columns=['video_name','label', 'camera', 'violence_prediction', 'has_female', 'violence_detected'])\n",
        "\n",
        "predictions_results = []\n",
        "\n",
        "for label, cam, vid in video_files_list:\n",
        "\n",
        "    video_cap = cv2.VideoCapture(directory_root+f'{label}/{cam}/{vid}')\n",
        "\n",
        "    violence_count = 0\n",
        "    female_number = 0\n",
        "    max_people_on_screen = 0\n",
        "    frame_count = 0\n",
        "    people_on_screen = []\n",
        "\n",
        "    while video_cap.isOpened():\n",
        "        ret, frame = video_cap.read()\n",
        "\n",
        "        if not ret:\n",
        "          print(\"Stream end. Exiting.\")\n",
        "          break\n",
        "\n",
        "        crop, bounding_boxes = detect_humans(net, frame)\n",
        "\n",
        "        resized = list(map(resize, crop))\n",
        "        predictions_gender = predict_gender(resized)\n",
        "\n",
        "        resized = tf.image.resize(frame, (120,160), tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
        "        resized_cast = tf.cast(resized, tf.float32)\n",
        "        prediction_violence = predict_violence(resized_cast)\n",
        "\n",
        "        if(prediction_violence[0][1] > prediction_violence[0][0]):\n",
        "          violence_count += 1\n",
        "\n",
        "        for pred in predictions_gender:\n",
        "            if(pred[0][0] < pred[0][1]):\n",
        "                female_number += 1\n",
        "\n",
        "        people_on_screen.append(len(bounding_boxes))\n",
        "        frame_count += 1\n",
        "\n",
        "    max_people_on_screen = np.argmax(np.bincount(people_on_screen))\n",
        "    has_female = (female_number/max_people_on_screen) > (frame_count/2)\n",
        "    violence_detected = violence_count > 10\n",
        "    #1 = violence; 0 = non-violence\n",
        "    classification = 1 if violence_detected and has_female else 0\n",
        "\n",
        "    predictions_results.append(pd.Series([vid, label, cam[-1], classification, has_female, violence_detected], index=df_violence_results.columns))\n",
        "\n",
        "    video_cap.release()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ug-dy7ma-7m8"
      },
      "outputs": [],
      "source": [
        "result_dataframe = pd.concat(predictions_results,axis=1).T\n",
        "\n",
        "result_saving_path = '/content/vgg(V)_vgg(G).csv'\n",
        "result_dataframe.to_csv(result_saving_path,index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "VAr7KPDILc6P",
        "outputId": "dde291bd-ae52-4963-a01e-97a5ef869aa4"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_f1e85f06-547b-4d1a-accf-0b88d775f9fc\", \"vgg(V)_vgg(G).csv\", 11045)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.download(result_saving_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AHrOUoIICxXE",
        "outputId": "e8aa09a7-c5ec-4908-9b0a-0de91c8b8f5b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 350 entries, 0 to 349\n",
            "Data columns (total 6 columns):\n",
            " #   Column               Non-Null Count  Dtype \n",
            "---  ------               --------------  ----- \n",
            " 0   video_name           350 non-null    object\n",
            " 1   label                350 non-null    object\n",
            " 2   camera               350 non-null    object\n",
            " 3   violence_prediction  350 non-null    object\n",
            " 4   has_female           350 non-null    object\n",
            " 5   violence_detected    350 non-null    object\n",
            "dtypes: object(6)\n",
            "memory usage: 16.5+ KB\n"
          ]
        }
      ],
      "source": [
        "result_dataframe.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "mg83atxtf07y",
        "outputId": "1cfaf154-9ea2-4b8f-da3d-c59a15a23393"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"result_dataframe\",\n  \"rows\": 350,\n  \"fields\": [\n    {\n      \"column\": \"video_name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 115,\n        \"samples\": [\n          \"3.mp4\",\n          \"85.mp4\",\n          \"76.mp4\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"non-violent\",\n          \"violent\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"camera\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"1\",\n          \"2\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"violence_prediction\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"has_female\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"True\",\n          \"False\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"violence_detected\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          false,\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "result_dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-c3f619d7-ba7d-4c90-a3fa-7e28eb80a7f9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>video_name</th>\n",
              "      <th>label</th>\n",
              "      <th>camera</th>\n",
              "      <th>violence_prediction</th>\n",
              "      <th>has_female</th>\n",
              "      <th>violence_detected</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>98.mp4</td>\n",
              "      <td>violent</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>79.mp4</td>\n",
              "      <td>violent</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>34.mp4</td>\n",
              "      <td>violent</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>102.mp4</td>\n",
              "      <td>violent</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>85.mp4</td>\n",
              "      <td>violent</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c3f619d7-ba7d-4c90-a3fa-7e28eb80a7f9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c3f619d7-ba7d-4c90-a3fa-7e28eb80a7f9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c3f619d7-ba7d-4c90-a3fa-7e28eb80a7f9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1cfaeea3-6cbd-4aa7-8e8b-7f15dcf47cca\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1cfaeea3-6cbd-4aa7-8e8b-7f15dcf47cca')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1cfaeea3-6cbd-4aa7-8e8b-7f15dcf47cca button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "  video_name    label camera violence_prediction has_female violence_detected\n",
              "0     98.mp4  violent      2                   0      False              True\n",
              "1     79.mp4  violent      2                   0      False              True\n",
              "2     34.mp4  violent      2                   0      False              True\n",
              "3    102.mp4  violent      2                   0      False              True\n",
              "4     85.mp4  violent      2                   0      False              True"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result_dataframe.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "6a5LJnITI_0J",
        "outputId": "fa9bc6b7-4cae-4956-d5f9-a6521cbe75ca"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"result_dataframe\",\n  \"rows\": 350,\n  \"fields\": [\n    {\n      \"column\": \"video_name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 115,\n        \"samples\": [\n          \"73.mp4\",\n          \"12.mp4\",\n          \"4.mp4\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"violent\",\n          \"non-violent\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"camera\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"2\",\n          \"1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"violence_prediction\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"has_female\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"False\",\n          \"True\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"violence_detected\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          false,\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "result_dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-2dfd9308-96f0-4654-a04e-fb56005f9d67\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>video_name</th>\n",
              "      <th>label</th>\n",
              "      <th>camera</th>\n",
              "      <th>violence_prediction</th>\n",
              "      <th>has_female</th>\n",
              "      <th>violence_detected</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>53.mp4</td>\n",
              "      <td>non-violent</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>44.mp4</td>\n",
              "      <td>non-violent</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>18.mp4</td>\n",
              "      <td>non-violent</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>21.mp4</td>\n",
              "      <td>non-violent</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>12.mp4</td>\n",
              "      <td>non-violent</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2dfd9308-96f0-4654-a04e-fb56005f9d67')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2dfd9308-96f0-4654-a04e-fb56005f9d67 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2dfd9308-96f0-4654-a04e-fb56005f9d67');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-06c79666-8bea-4208-acd2-3aeb6b321e0f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-06c79666-8bea-4208-acd2-3aeb6b321e0f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-06c79666-8bea-4208-acd2-3aeb6b321e0f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "  video_name        label camera violence_prediction has_female  \\\n",
              "0     53.mp4  non-violent      1                   1       True   \n",
              "1     44.mp4  non-violent      1                   1       True   \n",
              "2     18.mp4  non-violent      1                   1       True   \n",
              "3     21.mp4  non-violent      1                   1       True   \n",
              "4     12.mp4  non-violent      1                   0      False   \n",
              "\n",
              "  violence_detected  \n",
              "0              True  \n",
              "1              True  \n",
              "2              True  \n",
              "3              True  \n",
              "4              True  "
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result_dataframe.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "KIWFyUzSt29m",
        "outputId": "0a6b10d3-a544-4245-e4c4-2d6ad8783d45"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"result_dataframe\",\n  \"rows\": 350,\n  \"fields\": [\n    {\n      \"column\": \"video_name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 115,\n        \"samples\": [\n          \"73.mp4\",\n          \"12.mp4\",\n          \"4.mp4\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"violent\",\n          \"non-violent\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"camera\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"2\",\n          \"1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"violence_prediction\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"has_female\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"True\",\n          \"False\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"violence_detected\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          false,\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "result_dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-73981fbc-0b33-4d79-8f63-0de82ebf1a8a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>video_name</th>\n",
              "      <th>label</th>\n",
              "      <th>camera</th>\n",
              "      <th>violence_prediction</th>\n",
              "      <th>has_female</th>\n",
              "      <th>violence_detected</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>53.mp4</td>\n",
              "      <td>non-violent</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>44.mp4</td>\n",
              "      <td>non-violent</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>18.mp4</td>\n",
              "      <td>non-violent</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>21.mp4</td>\n",
              "      <td>non-violent</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>12.mp4</td>\n",
              "      <td>non-violent</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-73981fbc-0b33-4d79-8f63-0de82ebf1a8a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-73981fbc-0b33-4d79-8f63-0de82ebf1a8a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-73981fbc-0b33-4d79-8f63-0de82ebf1a8a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-592a61cf-84a9-4583-9201-f5e7e725c38b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-592a61cf-84a9-4583-9201-f5e7e725c38b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-592a61cf-84a9-4583-9201-f5e7e725c38b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "  video_name        label camera violence_prediction has_female  \\\n",
              "0     53.mp4  non-violent      1                   0      False   \n",
              "1     44.mp4  non-violent      1                   0      False   \n",
              "2     18.mp4  non-violent      1                   0      False   \n",
              "3     21.mp4  non-violent      1                   0      False   \n",
              "4     12.mp4  non-violent      1                   0      False   \n",
              "\n",
              "  violence_detected  \n",
              "0              True  \n",
              "1              True  \n",
              "2              True  \n",
              "3              True  \n",
              "4              True  "
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result_dataframe.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "amfMwCS-9GXj",
        "outputId": "6c77e7ff-f910-4369-fadf-5770a6872edd"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"result_dataframe\",\n  \"rows\": 350,\n  \"fields\": [\n    {\n      \"column\": \"video_name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 115,\n        \"samples\": [\n          \"82.mp4\",\n          \"23.mp4\",\n          \"39.mp4\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"violent\",\n          \"non-violent\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"camera\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"1\",\n          \"2\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"violence_prediction\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"has_female\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"True\",\n          \"False\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"violence_detected\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          false,\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "result_dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-eb9b4c2c-dc66-4dc7-9b7d-22c308064088\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>video_name</th>\n",
              "      <th>label</th>\n",
              "      <th>camera</th>\n",
              "      <th>violence_prediction</th>\n",
              "      <th>has_female</th>\n",
              "      <th>violence_detected</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10.mp4</td>\n",
              "      <td>non-violent</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>43.mp4</td>\n",
              "      <td>non-violent</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>27.mp4</td>\n",
              "      <td>non-violent</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>44.mp4</td>\n",
              "      <td>non-violent</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>23.mp4</td>\n",
              "      <td>non-violent</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-eb9b4c2c-dc66-4dc7-9b7d-22c308064088')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-eb9b4c2c-dc66-4dc7-9b7d-22c308064088 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-eb9b4c2c-dc66-4dc7-9b7d-22c308064088');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-6bfead9a-9ba9-4480-9d93-c85b39d08daf\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6bfead9a-9ba9-4480-9d93-c85b39d08daf')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-6bfead9a-9ba9-4480-9d93-c85b39d08daf button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "  video_name        label camera violence_prediction has_female  \\\n",
              "0     10.mp4  non-violent      2                   0      False   \n",
              "1     43.mp4  non-violent      2                   1       True   \n",
              "2     27.mp4  non-violent      2                   0      False   \n",
              "3     44.mp4  non-violent      2                   1       True   \n",
              "4     23.mp4  non-violent      2                   1       True   \n",
              "\n",
              "  violence_detected  \n",
              "0              True  \n",
              "1              True  \n",
              "2              True  \n",
              "3              True  \n",
              "4              True  "
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result_dataframe.head()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
