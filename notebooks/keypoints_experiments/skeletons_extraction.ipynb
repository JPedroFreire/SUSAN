{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DFQGjgwQJ5Dk",
        "outputId": "2d626e37-77e5-41f4-a13f-58c44204935e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w1MawY-caegi",
        "outputId": "7c1815be-b885-4ef4-fe2a-2f43d88db73d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'A-Dataset-for-Automatic-Violence-Detection-in-Videos'...\n",
            "remote: Enumerating objects: 376, done.\u001b[K\n",
            "remote: Counting objects: 100% (12/12), done.\u001b[K\n",
            "remote: Compressing objects: 100% (9/9), done.\u001b[K\n",
            "remote: Total 376 (delta 3), reused 11 (delta 3), pack-reused 364 (from 1)\u001b[K\n",
            "Receiving objects: 100% (376/376), 1.02 GiB | 23.39 MiB/s, done.\n",
            "Resolving deltas: 100% (3/3), done.\n",
            "Updating files: 100% (355/355), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/airtlab/A-Dataset-for-Automatic-Violence-Detection-in-Videos.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJ7Pb-vmKp5V",
        "outputId": "42b0c416-53e7-41a1-e197-4c136f7dab51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.199-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (4.12.0.88)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (11.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.32.4)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.16.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (0.23.0+cu126)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: polars in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.25.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.17-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.59.2)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2025.8.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Downloading ultralytics-8.3.199-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.17-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: ultralytics-thop, ultralytics\n",
            "Successfully installed ultralytics-8.3.199 ultralytics-thop-2.0.17\n"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTeFahDTAARr"
      },
      "source": [
        "# Keypoints Extractions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CUKusWOSihMl",
        "outputId": "d71d1743-f8ec-4c6b-bd77-8927e8bb5c17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from ultralytics import YOLO\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PLZnWjjVFkuV"
      },
      "outputs": [],
      "source": [
        "def get_data_files(folder_path):\n",
        "    video_files = []\n",
        "\n",
        "    for root, dirs, files in os.walk(folder_path):\n",
        "        subfolder_list = root.split(os.path.sep)\n",
        "        v_nv = subfolder_list[-2]\n",
        "        c1_c2 = subfolder_list[-1]\n",
        "\n",
        "        video_files.extend([(v_nv, c1_c2, file) for file in files if file.lower().endswith(('.mp4', '.jpg'))])\n",
        "\n",
        "    return video_files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iaaCqmUqHxA4"
      },
      "source": [
        "## Full Videos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nvBZoUdxIKzo"
      },
      "outputs": [],
      "source": [
        "folder_path = '/content/A-Dataset-for-Automatic-Violence-Detection-in-Videos/violence-detection-dataset'\n",
        "\n",
        "video_files_list = get_data_files(folder_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "VfeimlQZKzHI",
        "outputId": "91977849-ab2f-49a8-e32a-e07769a3581f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Speed: 3.4ms preprocess, 12.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12.1ms\n",
            "Speed: 5.6ms preprocess, 12.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.3ms\n",
            "Speed: 3.7ms preprocess, 10.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.4ms\n",
            "Speed: 3.3ms preprocess, 11.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.1ms\n",
            "Speed: 2.6ms preprocess, 10.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.4ms\n",
            "Speed: 2.6ms preprocess, 10.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12.7ms\n",
            "Speed: 2.4ms preprocess, 12.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 13.2ms\n",
            "Speed: 2.6ms preprocess, 13.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.6ms\n",
            "Speed: 3.2ms preprocess, 11.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.4ms\n",
            "Speed: 3.2ms preprocess, 10.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.6ms\n",
            "Speed: 3.1ms preprocess, 10.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 13.7ms\n",
            "Speed: 3.2ms preprocess, 13.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.4ms\n",
            "Speed: 6.9ms preprocess, 10.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.0ms\n",
            "Speed: 4.2ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.0ms\n",
            "Speed: 3.2ms preprocess, 11.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 17.3ms\n",
            "Speed: 3.2ms preprocess, 17.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.3ms\n",
            "Speed: 4.1ms preprocess, 10.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.5ms\n",
            "Speed: 3.6ms preprocess, 11.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.7ms\n",
            "Speed: 3.6ms preprocess, 10.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 18.6ms\n",
            "Speed: 3.2ms preprocess, 18.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.8ms\n",
            "Speed: 6.4ms preprocess, 11.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 9.6ms\n",
            "Speed: 3.3ms preprocess, 9.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 14.1ms\n",
            "Speed: 3.0ms preprocess, 14.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 9.5ms\n",
            "Speed: 3.9ms preprocess, 9.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.4ms\n",
            "Speed: 3.1ms preprocess, 11.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 16.8ms\n",
            "Speed: 3.1ms preprocess, 16.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 18.4ms\n",
            "Speed: 4.1ms preprocess, 18.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.3ms\n",
            "Speed: 7.7ms preprocess, 10.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 9.8ms\n",
            "Speed: 3.2ms preprocess, 9.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.2ms\n",
            "Speed: 3.0ms preprocess, 11.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.0ms\n",
            "Speed: 3.1ms preprocess, 10.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.8ms\n",
            "Speed: 10.2ms preprocess, 10.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.9ms\n",
            "Speed: 3.0ms preprocess, 10.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 13.0ms\n",
            "Speed: 2.9ms preprocess, 13.0ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12.2ms\n",
            "Speed: 6.8ms preprocess, 12.2ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.9ms\n",
            "Speed: 3.0ms preprocess, 10.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.2ms\n",
            "Speed: 3.2ms preprocess, 11.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.9ms\n",
            "Speed: 3.1ms preprocess, 10.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.5ms\n",
            "Speed: 3.1ms preprocess, 10.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12.4ms\n",
            "Speed: 4.4ms preprocess, 12.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 9.9ms\n",
            "Speed: 3.2ms preprocess, 9.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.4ms\n",
            "Speed: 4.2ms preprocess, 10.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.5ms\n",
            "Speed: 3.1ms preprocess, 11.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12.1ms\n",
            "Speed: 4.5ms preprocess, 12.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 9.6ms\n",
            "Speed: 3.7ms preprocess, 9.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.4ms\n",
            "Speed: 3.6ms preprocess, 11.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12.3ms\n",
            "Speed: 3.0ms preprocess, 12.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 9.0ms\n",
            "Speed: 3.2ms preprocess, 9.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 13.9ms\n",
            "Speed: 2.9ms preprocess, 13.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 9.1ms\n",
            "Speed: 3.4ms preprocess, 9.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 9.7ms\n",
            "Speed: 4.0ms preprocess, 9.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.0ms\n",
            "Speed: 3.2ms preprocess, 11.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 20.0ms\n",
            "Speed: 3.7ms preprocess, 20.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12.1ms\n",
            "Speed: 3.3ms preprocess, 12.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.4ms\n",
            "Speed: 3.1ms preprocess, 10.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.2ms\n",
            "Speed: 3.4ms preprocess, 10.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 13.3ms\n",
            "Speed: 3.1ms preprocess, 13.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.3ms\n",
            "Speed: 3.2ms preprocess, 10.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 9.8ms\n",
            "Speed: 3.2ms preprocess, 9.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.4ms\n",
            "Speed: 3.2ms preprocess, 10.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 25.1ms\n",
            "Speed: 3.2ms preprocess, 25.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.8ms\n",
            "Speed: 2.6ms preprocess, 11.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.7ms\n",
            "Speed: 4.0ms preprocess, 11.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.9ms\n",
            "Speed: 3.3ms preprocess, 10.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 9.8ms\n",
            "Speed: 8.4ms preprocess, 9.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 9.9ms\n",
            "Speed: 3.3ms preprocess, 9.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.4ms\n",
            "Speed: 3.0ms preprocess, 10.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.3ms\n",
            "Speed: 3.8ms preprocess, 11.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 14.4ms\n",
            "Speed: 3.2ms preprocess, 14.4ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.8ms\n",
            "Speed: 2.8ms preprocess, 10.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 13.8ms\n",
            "Speed: 4.5ms preprocess, 13.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.8ms\n",
            "Speed: 3.1ms preprocess, 11.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 14.9ms\n",
            "Speed: 2.8ms preprocess, 14.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.0ms\n",
            "Speed: 3.1ms preprocess, 10.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 9.0ms\n",
            "Speed: 3.3ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 8.9ms\n",
            "Speed: 3.1ms preprocess, 8.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 16.8ms\n",
            "Speed: 3.2ms preprocess, 16.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.4ms\n",
            "Speed: 3.0ms preprocess, 11.4ms inference, 8.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 9.9ms\n",
            "Speed: 2.7ms preprocess, 9.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 8.9ms\n",
            "Speed: 2.9ms preprocess, 8.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 7.5ms\n",
            "Speed: 3.2ms preprocess, 7.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 8.9ms\n",
            "Speed: 3.0ms preprocess, 8.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 9.6ms\n",
            "Speed: 4.9ms preprocess, 9.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.0ms\n",
            "Speed: 3.0ms preprocess, 10.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 17.4ms\n",
            "Speed: 3.1ms preprocess, 17.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.2ms\n",
            "Speed: 3.3ms preprocess, 11.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.8ms\n",
            "Speed: 3.5ms preprocess, 10.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.6ms\n",
            "Speed: 4.0ms preprocess, 10.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 13.6ms\n",
            "Speed: 3.9ms preprocess, 13.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.7ms\n",
            "Speed: 5.6ms preprocess, 10.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 13.3ms\n",
            "Speed: 3.0ms preprocess, 13.3ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12.1ms\n",
            "Speed: 3.0ms preprocess, 12.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 8.2ms\n",
            "Speed: 3.2ms preprocess, 8.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 9.9ms\n",
            "Speed: 3.1ms preprocess, 9.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.1ms\n",
            "Speed: 4.1ms preprocess, 11.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 15.3ms\n",
            "Speed: 3.2ms preprocess, 15.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 14.3ms\n",
            "Speed: 5.1ms preprocess, 14.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.9ms\n",
            "Speed: 3.0ms preprocess, 11.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.0ms\n",
            "Speed: 3.4ms preprocess, 10.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.9ms\n",
            "Speed: 3.3ms preprocess, 10.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.3ms\n",
            "Speed: 3.6ms preprocess, 11.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 9.6ms\n",
            "Speed: 3.0ms preprocess, 9.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.8ms\n",
            "Speed: 8.6ms preprocess, 10.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.1ms\n",
            "Speed: 3.2ms preprocess, 11.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 13.1ms\n",
            "Speed: 3.3ms preprocess, 13.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.0ms\n",
            "Speed: 4.4ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.5ms\n",
            "Speed: 3.3ms preprocess, 11.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 9.8ms\n",
            "Speed: 3.2ms preprocess, 9.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 14.5ms\n",
            "Speed: 3.4ms preprocess, 14.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12.3ms\n",
            "Speed: 3.2ms preprocess, 12.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.3ms\n",
            "Speed: 3.1ms preprocess, 10.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.8ms\n",
            "Speed: 4.7ms preprocess, 10.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 15.8ms\n",
            "Speed: 3.5ms preprocess, 15.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.2ms\n",
            "Speed: 3.5ms preprocess, 10.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 9.4ms\n",
            "Speed: 3.1ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.4ms\n",
            "Speed: 3.1ms preprocess, 11.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 9.7ms\n",
            "Speed: 3.3ms preprocess, 9.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.6ms\n",
            "Speed: 3.0ms preprocess, 10.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 16.0ms\n",
            "Speed: 3.2ms preprocess, 16.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 8.8ms\n",
            "Speed: 3.4ms preprocess, 8.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 9.9ms\n",
            "Speed: 2.8ms preprocess, 9.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 9.2ms\n",
            "Speed: 3.3ms preprocess, 9.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.1ms\n",
            "Speed: 3.1ms preprocess, 11.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.1ms\n",
            "Speed: 3.0ms preprocess, 11.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.2ms\n",
            "Speed: 2.6ms preprocess, 10.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12.4ms\n",
            "Speed: 3.3ms preprocess, 12.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.2ms\n",
            "Speed: 4.6ms preprocess, 10.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 13.0ms\n",
            "Speed: 3.3ms preprocess, 13.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 8.8ms\n",
            "Speed: 3.2ms preprocess, 8.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12.5ms\n",
            "Speed: 3.3ms preprocess, 12.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 8.3ms\n",
            "Speed: 3.2ms preprocess, 8.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 14.3ms\n",
            "Speed: 3.3ms preprocess, 14.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 17.2ms\n",
            "Speed: 3.0ms preprocess, 17.2ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.1ms\n",
            "Speed: 2.6ms preprocess, 11.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12.3ms\n",
            "Speed: 3.0ms preprocess, 12.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9.7ms\n",
            "Speed: 3.0ms preprocess, 9.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.3ms\n",
            "Speed: 3.0ms preprocess, 10.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9.5ms\n",
            "Speed: 3.2ms preprocess, 9.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 13.2ms\n",
            "Speed: 3.5ms preprocess, 13.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 8.5ms\n",
            "Speed: 3.2ms preprocess, 8.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.7ms\n",
            "Speed: 3.2ms preprocess, 11.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.3ms\n",
            "Speed: 3.1ms preprocess, 10.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.5ms\n",
            "Speed: 3.0ms preprocess, 10.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9.6ms\n",
            "Speed: 3.2ms preprocess, 9.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.1ms\n",
            "Speed: 3.0ms preprocess, 11.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.1ms\n",
            "Speed: 3.1ms preprocess, 11.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.8ms\n",
            "Speed: 3.3ms preprocess, 11.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9.8ms\n",
            "Speed: 4.3ms preprocess, 9.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.6ms\n",
            "Speed: 3.1ms preprocess, 11.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.3ms\n",
            "Speed: 3.2ms preprocess, 11.3ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.4ms\n",
            "Speed: 3.2ms preprocess, 10.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.1ms\n",
            "Speed: 3.1ms preprocess, 11.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 15.7ms\n",
            "Speed: 3.1ms preprocess, 15.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.4ms\n",
            "Speed: 3.1ms preprocess, 10.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.6ms\n",
            "Speed: 2.3ms preprocess, 11.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.4ms\n",
            "Speed: 4.4ms preprocess, 10.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.6ms\n",
            "Speed: 3.0ms preprocess, 10.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.3ms\n",
            "Speed: 3.2ms preprocess, 10.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.5ms\n",
            "Speed: 3.3ms preprocess, 11.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12.4ms\n",
            "Speed: 3.3ms preprocess, 12.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.6ms\n",
            "Speed: 5.3ms preprocess, 10.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9.8ms\n",
            "Speed: 4.1ms preprocess, 9.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.3ms\n",
            "Speed: 2.9ms preprocess, 10.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.0ms\n",
            "Speed: 4.1ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.3ms\n",
            "Speed: 3.4ms preprocess, 10.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.6ms\n",
            "Speed: 3.1ms preprocess, 10.6ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.6ms\n",
            "Speed: 3.2ms preprocess, 10.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 13.7ms\n",
            "Speed: 3.6ms preprocess, 13.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12.2ms\n",
            "Speed: 3.3ms preprocess, 12.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 13.0ms\n",
            "Speed: 3.1ms preprocess, 13.0ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.2ms\n",
            "Speed: 3.1ms preprocess, 11.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 15.5ms\n",
            "Speed: 3.2ms preprocess, 15.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.2ms\n",
            "Speed: 3.1ms preprocess, 10.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.9ms\n",
            "Speed: 3.2ms preprocess, 11.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 17.5ms\n",
            "Speed: 3.2ms preprocess, 17.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.0ms\n",
            "Speed: 5.5ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 8.1ms\n",
            "Speed: 3.3ms preprocess, 8.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 7.4ms\n",
            "Speed: 3.1ms preprocess, 7.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9.4ms\n",
            "Speed: 3.1ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9.2ms\n",
            "Speed: 8.6ms preprocess, 9.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.9ms\n",
            "Speed: 3.0ms preprocess, 10.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.5ms\n",
            "Speed: 3.1ms preprocess, 11.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 12.2ms\n",
            "Speed: 3.1ms preprocess, 12.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 8.7ms\n",
            "Speed: 3.2ms preprocess, 8.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12.0ms\n",
            "Speed: 7.5ms preprocess, 12.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.9ms\n",
            "Speed: 3.0ms preprocess, 10.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.5ms\n",
            "Speed: 2.9ms preprocess, 10.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 13.8ms\n",
            "Speed: 3.1ms preprocess, 13.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12.8ms\n",
            "Speed: 3.0ms preprocess, 12.8ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 14.5ms\n",
            "Speed: 3.3ms preprocess, 14.5ms inference, 6.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.8ms\n",
            "Speed: 3.1ms preprocess, 10.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12.2ms\n",
            "Speed: 3.0ms preprocess, 12.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.5ms\n",
            "Speed: 3.3ms preprocess, 11.5ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 16.4ms\n",
            "Speed: 3.8ms preprocess, 16.4ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 33.6ms\n",
            "Speed: 3.1ms preprocess, 33.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 19.1ms\n",
            "Speed: 5.3ms preprocess, 19.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 12.4ms\n",
            "Speed: 3.5ms preprocess, 12.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 16.2ms\n",
            "Speed: 3.1ms preprocess, 16.2ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 21.3ms\n",
            "Speed: 7.8ms preprocess, 21.3ms inference, 7.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 39.0ms\n",
            "Speed: 5.1ms preprocess, 39.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 23.6ms\n",
            "Speed: 9.9ms preprocess, 23.6ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 15.4ms\n",
            "Speed: 4.5ms preprocess, 15.4ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 14.9ms\n",
            "Speed: 5.0ms preprocess, 14.9ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 25.3ms\n",
            "Speed: 15.0ms preprocess, 25.3ms inference, 9.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 28.0ms\n",
            "Speed: 3.2ms preprocess, 28.0ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.4ms\n",
            "Speed: 3.3ms preprocess, 10.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.9ms\n",
            "Speed: 2.9ms preprocess, 10.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.4ms\n",
            "Speed: 4.0ms preprocess, 10.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 7.6ms\n",
            "Speed: 3.3ms preprocess, 7.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.3ms\n",
            "Speed: 3.1ms preprocess, 10.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 8.0ms\n",
            "Speed: 3.1ms preprocess, 8.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.5ms\n",
            "Speed: 3.4ms preprocess, 11.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 7.8ms\n",
            "Speed: 3.6ms preprocess, 7.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.7ms\n",
            "Speed: 3.1ms preprocess, 11.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9.7ms\n",
            "Speed: 3.4ms preprocess, 9.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 14.4ms\n",
            "Speed: 3.1ms preprocess, 14.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 9.9ms\n",
            "Speed: 3.2ms preprocess, 9.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.0ms\n",
            "Speed: 3.1ms preprocess, 10.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 8.6ms\n",
            "Speed: 3.0ms preprocess, 8.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.1ms\n",
            "Speed: 4.3ms preprocess, 11.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.4ms\n",
            "Speed: 3.8ms preprocess, 10.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.1ms\n",
            "Speed: 4.0ms preprocess, 10.1ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.2ms\n",
            "Speed: 3.9ms preprocess, 10.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.9ms\n",
            "Speed: 2.4ms preprocess, 10.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 13.8ms\n",
            "Speed: 6.8ms preprocess, 13.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 8.9ms\n",
            "Speed: 3.3ms preprocess, 8.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.0ms\n",
            "Speed: 3.3ms preprocess, 10.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.4ms\n",
            "Speed: 3.1ms preprocess, 10.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 8.4ms\n",
            "Speed: 3.9ms preprocess, 8.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 17.0ms\n",
            "Speed: 4.2ms preprocess, 17.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.9ms\n",
            "Speed: 3.2ms preprocess, 10.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.0ms\n",
            "Speed: 2.7ms preprocess, 10.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.1ms\n",
            "Speed: 3.4ms preprocess, 10.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 18.5ms\n",
            "Speed: 5.6ms preprocess, 18.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.0ms\n",
            "Speed: 3.3ms preprocess, 10.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9.7ms\n",
            "Speed: 3.2ms preprocess, 9.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 8.7ms\n",
            "Speed: 3.3ms preprocess, 8.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 8.4ms\n",
            "Speed: 3.3ms preprocess, 8.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9.6ms\n",
            "Speed: 3.2ms preprocess, 9.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 8.4ms\n",
            "Speed: 3.2ms preprocess, 8.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 17.1ms\n",
            "Speed: 3.6ms preprocess, 17.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.6ms\n",
            "Speed: 4.1ms preprocess, 10.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.8ms\n",
            "Speed: 3.6ms preprocess, 10.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9.0ms\n",
            "Speed: 3.2ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 13.2ms\n",
            "Speed: 3.1ms preprocess, 13.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 9.3ms\n",
            "Speed: 3.3ms preprocess, 9.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.2ms\n",
            "Speed: 3.2ms preprocess, 10.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9.6ms\n",
            "Speed: 3.9ms preprocess, 9.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.4ms\n",
            "Speed: 3.6ms preprocess, 11.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.6ms\n",
            "Speed: 3.2ms preprocess, 10.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.4ms\n",
            "Speed: 3.3ms preprocess, 11.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.5ms\n",
            "Speed: 3.0ms preprocess, 10.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 9.8ms\n",
            "Speed: 3.3ms preprocess, 9.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12.7ms\n",
            "Speed: 3.1ms preprocess, 12.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 9.8ms\n",
            "Speed: 4.8ms preprocess, 9.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 15.9ms\n",
            "Speed: 3.1ms preprocess, 15.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 14.2ms\n",
            "Speed: 3.1ms preprocess, 14.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.8ms\n",
            "Speed: 2.6ms preprocess, 11.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 17.9ms\n",
            "Speed: 3.8ms preprocess, 17.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.2ms\n",
            "Speed: 3.0ms preprocess, 11.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 14.1ms\n",
            "Speed: 3.1ms preprocess, 14.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 9.6ms\n",
            "Speed: 3.1ms preprocess, 9.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 9.8ms\n",
            "Speed: 3.3ms preprocess, 9.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 14.1ms\n",
            "Speed: 5.2ms preprocess, 14.1ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 15.4ms\n",
            "Speed: 5.2ms preprocess, 15.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 9.9ms\n",
            "Speed: 5.2ms preprocess, 9.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 9.1ms\n",
            "Speed: 3.0ms preprocess, 9.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 16.4ms\n",
            "Speed: 3.0ms preprocess, 16.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 13.9ms\n",
            "Speed: 3.0ms preprocess, 13.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.1ms\n",
            "Speed: 3.0ms preprocess, 10.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 9.2ms\n",
            "Speed: 2.5ms preprocess, 9.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12.2ms\n",
            "Speed: 3.2ms preprocess, 12.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.8ms\n",
            "Speed: 3.1ms preprocess, 10.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.1ms\n",
            "Speed: 3.3ms preprocess, 11.1ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.6ms\n",
            "Speed: 4.5ms preprocess, 11.6ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 17.0ms\n",
            "Speed: 3.2ms preprocess, 17.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9.7ms\n",
            "Speed: 3.1ms preprocess, 9.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 13.2ms\n",
            "Speed: 3.1ms preprocess, 13.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 13.1ms\n",
            "Speed: 3.1ms preprocess, 13.1ms inference, 5.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 18.9ms\n",
            "Speed: 3.0ms preprocess, 18.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 15.5ms\n",
            "Speed: 3.1ms preprocess, 15.5ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9.8ms\n",
            "Speed: 3.3ms preprocess, 9.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 13.6ms\n",
            "Speed: 3.1ms preprocess, 13.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 14.5ms\n",
            "Speed: 3.3ms preprocess, 14.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 9.8ms\n",
            "Speed: 3.2ms preprocess, 9.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 17.9ms\n",
            "Speed: 3.2ms preprocess, 17.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.4ms\n",
            "Speed: 3.1ms preprocess, 10.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 16.5ms\n",
            "Speed: 2.9ms preprocess, 16.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12.1ms\n",
            "Speed: 3.1ms preprocess, 12.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.6ms\n",
            "Speed: 8.8ms preprocess, 11.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 9.6ms\n",
            "Speed: 2.7ms preprocess, 9.6ms inference, 6.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 15.3ms\n",
            "Speed: 3.0ms preprocess, 15.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 15.1ms\n",
            "Speed: 3.2ms preprocess, 15.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 17.4ms\n",
            "Speed: 3.1ms preprocess, 17.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 14.2ms\n",
            "Speed: 3.1ms preprocess, 14.2ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 22.4ms\n",
            "Speed: 3.3ms preprocess, 22.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.9ms\n",
            "Speed: 3.1ms preprocess, 10.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.7ms\n",
            "Speed: 3.1ms preprocess, 11.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 14.1ms\n",
            "Speed: 3.1ms preprocess, 14.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 19.3ms\n",
            "Speed: 3.2ms preprocess, 19.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 15.0ms\n",
            "Speed: 3.2ms preprocess, 15.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.1ms\n",
            "Speed: 3.0ms preprocess, 10.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 17.6ms\n",
            "Speed: 3.0ms preprocess, 17.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12.5ms\n",
            "Speed: 3.1ms preprocess, 12.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 13.3ms\n",
            "Speed: 3.0ms preprocess, 13.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 28.9ms\n",
            "Speed: 3.0ms preprocess, 28.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 19.3ms\n",
            "Speed: 3.0ms preprocess, 19.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 19.3ms\n",
            "Speed: 3.1ms preprocess, 19.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 17.9ms\n",
            "Speed: 3.2ms preprocess, 17.9ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 18.1ms\n",
            "Speed: 2.8ms preprocess, 18.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.9ms\n",
            "Speed: 3.7ms preprocess, 11.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.6ms\n",
            "Speed: 3.0ms preprocess, 11.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.8ms\n",
            "Speed: 5.3ms preprocess, 11.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 8.7ms\n",
            "Speed: 4.3ms preprocess, 8.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 9.9ms\n",
            "Speed: 4.9ms preprocess, 9.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 15.8ms\n",
            "Speed: 2.8ms preprocess, 15.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 15.3ms\n",
            "Speed: 3.1ms preprocess, 15.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 13.3ms\n",
            "Speed: 3.1ms preprocess, 13.3ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 13.6ms\n",
            "Speed: 4.5ms preprocess, 13.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12.1ms\n",
            "Speed: 3.0ms preprocess, 12.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.7ms\n",
            "Speed: 3.2ms preprocess, 10.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.4ms\n",
            "Speed: 3.1ms preprocess, 10.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 20.6ms\n",
            "Speed: 7.8ms preprocess, 20.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 18.7ms\n",
            "Speed: 3.3ms preprocess, 18.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 19.8ms\n",
            "Speed: 6.1ms preprocess, 19.8ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 14.4ms\n",
            "Speed: 2.9ms preprocess, 14.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12.7ms\n",
            "Speed: 3.2ms preprocess, 12.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 20.0ms\n",
            "Speed: 3.0ms preprocess, 20.0ms inference, 7.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 14.5ms\n",
            "Speed: 3.2ms preprocess, 14.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 15.3ms\n",
            "Speed: 3.1ms preprocess, 15.3ms inference, 6.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 16.6ms\n",
            "Speed: 3.1ms preprocess, 16.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 19.3ms\n",
            "Speed: 3.0ms preprocess, 19.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 17.6ms\n",
            "Speed: 3.1ms preprocess, 17.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 18.1ms\n",
            "Speed: 3.2ms preprocess, 18.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 14.1ms\n",
            "Speed: 3.0ms preprocess, 14.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.6ms\n",
            "Speed: 4.1ms preprocess, 10.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 20.2ms\n",
            "Speed: 3.1ms preprocess, 20.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12.1ms\n",
            "Speed: 4.2ms preprocess, 12.1ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 13.6ms\n",
            "Speed: 3.3ms preprocess, 13.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 16.3ms\n",
            "Speed: 3.1ms preprocess, 16.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 15.0ms\n",
            "Speed: 3.2ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 16.6ms\n",
            "Speed: 5.6ms preprocess, 16.6ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.4ms\n",
            "Speed: 3.3ms preprocess, 10.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 17.0ms\n",
            "Speed: 3.4ms preprocess, 17.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 17.0ms\n",
            "Speed: 4.3ms preprocess, 17.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 13.8ms\n",
            "Speed: 2.9ms preprocess, 13.8ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.1ms\n",
            "Speed: 3.1ms preprocess, 11.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12.0ms\n",
            "Speed: 3.1ms preprocess, 12.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 16.4ms\n",
            "Speed: 6.4ms preprocess, 16.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 16.4ms\n",
            "Speed: 4.2ms preprocess, 16.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 15.4ms\n",
            "Speed: 3.2ms preprocess, 15.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 13.3ms\n",
            "Speed: 3.7ms preprocess, 13.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 14.2ms\n",
            "Speed: 4.3ms preprocess, 14.2ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 16.3ms\n",
            "Speed: 3.0ms preprocess, 16.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 19.5ms\n",
            "Speed: 3.7ms preprocess, 19.5ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 15.7ms\n",
            "Speed: 3.0ms preprocess, 15.7ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 17.6ms\n",
            "Speed: 3.3ms preprocess, 17.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 16.7ms\n",
            "Speed: 3.1ms preprocess, 16.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.5ms\n",
            "Speed: 3.2ms preprocess, 11.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.3ms\n",
            "Speed: 3.1ms preprocess, 10.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.5ms\n",
            "Speed: 3.7ms preprocess, 10.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.0ms\n",
            "Speed: 4.5ms preprocess, 10.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.7ms\n",
            "Speed: 3.2ms preprocess, 10.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 9.7ms\n",
            "Speed: 3.4ms preprocess, 9.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.3ms\n",
            "Speed: 3.2ms preprocess, 10.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.2ms\n",
            "Speed: 3.1ms preprocess, 10.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12.7ms\n",
            "Speed: 5.3ms preprocess, 12.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12.0ms\n",
            "Speed: 3.3ms preprocess, 12.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 9.9ms\n",
            "Speed: 3.0ms preprocess, 9.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.5ms\n",
            "Speed: 3.1ms preprocess, 11.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 13.9ms\n",
            "Speed: 3.3ms preprocess, 13.9ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.1ms\n",
            "Speed: 3.2ms preprocess, 11.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.9ms\n",
            "Speed: 3.0ms preprocess, 10.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.0ms\n",
            "Speed: 3.0ms preprocess, 11.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12.6ms\n",
            "Speed: 7.2ms preprocess, 12.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.6ms\n",
            "Speed: 4.1ms preprocess, 10.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.7ms\n",
            "Speed: 3.5ms preprocess, 10.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.5ms\n",
            "Speed: 3.1ms preprocess, 11.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.6ms\n",
            "Speed: 6.1ms preprocess, 10.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 9.9ms\n",
            "Speed: 3.4ms preprocess, 9.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 12.7ms\n",
            "Speed: 3.4ms preprocess, 12.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.5ms\n",
            "Speed: 2.7ms preprocess, 10.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 22.9ms\n",
            "Speed: 3.0ms preprocess, 22.9ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 21.3ms\n",
            "Speed: 3.1ms preprocess, 21.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 12.3ms\n",
            "Speed: 3.3ms preprocess, 12.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.4ms\n",
            "Speed: 3.1ms preprocess, 10.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 16.1ms\n",
            "Speed: 3.4ms preprocess, 16.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.1ms\n",
            "Speed: 2.9ms preprocess, 11.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.7ms\n",
            "Speed: 3.3ms preprocess, 10.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.0ms\n",
            "Speed: 3.4ms preprocess, 11.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 18.8ms\n",
            "Speed: 3.1ms preprocess, 18.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.5ms\n",
            "Speed: 3.2ms preprocess, 10.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.0ms\n",
            "Speed: 3.3ms preprocess, 10.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 8.0ms\n",
            "Speed: 3.4ms preprocess, 8.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9.0ms\n",
            "Speed: 3.2ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 16.1ms\n",
            "Speed: 3.0ms preprocess, 16.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9.0ms\n",
            "Speed: 3.0ms preprocess, 9.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.9ms\n",
            "Speed: 7.2ms preprocess, 10.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.8ms\n",
            "Speed: 3.4ms preprocess, 11.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.4ms\n",
            "Speed: 3.1ms preprocess, 10.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.2ms\n",
            "Speed: 4.1ms preprocess, 10.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.0ms\n",
            "Speed: 3.5ms preprocess, 11.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.5ms\n",
            "Speed: 3.2ms preprocess, 11.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.0ms\n",
            "Speed: 3.5ms preprocess, 10.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 9.7ms\n",
            "Speed: 3.0ms preprocess, 9.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 17.1ms\n",
            "Speed: 3.6ms preprocess, 17.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.3ms\n",
            "Speed: 3.1ms preprocess, 11.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 8.6ms\n",
            "Speed: 3.3ms preprocess, 8.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.1ms\n",
            "Speed: 2.9ms preprocess, 11.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12.2ms\n",
            "Speed: 3.2ms preprocess, 12.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.4ms\n",
            "Speed: 3.3ms preprocess, 10.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9.8ms\n",
            "Speed: 3.1ms preprocess, 9.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 12.3ms\n",
            "Speed: 3.2ms preprocess, 12.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 14.2ms\n",
            "Speed: 3.2ms preprocess, 14.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.5ms\n",
            "Speed: 3.1ms preprocess, 10.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.3ms\n",
            "Speed: 3.3ms preprocess, 10.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.3ms\n",
            "Speed: 3.0ms preprocess, 11.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 19.2ms\n",
            "Speed: 3.2ms preprocess, 19.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 14.1ms\n",
            "Speed: 3.2ms preprocess, 14.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.4ms\n",
            "Speed: 3.4ms preprocess, 11.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.6ms\n",
            "Speed: 3.4ms preprocess, 10.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 14.9ms\n",
            "Speed: 3.3ms preprocess, 14.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.0ms\n",
            "Speed: 3.3ms preprocess, 11.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 8.3ms\n",
            "Speed: 3.3ms preprocess, 8.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.1ms\n",
            "Speed: 5.7ms preprocess, 11.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.6ms\n",
            "Speed: 7.3ms preprocess, 11.6ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9.6ms\n",
            "Speed: 3.6ms preprocess, 9.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9.8ms\n",
            "Speed: 3.0ms preprocess, 9.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 8.6ms\n",
            "Speed: 3.3ms preprocess, 8.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 17.6ms\n",
            "Speed: 8.3ms preprocess, 17.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 14.0ms\n",
            "Speed: 7.1ms preprocess, 14.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.9ms\n",
            "Speed: 3.0ms preprocess, 11.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.7ms\n",
            "Speed: 3.5ms preprocess, 11.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.2ms\n",
            "Speed: 3.3ms preprocess, 10.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.0ms\n",
            "Speed: 3.3ms preprocess, 11.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.5ms\n",
            "Speed: 3.1ms preprocess, 10.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 18.4ms\n",
            "Speed: 3.7ms preprocess, 18.4ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 19.0ms\n",
            "Speed: 4.3ms preprocess, 19.0ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 21.6ms\n",
            "Speed: 3.2ms preprocess, 21.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 18.0ms\n",
            "Speed: 3.1ms preprocess, 18.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 16.0ms\n",
            "Speed: 3.2ms preprocess, 16.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.5ms\n",
            "Speed: 5.0ms preprocess, 10.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 20.2ms\n",
            "Speed: 5.1ms preprocess, 20.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.7ms\n",
            "Speed: 3.2ms preprocess, 10.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 16.9ms\n",
            "Speed: 3.0ms preprocess, 16.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.6ms\n",
            "Speed: 3.1ms preprocess, 11.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.7ms\n",
            "Speed: 3.2ms preprocess, 10.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.7ms\n",
            "Speed: 3.2ms preprocess, 11.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 14.7ms\n",
            "Speed: 3.5ms preprocess, 14.7ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 18.9ms\n",
            "Speed: 4.1ms preprocess, 18.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 16.4ms\n",
            "Speed: 4.3ms preprocess, 16.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.3ms\n",
            "Speed: 4.1ms preprocess, 11.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 14.8ms\n",
            "Speed: 7.4ms preprocess, 14.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 14.2ms\n",
            "Speed: 3.2ms preprocess, 14.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 19.3ms\n",
            "Speed: 3.2ms preprocess, 19.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 13.3ms\n",
            "Speed: 3.2ms preprocess, 13.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 14.1ms\n",
            "Speed: 5.8ms preprocess, 14.1ms inference, 7.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 19.3ms\n",
            "Speed: 3.1ms preprocess, 19.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 15.6ms\n",
            "Speed: 3.2ms preprocess, 15.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9.8ms\n",
            "Speed: 4.8ms preprocess, 9.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.0ms\n",
            "Speed: 3.1ms preprocess, 10.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.2ms\n",
            "Speed: 2.9ms preprocess, 10.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.4ms\n",
            "Speed: 3.1ms preprocess, 11.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9.9ms\n",
            "Speed: 3.4ms preprocess, 9.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.6ms\n",
            "Speed: 3.2ms preprocess, 11.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9.7ms\n",
            "Speed: 3.2ms preprocess, 9.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9.6ms\n",
            "Speed: 3.3ms preprocess, 9.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9.8ms\n",
            "Speed: 3.1ms preprocess, 9.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.0ms\n",
            "Speed: 3.1ms preprocess, 10.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9.9ms\n",
            "Speed: 3.1ms preprocess, 9.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12.0ms\n",
            "Speed: 3.1ms preprocess, 12.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.2ms\n",
            "Speed: 3.1ms preprocess, 10.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.1ms\n",
            "Speed: 3.3ms preprocess, 10.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9.6ms\n",
            "Speed: 3.1ms preprocess, 9.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 15.6ms\n",
            "Speed: 3.9ms preprocess, 15.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 16.3ms\n",
            "Speed: 3.6ms preprocess, 16.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 15.4ms\n",
            "Speed: 3.2ms preprocess, 15.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.2ms\n",
            "Speed: 3.1ms preprocess, 11.2ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 17.9ms\n",
            "Speed: 3.2ms preprocess, 17.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 14.7ms\n",
            "Speed: 3.1ms preprocess, 14.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.3ms\n",
            "Speed: 3.3ms preprocess, 10.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 13.2ms\n",
            "Speed: 3.1ms preprocess, 13.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 16.0ms\n",
            "Speed: 2.5ms preprocess, 16.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.1ms\n",
            "Speed: 3.2ms preprocess, 10.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9.8ms\n",
            "Speed: 3.2ms preprocess, 9.8ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9.8ms\n",
            "Speed: 3.3ms preprocess, 9.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 15.7ms\n",
            "Speed: 3.1ms preprocess, 15.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.6ms\n",
            "Speed: 3.1ms preprocess, 10.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9.6ms\n",
            "Speed: 3.1ms preprocess, 9.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 12.6ms\n",
            "Speed: 3.3ms preprocess, 12.6ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.4ms\n",
            "Speed: 3.7ms preprocess, 11.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.2ms\n",
            "Speed: 3.2ms preprocess, 10.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9.7ms\n",
            "Speed: 4.4ms preprocess, 9.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12.2ms\n",
            "Speed: 3.2ms preprocess, 12.2ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.1ms\n",
            "Speed: 3.9ms preprocess, 10.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9.2ms\n",
            "Speed: 3.8ms preprocess, 9.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 8.9ms\n",
            "Speed: 3.8ms preprocess, 8.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.6ms\n",
            "Speed: 4.2ms preprocess, 11.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9.8ms\n",
            "Speed: 4.3ms preprocess, 9.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12.2ms\n",
            "Speed: 3.4ms preprocess, 12.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 21.7ms\n",
            "Speed: 3.4ms preprocess, 21.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 20.7ms\n",
            "Speed: 3.6ms preprocess, 20.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.7ms\n",
            "Speed: 3.4ms preprocess, 10.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.9ms\n",
            "Speed: 3.5ms preprocess, 11.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12.6ms\n",
            "Speed: 3.5ms preprocess, 12.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 16.0ms\n",
            "Speed: 12.9ms preprocess, 16.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.1ms\n",
            "Speed: 3.2ms preprocess, 11.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.7ms\n",
            "Speed: 3.3ms preprocess, 11.7ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 16.5ms\n",
            "Speed: 5.0ms preprocess, 16.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 23.0ms\n",
            "Speed: 9.6ms preprocess, 23.0ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 20.4ms\n",
            "Speed: 3.2ms preprocess, 20.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12.8ms\n",
            "Speed: 7.5ms preprocess, 12.8ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12.9ms\n",
            "Speed: 6.9ms preprocess, 12.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 14.5ms\n",
            "Speed: 3.1ms preprocess, 14.5ms inference, 6.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 18.3ms\n",
            "Speed: 6.1ms preprocess, 18.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 23.8ms\n",
            "Speed: 3.2ms preprocess, 23.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 17.7ms\n",
            "Speed: 3.2ms preprocess, 17.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 17.5ms\n",
            "Speed: 3.0ms preprocess, 17.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 19.0ms\n",
            "Speed: 3.0ms preprocess, 19.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 14.5ms\n",
            "Speed: 5.4ms preprocess, 14.5ms inference, 7.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 15.0ms\n",
            "Speed: 5.0ms preprocess, 15.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 16.4ms\n",
            "Speed: 3.2ms preprocess, 16.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9.4ms\n",
            "Speed: 6.2ms preprocess, 9.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 18.5ms\n",
            "Speed: 3.4ms preprocess, 18.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.5ms\n",
            "Speed: 4.5ms preprocess, 10.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12.2ms\n",
            "Speed: 3.9ms preprocess, 12.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12.4ms\n",
            "Speed: 4.7ms preprocess, 12.4ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 15.0ms\n",
            "Speed: 6.3ms preprocess, 15.0ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.5ms\n",
            "Speed: 4.4ms preprocess, 11.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12.6ms\n",
            "Speed: 3.1ms preprocess, 12.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.5ms\n",
            "Speed: 3.1ms preprocess, 11.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 20.6ms\n",
            "Speed: 2.6ms preprocess, 20.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.3ms\n",
            "Speed: 3.1ms preprocess, 10.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 16.0ms\n",
            "Speed: 3.1ms preprocess, 16.0ms inference, 6.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 16.9ms\n",
            "Speed: 3.3ms preprocess, 16.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 21.4ms\n",
            "Speed: 7.2ms preprocess, 21.4ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 21.6ms\n",
            "Speed: 3.2ms preprocess, 21.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12.3ms\n",
            "Speed: 6.9ms preprocess, 12.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 22.4ms\n",
            "Speed: 3.0ms preprocess, 22.4ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 20.0ms\n",
            "Speed: 3.3ms preprocess, 20.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 13.9ms\n",
            "Speed: 3.3ms preprocess, 13.9ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 16.7ms\n",
            "Speed: 3.1ms preprocess, 16.7ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12.9ms\n",
            "Speed: 4.1ms preprocess, 12.9ms inference, 7.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 13.4ms\n",
            "Speed: 4.8ms preprocess, 13.4ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 25.4ms\n",
            "Speed: 3.2ms preprocess, 25.4ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 13.5ms\n",
            "Speed: 4.8ms preprocess, 13.5ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.0ms\n",
            "Speed: 3.4ms preprocess, 10.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.5ms\n",
            "Speed: 3.0ms preprocess, 10.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.4ms\n",
            "Speed: 3.0ms preprocess, 10.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.2ms\n",
            "Speed: 2.5ms preprocess, 10.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.6ms\n",
            "Speed: 2.9ms preprocess, 10.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.7ms\n",
            "Speed: 9.7ms preprocess, 10.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12.0ms\n",
            "Speed: 3.1ms preprocess, 12.0ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12.4ms\n",
            "Speed: 3.3ms preprocess, 12.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.6ms\n",
            "Speed: 2.4ms preprocess, 10.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 18.6ms\n",
            "Speed: 3.1ms preprocess, 18.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.1ms\n",
            "Speed: 3.8ms preprocess, 10.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.4ms\n",
            "Speed: 3.2ms preprocess, 10.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.8ms\n",
            "Speed: 2.9ms preprocess, 10.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 13.1ms\n",
            "Speed: 3.2ms preprocess, 13.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.1ms\n",
            "Speed: 2.7ms preprocess, 10.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.2ms\n",
            "Speed: 3.4ms preprocess, 10.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9.3ms\n",
            "Speed: 3.4ms preprocess, 9.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 15.8ms\n",
            "Speed: 4.2ms preprocess, 15.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.4ms\n",
            "Speed: 3.3ms preprocess, 10.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.6ms\n",
            "Speed: 3.4ms preprocess, 10.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 16.4ms\n",
            "Speed: 3.1ms preprocess, 16.4ms inference, 8.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 13.0ms\n",
            "Speed: 4.2ms preprocess, 13.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.1ms\n",
            "Speed: 3.5ms preprocess, 11.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.3ms\n",
            "Speed: 3.3ms preprocess, 10.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 22.8ms\n",
            "Speed: 3.6ms preprocess, 22.8ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 19.1ms\n",
            "Speed: 3.1ms preprocess, 19.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 14.6ms\n",
            "Speed: 3.1ms preprocess, 14.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.8ms\n",
            "Speed: 2.9ms preprocess, 11.8ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 14.8ms\n",
            "Speed: 3.1ms preprocess, 14.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.8ms\n",
            "Speed: 4.7ms preprocess, 10.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.1ms\n",
            "Speed: 4.0ms preprocess, 11.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.4ms\n",
            "Speed: 4.3ms preprocess, 10.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12.3ms\n",
            "Speed: 4.4ms preprocess, 12.3ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.7ms\n",
            "Speed: 2.9ms preprocess, 10.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.6ms\n",
            "Speed: 2.6ms preprocess, 10.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.3ms\n",
            "Speed: 3.1ms preprocess, 10.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.8ms\n",
            "Speed: 3.5ms preprocess, 11.8ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9.3ms\n",
            "Speed: 4.5ms preprocess, 9.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.9ms\n",
            "Speed: 3.1ms preprocess, 10.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.2ms\n",
            "Speed: 2.8ms preprocess, 10.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.5ms\n",
            "Speed: 3.1ms preprocess, 10.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.8ms\n",
            "Speed: 4.5ms preprocess, 10.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.2ms\n",
            "Speed: 3.7ms preprocess, 10.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.2ms\n",
            "Speed: 7.6ms preprocess, 11.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 16.3ms\n",
            "Speed: 2.9ms preprocess, 16.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 13.8ms\n",
            "Speed: 3.1ms preprocess, 13.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.0ms\n",
            "Speed: 3.3ms preprocess, 10.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.5ms\n",
            "Speed: 3.2ms preprocess, 10.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12.6ms\n",
            "Speed: 3.1ms preprocess, 12.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.4ms\n",
            "Speed: 6.1ms preprocess, 11.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.8ms\n",
            "Speed: 4.0ms preprocess, 10.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9.5ms\n",
            "Speed: 4.3ms preprocess, 9.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.6ms\n",
            "Speed: 3.7ms preprocess, 10.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9.8ms\n",
            "Speed: 4.1ms preprocess, 9.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.4ms\n",
            "Speed: 4.1ms preprocess, 10.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12.3ms\n",
            "Speed: 4.3ms preprocess, 12.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.2ms\n",
            "Speed: 3.3ms preprocess, 10.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 20.1ms\n",
            "Speed: 4.4ms preprocess, 20.1ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.1ms\n",
            "Speed: 3.1ms preprocess, 10.1ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 16.1ms\n",
            "Speed: 3.2ms preprocess, 16.1ms inference, 7.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9.8ms\n",
            "Speed: 5.4ms preprocess, 9.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 18.3ms\n",
            "Speed: 3.2ms preprocess, 18.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.7ms\n",
            "Speed: 4.0ms preprocess, 10.7ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.8ms\n",
            "Speed: 2.8ms preprocess, 10.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9.8ms\n",
            "Speed: 3.3ms preprocess, 9.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.0ms\n",
            "Speed: 3.2ms preprocess, 10.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9.9ms\n",
            "Speed: 2.9ms preprocess, 9.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9.4ms\n",
            "Speed: 3.0ms preprocess, 9.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12.6ms\n",
            "Speed: 3.5ms preprocess, 12.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.5ms\n",
            "Speed: 3.0ms preprocess, 11.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12.0ms\n",
            "Speed: 3.1ms preprocess, 12.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.2ms\n",
            "Speed: 3.3ms preprocess, 11.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.1ms\n",
            "Speed: 3.1ms preprocess, 10.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.6ms\n",
            "Speed: 3.1ms preprocess, 11.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.6ms\n",
            "Speed: 3.2ms preprocess, 10.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.4ms\n",
            "Speed: 3.1ms preprocess, 10.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.7ms\n",
            "Speed: 3.0ms preprocess, 10.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.1ms\n",
            "Speed: 2.5ms preprocess, 11.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.1ms\n",
            "Speed: 7.8ms preprocess, 11.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.9ms\n",
            "Speed: 6.7ms preprocess, 11.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 14.2ms\n",
            "Speed: 3.5ms preprocess, 14.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.7ms\n",
            "Speed: 3.1ms preprocess, 10.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 13.8ms\n",
            "Speed: 4.5ms preprocess, 13.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.6ms\n",
            "Speed: 3.0ms preprocess, 10.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 14.6ms\n",
            "Speed: 3.1ms preprocess, 14.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 9.6ms\n",
            "Speed: 3.2ms preprocess, 9.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 14.1ms\n",
            "Speed: 5.2ms preprocess, 14.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.4ms\n",
            "Speed: 3.2ms preprocess, 10.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.3ms\n",
            "Speed: 3.2ms preprocess, 11.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.0ms\n",
            "Speed: 3.7ms preprocess, 10.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.9ms\n",
            "Speed: 3.4ms preprocess, 10.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.0ms\n",
            "Speed: 3.9ms preprocess, 10.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.4ms\n",
            "Speed: 4.1ms preprocess, 10.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 18.1ms\n",
            "Speed: 3.3ms preprocess, 18.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 18.4ms\n",
            "Speed: 6.3ms preprocess, 18.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.3ms\n",
            "Speed: 5.7ms preprocess, 10.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 13.9ms\n",
            "Speed: 3.3ms preprocess, 13.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.8ms\n",
            "Speed: 3.7ms preprocess, 11.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 16.6ms\n",
            "Speed: 3.8ms preprocess, 16.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.1ms\n",
            "Speed: 3.2ms preprocess, 10.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.3ms\n",
            "Speed: 3.2ms preprocess, 11.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 15.2ms\n",
            "Speed: 3.1ms preprocess, 15.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.5ms\n",
            "Speed: 3.4ms preprocess, 11.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 9.2ms\n",
            "Speed: 3.3ms preprocess, 9.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.2ms\n",
            "Speed: 4.8ms preprocess, 11.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 8.1ms\n",
            "Speed: 3.2ms preprocess, 8.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12.8ms\n",
            "Speed: 3.1ms preprocess, 12.8ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.1ms\n",
            "Speed: 2.6ms preprocess, 11.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 9.0ms\n",
            "Speed: 4.7ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.5ms\n",
            "Speed: 3.7ms preprocess, 11.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 18.0ms\n",
            "Speed: 3.6ms preprocess, 18.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.4ms\n",
            "Speed: 7.0ms preprocess, 10.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 9.6ms\n",
            "Speed: 3.3ms preprocess, 9.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 9.4ms\n",
            "Speed: 2.7ms preprocess, 9.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.8ms\n",
            "Speed: 3.3ms preprocess, 11.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 9.7ms\n",
            "Speed: 3.5ms preprocess, 9.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 15.7ms\n",
            "Speed: 3.0ms preprocess, 15.7ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 16.7ms\n",
            "Speed: 3.2ms preprocess, 16.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 15.8ms\n",
            "Speed: 3.2ms preprocess, 15.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.7ms\n",
            "Speed: 3.5ms preprocess, 11.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 24.9ms\n",
            "Speed: 3.1ms preprocess, 24.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 18.9ms\n",
            "Speed: 3.2ms preprocess, 18.9ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 19.7ms\n",
            "Speed: 3.2ms preprocess, 19.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12.9ms\n",
            "Speed: 3.1ms preprocess, 12.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 19.2ms\n",
            "Speed: 3.2ms preprocess, 19.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 24.3ms\n",
            "Speed: 3.0ms preprocess, 24.3ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 23.1ms\n",
            "Speed: 4.1ms preprocess, 23.1ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 15.7ms\n",
            "Speed: 3.0ms preprocess, 15.7ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 20.5ms\n",
            "Speed: 6.6ms preprocess, 20.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 15.4ms\n",
            "Speed: 6.1ms preprocess, 15.4ms inference, 7.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 20.7ms\n",
            "Speed: 3.1ms preprocess, 20.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 14.8ms\n",
            "Speed: 3.0ms preprocess, 14.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.2ms\n",
            "Speed: 3.1ms preprocess, 11.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 19.6ms\n",
            "Speed: 6.3ms preprocess, 19.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 15.9ms\n",
            "Speed: 7.2ms preprocess, 15.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 15.3ms\n",
            "Speed: 3.1ms preprocess, 15.3ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 13.9ms\n",
            "Speed: 3.2ms preprocess, 13.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12.9ms\n",
            "Speed: 3.1ms preprocess, 12.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.1ms\n",
            "Speed: 3.0ms preprocess, 10.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.3ms\n",
            "Speed: 3.2ms preprocess, 10.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 18.3ms\n",
            "Speed: 3.1ms preprocess, 18.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.2ms\n",
            "Speed: 3.1ms preprocess, 10.2ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.2ms\n",
            "Speed: 3.5ms preprocess, 10.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.4ms\n",
            "Speed: 3.4ms preprocess, 10.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.6ms\n",
            "Speed: 3.3ms preprocess, 10.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 20.9ms\n",
            "Speed: 4.3ms preprocess, 20.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12.7ms\n",
            "Speed: 7.2ms preprocess, 12.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 14.6ms\n",
            "Speed: 3.2ms preprocess, 14.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.4ms\n",
            "Speed: 5.1ms preprocess, 10.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.4ms\n",
            "Speed: 3.1ms preprocess, 10.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 9.6ms\n",
            "Speed: 7.2ms preprocess, 9.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.5ms\n",
            "Speed: 3.2ms preprocess, 10.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 15.8ms\n",
            "Speed: 3.2ms preprocess, 15.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.8ms\n",
            "Speed: 3.1ms preprocess, 11.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.4ms\n",
            "Speed: 4.0ms preprocess, 10.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.6ms\n",
            "Speed: 3.2ms preprocess, 10.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 9.8ms\n",
            "Speed: 6.1ms preprocess, 9.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 14.4ms\n",
            "Speed: 2.9ms preprocess, 14.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.0ms\n",
            "Speed: 3.1ms preprocess, 11.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 13.4ms\n",
            "Speed: 3.3ms preprocess, 13.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.4ms\n",
            "Speed: 3.0ms preprocess, 11.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.5ms\n",
            "Speed: 3.1ms preprocess, 11.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.5ms\n",
            "Speed: 3.1ms preprocess, 10.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 13.2ms\n",
            "Speed: 3.0ms preprocess, 13.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.6ms\n",
            "Speed: 2.9ms preprocess, 10.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 9.8ms\n",
            "Speed: 3.1ms preprocess, 9.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 14.2ms\n",
            "Speed: 3.1ms preprocess, 14.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.1ms\n",
            "Speed: 3.2ms preprocess, 10.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.3ms\n",
            "Speed: 3.0ms preprocess, 10.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 9.0ms\n",
            "Speed: 3.2ms preprocess, 9.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.7ms\n",
            "Speed: 3.1ms preprocess, 11.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.2ms\n",
            "Speed: 3.3ms preprocess, 10.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.3ms\n",
            "Speed: 2.6ms preprocess, 11.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 13.3ms\n",
            "Speed: 3.2ms preprocess, 13.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 13.5ms\n",
            "Speed: 3.0ms preprocess, 13.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.5ms\n",
            "Speed: 3.1ms preprocess, 10.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 14.0ms\n",
            "Speed: 4.3ms preprocess, 14.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 16.6ms\n",
            "Speed: 3.1ms preprocess, 16.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.9ms\n",
            "Speed: 3.1ms preprocess, 11.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.1ms\n",
            "Speed: 3.4ms preprocess, 11.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.2ms\n",
            "Speed: 3.5ms preprocess, 10.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.4ms\n",
            "Speed: 3.4ms preprocess, 11.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 9.8ms\n",
            "Speed: 2.9ms preprocess, 9.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 9.7ms\n",
            "Speed: 3.1ms preprocess, 9.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 9.5ms\n",
            "Speed: 3.2ms preprocess, 9.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.9ms\n",
            "Speed: 3.1ms preprocess, 11.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12.9ms\n",
            "Speed: 3.0ms preprocess, 12.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.1ms\n",
            "Speed: 3.2ms preprocess, 10.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 9.5ms\n",
            "Speed: 2.5ms preprocess, 9.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 9.9ms\n",
            "Speed: 3.0ms preprocess, 9.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.4ms\n",
            "Speed: 7.4ms preprocess, 11.4ms inference, 8.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 18.0ms\n",
            "Speed: 3.1ms preprocess, 18.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 17.8ms\n",
            "Speed: 3.1ms preprocess, 17.8ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 16.4ms\n",
            "Speed: 3.1ms preprocess, 16.4ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 21.6ms\n",
            "Speed: 6.3ms preprocess, 21.6ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 9.9ms\n",
            "Speed: 3.1ms preprocess, 9.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.7ms\n",
            "Speed: 3.0ms preprocess, 10.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.7ms\n",
            "Speed: 8.2ms preprocess, 11.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 19.2ms\n",
            "Speed: 3.0ms preprocess, 19.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 17.8ms\n",
            "Speed: 3.2ms preprocess, 17.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12.9ms\n",
            "Speed: 3.3ms preprocess, 12.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 13.4ms\n",
            "Speed: 3.2ms preprocess, 13.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.8ms\n",
            "Speed: 7.5ms preprocess, 11.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 15.8ms\n",
            "Speed: 3.0ms preprocess, 15.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 14.6ms\n",
            "Speed: 3.0ms preprocess, 14.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 9.9ms\n",
            "Speed: 3.1ms preprocess, 9.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.0ms\n",
            "Speed: 3.1ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 14.7ms\n",
            "Speed: 2.9ms preprocess, 14.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 18.5ms\n",
            "Speed: 3.3ms preprocess, 18.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 18.3ms\n",
            "Speed: 4.1ms preprocess, 18.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 18.2ms\n",
            "Speed: 4.2ms preprocess, 18.2ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.5ms\n",
            "Speed: 3.2ms preprocess, 10.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 19.0ms\n",
            "Speed: 2.9ms preprocess, 19.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.5ms\n",
            "Speed: 3.1ms preprocess, 11.5ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 13.3ms\n",
            "Speed: 3.2ms preprocess, 13.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 15.6ms\n",
            "Speed: 3.1ms preprocess, 15.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 19.6ms\n",
            "Speed: 7.2ms preprocess, 19.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.1ms\n",
            "Speed: 3.2ms preprocess, 10.1ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.7ms\n",
            "Speed: 3.1ms preprocess, 11.7ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9.5ms\n",
            "Speed: 3.1ms preprocess, 9.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 15.9ms\n",
            "Speed: 3.1ms preprocess, 15.9ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 16.6ms\n",
            "Speed: 3.1ms preprocess, 16.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 13.3ms\n",
            "Speed: 3.2ms preprocess, 13.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.5ms\n",
            "Speed: 3.0ms preprocess, 11.5ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 13.9ms\n",
            "Speed: 3.1ms preprocess, 13.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.8ms\n",
            "Speed: 3.1ms preprocess, 11.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12.6ms\n",
            "Speed: 3.1ms preprocess, 12.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12.0ms\n",
            "Speed: 3.6ms preprocess, 12.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 16.0ms\n",
            "Speed: 3.1ms preprocess, 16.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 16.1ms\n",
            "Speed: 3.0ms preprocess, 16.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.9ms\n",
            "Speed: 3.7ms preprocess, 11.9ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12.4ms\n",
            "Speed: 3.6ms preprocess, 12.4ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 23.6ms\n",
            "Speed: 2.7ms preprocess, 23.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 16.3ms\n",
            "Speed: 4.5ms preprocess, 16.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 24.3ms\n",
            "Speed: 3.2ms preprocess, 24.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.9ms\n",
            "Speed: 3.2ms preprocess, 10.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.8ms\n",
            "Speed: 6.5ms preprocess, 10.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 20.6ms\n",
            "Speed: 3.1ms preprocess, 20.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.2ms\n",
            "Speed: 2.6ms preprocess, 11.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.1ms\n",
            "Speed: 2.9ms preprocess, 11.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.6ms\n",
            "Speed: 3.1ms preprocess, 11.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.2ms\n",
            "Speed: 3.2ms preprocess, 10.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12.9ms\n",
            "Speed: 3.1ms preprocess, 12.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.4ms\n",
            "Speed: 3.2ms preprocess, 10.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 13.7ms\n",
            "Speed: 3.1ms preprocess, 13.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.7ms\n",
            "Speed: 3.3ms preprocess, 10.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9.6ms\n",
            "Speed: 3.5ms preprocess, 9.6ms inference, 6.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.2ms\n",
            "Speed: 2.6ms preprocess, 10.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.3ms\n",
            "Speed: 3.3ms preprocess, 10.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.2ms\n",
            "Speed: 3.3ms preprocess, 11.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.1ms\n",
            "Speed: 3.3ms preprocess, 11.1ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.7ms\n",
            "Speed: 4.9ms preprocess, 10.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.7ms\n",
            "Speed: 4.1ms preprocess, 11.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9.7ms\n",
            "Speed: 4.0ms preprocess, 9.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 16.4ms\n",
            "Speed: 2.7ms preprocess, 16.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 16.5ms\n",
            "Speed: 3.1ms preprocess, 16.5ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 14.2ms\n",
            "Speed: 3.1ms preprocess, 14.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9.8ms\n",
            "Speed: 4.0ms preprocess, 9.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.2ms\n",
            "Speed: 4.3ms preprocess, 10.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.1ms\n",
            "Speed: 3.2ms preprocess, 10.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 19.0ms\n",
            "Speed: 4.0ms preprocess, 19.0ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.7ms\n",
            "Speed: 3.7ms preprocess, 10.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9.6ms\n",
            "Speed: 3.1ms preprocess, 9.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 15.8ms\n",
            "Speed: 3.3ms preprocess, 15.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.9ms\n",
            "Speed: 3.6ms preprocess, 11.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.9ms\n",
            "Speed: 4.1ms preprocess, 10.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.1ms\n",
            "Speed: 3.7ms preprocess, 11.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 12.5ms\n",
            "Speed: 3.1ms preprocess, 12.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 15.0ms\n",
            "Speed: 8.7ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.7ms\n",
            "Speed: 2.7ms preprocess, 11.7ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 13.9ms\n",
            "Speed: 3.5ms preprocess, 13.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.1ms\n",
            "Speed: 3.5ms preprocess, 11.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.6ms\n",
            "Speed: 3.0ms preprocess, 11.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.1ms\n",
            "Speed: 3.2ms preprocess, 11.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.5ms\n",
            "Speed: 3.0ms preprocess, 11.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.9ms\n",
            "Speed: 3.1ms preprocess, 11.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 13.9ms\n",
            "Speed: 2.4ms preprocess, 13.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 14.4ms\n",
            "Speed: 3.0ms preprocess, 14.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 12.2ms\n",
            "Speed: 4.9ms preprocess, 12.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 14.1ms\n",
            "Speed: 3.7ms preprocess, 14.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.7ms\n",
            "Speed: 3.3ms preprocess, 11.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12.6ms\n",
            "Speed: 3.2ms preprocess, 12.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9.9ms\n",
            "Speed: 4.4ms preprocess, 9.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.8ms\n",
            "Speed: 3.4ms preprocess, 10.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 13.6ms\n",
            "Speed: 7.4ms preprocess, 13.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9.8ms\n",
            "Speed: 4.4ms preprocess, 9.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.0ms\n",
            "Speed: 4.2ms preprocess, 11.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.9ms\n",
            "Speed: 3.4ms preprocess, 10.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 18.1ms\n",
            "Speed: 4.4ms preprocess, 18.1ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 21.1ms\n",
            "Speed: 3.6ms preprocess, 21.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12.8ms\n",
            "Speed: 4.0ms preprocess, 12.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.1ms\n",
            "Speed: 3.1ms preprocess, 10.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.6ms\n",
            "Speed: 3.0ms preprocess, 10.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.7ms\n",
            "Speed: 3.0ms preprocess, 10.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.0ms\n",
            "Speed: 3.3ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.5ms\n",
            "Speed: 3.3ms preprocess, 11.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.9ms\n",
            "Speed: 3.1ms preprocess, 10.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.4ms\n",
            "Speed: 3.1ms preprocess, 11.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.5ms\n",
            "Speed: 4.4ms preprocess, 10.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12.0ms\n",
            "Speed: 4.4ms preprocess, 12.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.9ms\n",
            "Speed: 4.5ms preprocess, 10.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12.1ms\n",
            "Speed: 3.2ms preprocess, 12.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.6ms\n",
            "Speed: 4.4ms preprocess, 10.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12.0ms\n",
            "Speed: 3.1ms preprocess, 12.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9.8ms\n",
            "Speed: 5.3ms preprocess, 9.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.1ms\n",
            "Speed: 3.4ms preprocess, 11.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.4ms\n",
            "Speed: 3.5ms preprocess, 10.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.5ms\n",
            "Speed: 3.3ms preprocess, 11.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.7ms\n",
            "Speed: 3.1ms preprocess, 11.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.4ms\n",
            "Speed: 3.3ms preprocess, 10.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.2ms\n",
            "Speed: 3.2ms preprocess, 10.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.1ms\n",
            "Speed: 7.2ms preprocess, 10.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.6ms\n",
            "Speed: 3.0ms preprocess, 10.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9.8ms\n",
            "Speed: 3.4ms preprocess, 9.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9.4ms\n",
            "Speed: 3.2ms preprocess, 9.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.6ms\n",
            "Speed: 3.0ms preprocess, 11.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 18.1ms\n",
            "Speed: 3.3ms preprocess, 18.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.7ms\n",
            "Speed: 4.4ms preprocess, 10.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.1ms\n",
            "Speed: 3.3ms preprocess, 10.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.3ms\n",
            "Speed: 3.2ms preprocess, 10.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 15.2ms\n",
            "Speed: 3.4ms preprocess, 15.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.7ms\n",
            "Speed: 3.5ms preprocess, 11.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.2ms\n",
            "Speed: 6.1ms preprocess, 10.2ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 14.2ms\n",
            "Speed: 7.0ms preprocess, 14.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.2ms\n",
            "Speed: 8.2ms preprocess, 11.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12.6ms\n",
            "Speed: 3.0ms preprocess, 12.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.9ms\n",
            "Speed: 3.0ms preprocess, 10.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.2ms\n",
            "Speed: 2.7ms preprocess, 10.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.8ms\n",
            "Speed: 3.0ms preprocess, 10.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.5ms\n",
            "Speed: 3.3ms preprocess, 10.5ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.0ms\n",
            "Speed: 3.2ms preprocess, 11.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9.7ms\n",
            "Speed: 3.4ms preprocess, 9.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 12.4ms\n",
            "Speed: 3.1ms preprocess, 12.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 13.4ms\n",
            "Speed: 3.0ms preprocess, 13.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.1ms\n",
            "Speed: 3.3ms preprocess, 10.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.8ms\n",
            "Speed: 3.3ms preprocess, 10.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 15.5ms\n",
            "Speed: 3.3ms preprocess, 15.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.7ms\n",
            "Speed: 4.9ms preprocess, 10.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.1ms\n",
            "Speed: 3.3ms preprocess, 10.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 9.8ms\n",
            "Speed: 3.2ms preprocess, 9.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 12.4ms\n",
            "Speed: 3.8ms preprocess, 12.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.7ms\n",
            "Speed: 5.9ms preprocess, 11.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9.6ms\n",
            "Speed: 3.4ms preprocess, 9.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 13.6ms\n",
            "Speed: 3.4ms preprocess, 13.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9.8ms\n",
            "Speed: 3.5ms preprocess, 9.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12.6ms\n",
            "Speed: 3.5ms preprocess, 12.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.8ms\n",
            "Speed: 3.4ms preprocess, 11.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.4ms\n",
            "Speed: 3.4ms preprocess, 10.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.2ms\n",
            "Speed: 3.3ms preprocess, 10.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.4ms\n",
            "Speed: 4.2ms preprocess, 10.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12.6ms\n",
            "Speed: 3.1ms preprocess, 12.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.8ms\n",
            "Speed: 3.2ms preprocess, 11.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 17.9ms\n",
            "Speed: 3.1ms preprocess, 17.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 14.1ms\n",
            "Speed: 2.5ms preprocess, 14.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.8ms\n",
            "Speed: 3.4ms preprocess, 11.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12.1ms\n",
            "Speed: 3.1ms preprocess, 12.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12.1ms\n",
            "Speed: 3.1ms preprocess, 12.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.4ms\n",
            "Speed: 4.5ms preprocess, 11.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.5ms\n",
            "Speed: 5.2ms preprocess, 11.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.9ms\n",
            "Speed: 3.7ms preprocess, 11.9ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.5ms\n",
            "Speed: 4.8ms preprocess, 11.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.4ms\n",
            "Speed: 3.9ms preprocess, 10.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9.5ms\n",
            "Speed: 3.1ms preprocess, 9.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 8.4ms\n",
            "Speed: 3.4ms preprocess, 8.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.0ms\n",
            "Speed: 3.1ms preprocess, 10.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.8ms\n",
            "Speed: 3.2ms preprocess, 10.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.7ms\n",
            "Speed: 4.1ms preprocess, 10.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 16.0ms\n",
            "Speed: 3.2ms preprocess, 16.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12.5ms\n",
            "Speed: 3.1ms preprocess, 12.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.5ms\n",
            "Speed: 4.3ms preprocess, 10.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12.2ms\n",
            "Speed: 5.3ms preprocess, 12.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.0ms\n",
            "Speed: 3.2ms preprocess, 11.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.1ms\n",
            "Speed: 3.2ms preprocess, 11.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.4ms\n",
            "Speed: 3.3ms preprocess, 11.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.2ms\n",
            "Speed: 3.2ms preprocess, 11.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.8ms\n",
            "Speed: 3.5ms preprocess, 10.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9.2ms\n",
            "Speed: 3.1ms preprocess, 9.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12.0ms\n",
            "Speed: 3.0ms preprocess, 12.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9.8ms\n",
            "Speed: 3.2ms preprocess, 9.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9.9ms\n",
            "Speed: 4.0ms preprocess, 9.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.0ms\n",
            "Speed: 3.1ms preprocess, 11.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.3ms\n",
            "Speed: 3.1ms preprocess, 10.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.0ms\n",
            "Speed: 3.7ms preprocess, 10.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.2ms\n",
            "Speed: 3.2ms preprocess, 10.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 14.4ms\n",
            "Speed: 3.4ms preprocess, 14.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 8.3ms\n",
            "Speed: 3.2ms preprocess, 8.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 9.8ms\n",
            "Speed: 3.2ms preprocess, 9.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.1ms\n",
            "Speed: 3.1ms preprocess, 11.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9.7ms\n",
            "Speed: 3.1ms preprocess, 9.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9.0ms\n",
            "Speed: 3.4ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9.4ms\n",
            "Speed: 2.4ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12.3ms\n",
            "Speed: 3.4ms preprocess, 12.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9.8ms\n",
            "Speed: 4.5ms preprocess, 9.8ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 13.2ms\n",
            "Speed: 3.3ms preprocess, 13.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12.0ms\n",
            "Speed: 3.0ms preprocess, 12.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 13.5ms\n",
            "Speed: 2.9ms preprocess, 13.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9.2ms\n",
            "Speed: 4.3ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9.9ms\n",
            "Speed: 3.3ms preprocess, 9.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 9.9ms\n",
            "Speed: 3.1ms preprocess, 9.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 10.4ms\n",
            "Speed: 3.2ms preprocess, 10.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 8.4ms\n",
            "Speed: 5.1ms preprocess, 8.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.3ms\n",
            "Speed: 3.7ms preprocess, 11.3ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 8.2ms\n",
            "Speed: 3.0ms preprocess, 8.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.1ms\n",
            "Speed: 2.4ms preprocess, 10.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12.5ms\n",
            "Speed: 3.7ms preprocess, 12.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9.6ms\n",
            "Speed: 9.4ms preprocess, 9.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.9ms\n",
            "Speed: 3.1ms preprocess, 10.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 14.3ms\n",
            "Speed: 3.4ms preprocess, 14.3ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 8.1ms\n",
            "Speed: 3.3ms preprocess, 8.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9.8ms\n",
            "Speed: 2.8ms preprocess, 9.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 9.3ms\n",
            "Speed: 3.2ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12.0ms\n",
            "Speed: 3.1ms preprocess, 12.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9.7ms\n",
            "Speed: 2.7ms preprocess, 9.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.7ms\n",
            "Speed: 3.2ms preprocess, 10.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.1ms\n",
            "Speed: 3.0ms preprocess, 10.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.7ms\n",
            "Speed: 6.8ms preprocess, 10.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.2ms\n",
            "Speed: 3.2ms preprocess, 10.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 8.8ms\n",
            "Speed: 3.4ms preprocess, 8.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 8.4ms\n",
            "Speed: 3.4ms preprocess, 8.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12.6ms\n",
            "Speed: 3.1ms preprocess, 12.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.9ms\n",
            "Speed: 3.3ms preprocess, 10.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9.4ms\n",
            "Speed: 5.6ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 18.3ms\n",
            "Speed: 3.0ms preprocess, 18.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.0ms\n",
            "Speed: 3.1ms preprocess, 11.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12.9ms\n",
            "Speed: 3.2ms preprocess, 12.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 12.0ms\n",
            "Speed: 3.1ms preprocess, 12.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.9ms\n",
            "Speed: 3.0ms preprocess, 10.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.5ms\n",
            "Speed: 3.1ms preprocess, 10.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.5ms\n",
            "Speed: 2.9ms preprocess, 10.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 13.0ms\n",
            "Speed: 4.9ms preprocess, 13.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 15.7ms\n",
            "Speed: 3.1ms preprocess, 15.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 14.3ms\n",
            "Speed: 9.5ms preprocess, 14.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.7ms\n",
            "Speed: 3.1ms preprocess, 10.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12.2ms\n",
            "Speed: 2.9ms preprocess, 12.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.5ms\n",
            "Speed: 2.4ms preprocess, 10.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 13.5ms\n",
            "Speed: 3.2ms preprocess, 13.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 9.5ms\n",
            "Speed: 3.3ms preprocess, 9.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.0ms\n",
            "Speed: 3.1ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 9.9ms\n",
            "Speed: 2.5ms preprocess, 9.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 8.3ms\n",
            "Speed: 6.5ms preprocess, 8.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.6ms\n",
            "Speed: 5.3ms preprocess, 10.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 9.3ms\n",
            "Speed: 3.1ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.1ms\n",
            "Speed: 3.4ms preprocess, 11.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 14.3ms\n",
            "Speed: 3.2ms preprocess, 14.3ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 9.8ms\n",
            "Speed: 6.8ms preprocess, 9.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.2ms\n",
            "Speed: 2.7ms preprocess, 10.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.4ms\n",
            "Speed: 3.1ms preprocess, 11.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.7ms\n",
            "Speed: 3.2ms preprocess, 10.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.3ms\n",
            "Speed: 3.0ms preprocess, 11.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 9.5ms\n",
            "Speed: 3.2ms preprocess, 9.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 8.0ms\n",
            "Speed: 2.9ms preprocess, 8.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 14.8ms\n",
            "Speed: 3.1ms preprocess, 14.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12.1ms\n",
            "Speed: 3.3ms preprocess, 12.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12.0ms\n",
            "Speed: 3.1ms preprocess, 12.0ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 9.9ms\n",
            "Speed: 3.0ms preprocess, 9.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.1ms\n",
            "Speed: 3.3ms preprocess, 11.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12.4ms\n",
            "Speed: 3.2ms preprocess, 12.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.6ms\n",
            "Speed: 2.7ms preprocess, 10.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12.3ms\n",
            "Speed: 3.2ms preprocess, 12.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.4ms\n",
            "Speed: 4.8ms preprocess, 10.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 9.7ms\n",
            "Speed: 3.1ms preprocess, 9.7ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.1ms\n",
            "Speed: 3.0ms preprocess, 11.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.2ms\n",
            "Speed: 8.6ms preprocess, 10.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.2ms\n",
            "Speed: 3.8ms preprocess, 11.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 9.7ms\n",
            "Speed: 3.8ms preprocess, 9.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 12.0ms\n",
            "Speed: 3.5ms preprocess, 12.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 22.9ms\n",
            "Speed: 3.1ms preprocess, 22.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12.8ms\n",
            "Speed: 3.2ms preprocess, 12.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.0ms\n",
            "Speed: 3.1ms preprocess, 10.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 13.1ms\n",
            "Speed: 3.0ms preprocess, 13.1ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.3ms\n",
            "Speed: 3.1ms preprocess, 10.3ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9.5ms\n",
            "Speed: 7.3ms preprocess, 9.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9.1ms\n",
            "Speed: 3.3ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.5ms\n",
            "Speed: 3.2ms preprocess, 10.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.3ms\n",
            "Speed: 3.3ms preprocess, 10.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.8ms\n",
            "Speed: 3.2ms preprocess, 10.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.3ms\n",
            "Speed: 2.9ms preprocess, 11.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.0ms\n",
            "Speed: 5.0ms preprocess, 10.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 8.5ms\n",
            "Speed: 3.1ms preprocess, 8.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 9.9ms\n",
            "Speed: 9.5ms preprocess, 9.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 8.0ms\n",
            "Speed: 3.3ms preprocess, 8.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.0ms\n",
            "Speed: 3.1ms preprocess, 11.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.1ms\n",
            "Speed: 3.9ms preprocess, 10.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.6ms\n",
            "Speed: 5.2ms preprocess, 11.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.2ms\n",
            "Speed: 3.8ms preprocess, 10.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.5ms\n",
            "Speed: 5.1ms preprocess, 11.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.1ms\n",
            "Speed: 3.5ms preprocess, 10.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.8ms\n",
            "Speed: 3.1ms preprocess, 11.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.6ms\n",
            "Speed: 3.1ms preprocess, 11.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 9.6ms\n",
            "Speed: 3.0ms preprocess, 9.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.7ms\n",
            "Speed: 3.8ms preprocess, 11.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 12.1ms\n",
            "Speed: 3.2ms preprocess, 12.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 9.7ms\n",
            "Speed: 3.4ms preprocess, 9.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 14.9ms\n",
            "Speed: 3.5ms preprocess, 14.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 9.4ms\n",
            "Speed: 3.5ms preprocess, 9.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.1ms\n",
            "Speed: 3.0ms preprocess, 11.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 9.6ms\n",
            "Speed: 3.6ms preprocess, 9.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.5ms\n",
            "Speed: 3.3ms preprocess, 11.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.1ms\n",
            "Speed: 3.3ms preprocess, 10.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 13.7ms\n",
            "Speed: 3.3ms preprocess, 13.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 12.1ms\n",
            "Speed: 3.2ms preprocess, 12.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 27.1ms\n",
            "Speed: 3.2ms preprocess, 27.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 12.7ms\n",
            "Speed: 3.5ms preprocess, 12.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 8.2ms\n",
            "Speed: 2.6ms preprocess, 8.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 8.8ms\n",
            "Speed: 3.0ms preprocess, 8.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.7ms\n",
            "Speed: 3.2ms preprocess, 10.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 9.5ms\n",
            "Speed: 3.6ms preprocess, 9.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.2ms\n",
            "Speed: 3.8ms preprocess, 10.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.9ms\n",
            "Speed: 2.6ms preprocess, 10.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.0ms\n",
            "Speed: 6.6ms preprocess, 10.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.2ms\n",
            "Speed: 3.3ms preprocess, 10.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.0ms\n",
            "Speed: 3.2ms preprocess, 11.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.0ms\n",
            "Speed: 6.9ms preprocess, 10.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.9ms\n",
            "Speed: 3.6ms preprocess, 10.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 9.5ms\n",
            "Speed: 3.5ms preprocess, 9.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 19.2ms\n",
            "Speed: 3.4ms preprocess, 19.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 9.3ms\n",
            "Speed: 5.9ms preprocess, 9.3ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 16.4ms\n",
            "Speed: 3.0ms preprocess, 16.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 14.1ms\n",
            "Speed: 4.9ms preprocess, 14.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 12.0ms\n",
            "Speed: 3.1ms preprocess, 12.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 13.7ms\n",
            "Speed: 3.2ms preprocess, 13.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.4ms\n",
            "Speed: 3.2ms preprocess, 10.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 11.4ms\n",
            "Speed: 3.2ms preprocess, 11.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 11.9ms\n",
            "Speed: 3.2ms preprocess, 11.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 11.7ms\n",
            "Speed: 3.0ms preprocess, 11.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 10.6ms\n",
            "Speed: 4.0ms preprocess, 10.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 8.2ms\n",
            "Speed: 3.4ms preprocess, 8.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.5ms\n",
            "Speed: 3.4ms preprocess, 10.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.3ms\n",
            "Speed: 3.0ms preprocess, 11.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.2ms\n",
            "Speed: 3.3ms preprocess, 10.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 13.7ms\n",
            "Speed: 3.4ms preprocess, 13.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 16.3ms\n",
            "Speed: 3.2ms preprocess, 16.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.9ms\n",
            "Speed: 3.5ms preprocess, 10.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.2ms\n",
            "Speed: 3.3ms preprocess, 10.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.2ms\n",
            "Speed: 3.3ms preprocess, 10.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.9ms\n",
            "Speed: 8.2ms preprocess, 10.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 17.8ms\n",
            "Speed: 7.2ms preprocess, 17.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 18.1ms\n",
            "Speed: 3.0ms preprocess, 18.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.3ms\n",
            "Speed: 3.1ms preprocess, 11.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.9ms\n",
            "Speed: 2.7ms preprocess, 10.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 10.4ms\n",
            "Speed: 3.1ms preprocess, 10.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 9.9ms\n",
            "Speed: 3.5ms preprocess, 9.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.2ms\n",
            "Speed: 3.0ms preprocess, 11.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 10.6ms\n",
            "Speed: 4.8ms preprocess, 10.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 12.7ms\n",
            "Speed: 4.8ms preprocess, 12.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 9.5ms\n",
            "Speed: 2.9ms preprocess, 9.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 12.3ms\n",
            "Speed: 3.1ms preprocess, 12.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.8ms\n",
            "Speed: 4.0ms preprocess, 10.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.9ms\n",
            "Speed: 4.3ms preprocess, 10.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 11.0ms\n",
            "Speed: 3.0ms preprocess, 11.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.1ms\n",
            "Speed: 3.4ms preprocess, 10.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.5ms\n",
            "Speed: 4.8ms preprocess, 11.5ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.0ms\n",
            "Speed: 6.7ms preprocess, 10.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.1ms\n",
            "Speed: 3.4ms preprocess, 10.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 12.0ms\n",
            "Speed: 3.1ms preprocess, 12.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 18.3ms\n",
            "Speed: 2.7ms preprocess, 18.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 14.3ms\n",
            "Speed: 3.1ms preprocess, 14.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 14.4ms\n",
            "Speed: 3.2ms preprocess, 14.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 9.0ms\n",
            "Speed: 3.3ms preprocess, 9.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 12.1ms\n",
            "Speed: 3.3ms preprocess, 12.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 14.9ms\n",
            "Speed: 3.2ms preprocess, 14.9ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 12.8ms\n",
            "Speed: 3.3ms preprocess, 12.8ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 15.3ms\n",
            "Speed: 8.8ms preprocess, 15.3ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 11.1ms\n",
            "Speed: 3.2ms preprocess, 11.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 9.0ms\n",
            "Speed: 3.1ms preprocess, 9.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 13.0ms\n",
            "Speed: 3.3ms preprocess, 13.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 12.0ms\n",
            "Speed: 3.3ms preprocess, 12.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 14.9ms\n",
            "Speed: 5.0ms preprocess, 14.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 11.4ms\n",
            "Speed: 2.9ms preprocess, 11.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 20.2ms\n",
            "Speed: 2.9ms preprocess, 20.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 19.5ms\n",
            "Speed: 6.0ms preprocess, 19.5ms inference, 6.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 14.5ms\n",
            "Speed: 6.6ms preprocess, 14.5ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 15.5ms\n",
            "Speed: 3.1ms preprocess, 15.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 16.6ms\n",
            "Speed: 3.5ms preprocess, 16.6ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 18.4ms\n",
            "Speed: 3.3ms preprocess, 18.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.2ms\n",
            "Speed: 3.2ms preprocess, 11.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 16.4ms\n",
            "Speed: 3.1ms preprocess, 16.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 12.3ms\n",
            "Speed: 3.5ms preprocess, 12.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 15.0ms\n",
            "Speed: 3.1ms preprocess, 15.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.4ms\n",
            "Speed: 3.1ms preprocess, 10.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 14.0ms\n",
            "Speed: 3.1ms preprocess, 14.0ms inference, 7.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 15.2ms\n",
            "Speed: 2.9ms preprocess, 15.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 12.5ms\n",
            "Speed: 3.3ms preprocess, 12.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.9ms\n",
            "Speed: 3.2ms preprocess, 10.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.2ms\n",
            "Speed: 3.2ms preprocess, 11.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 9.0ms\n",
            "Speed: 3.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 18.9ms\n",
            "Speed: 4.0ms preprocess, 18.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.5ms\n",
            "Speed: 3.1ms preprocess, 10.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.0ms\n",
            "Speed: 3.2ms preprocess, 10.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 9.8ms\n",
            "Speed: 3.1ms preprocess, 9.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 13.5ms\n",
            "Speed: 3.2ms preprocess, 13.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 16.3ms\n",
            "Speed: 3.2ms preprocess, 16.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 17.1ms\n",
            "Speed: 3.6ms preprocess, 17.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.2ms\n",
            "Speed: 3.6ms preprocess, 11.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 14.6ms\n",
            "Speed: 9.6ms preprocess, 14.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.7ms\n",
            "Speed: 3.4ms preprocess, 10.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.9ms\n",
            "Speed: 3.2ms preprocess, 11.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 14.9ms\n",
            "Speed: 3.1ms preprocess, 14.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 15.2ms\n",
            "Speed: 6.7ms preprocess, 15.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 9.6ms\n",
            "Speed: 3.1ms preprocess, 9.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.2ms\n",
            "Speed: 3.1ms preprocess, 10.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.9ms\n",
            "Speed: 3.1ms preprocess, 10.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 19.8ms\n",
            "Speed: 3.0ms preprocess, 19.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 12.7ms\n",
            "Speed: 4.9ms preprocess, 12.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9.4ms\n",
            "Speed: 3.0ms preprocess, 9.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.6ms\n",
            "Speed: 3.1ms preprocess, 10.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 14.7ms\n",
            "Speed: 3.0ms preprocess, 14.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9.7ms\n",
            "Speed: 3.0ms preprocess, 9.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.1ms\n",
            "Speed: 3.1ms preprocess, 10.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 13.4ms\n",
            "Speed: 3.1ms preprocess, 13.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12.9ms\n",
            "Speed: 4.3ms preprocess, 12.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.1ms\n",
            "Speed: 3.1ms preprocess, 10.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.7ms\n",
            "Speed: 3.2ms preprocess, 11.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.6ms\n",
            "Speed: 3.1ms preprocess, 10.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 15.8ms\n",
            "Speed: 3.1ms preprocess, 15.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.5ms\n",
            "Speed: 3.0ms preprocess, 10.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.6ms\n",
            "Speed: 4.0ms preprocess, 10.6ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.3ms\n",
            "Speed: 3.1ms preprocess, 10.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 17.4ms\n",
            "Speed: 3.4ms preprocess, 17.4ms inference, 6.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 21.5ms\n",
            "Speed: 3.1ms preprocess, 21.5ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 17.8ms\n",
            "Speed: 2.9ms preprocess, 17.8ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 19.3ms\n",
            "Speed: 3.2ms preprocess, 19.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 22.6ms\n",
            "Speed: 3.2ms preprocess, 22.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 19.8ms\n",
            "Speed: 3.2ms preprocess, 19.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12.9ms\n",
            "Speed: 3.1ms preprocess, 12.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.2ms\n",
            "Speed: 3.1ms preprocess, 11.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.2ms\n",
            "Speed: 3.2ms preprocess, 10.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9.8ms\n",
            "Speed: 4.5ms preprocess, 9.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.8ms\n",
            "Speed: 4.7ms preprocess, 10.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.4ms\n",
            "Speed: 3.2ms preprocess, 10.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.1ms\n",
            "Speed: 3.1ms preprocess, 10.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 13.2ms\n",
            "Speed: 3.1ms preprocess, 13.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.5ms\n",
            "Speed: 3.1ms preprocess, 11.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.4ms\n",
            "Speed: 3.3ms preprocess, 11.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9.9ms\n",
            "Speed: 5.3ms preprocess, 9.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 14.6ms\n",
            "Speed: 3.1ms preprocess, 14.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 17.1ms\n",
            "Speed: 3.8ms preprocess, 17.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 19.1ms\n",
            "Speed: 4.7ms preprocess, 19.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 9.9ms\n",
            "Speed: 5.0ms preprocess, 9.9ms inference, 7.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.7ms\n",
            "Speed: 3.2ms preprocess, 11.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 17.9ms\n",
            "Speed: 6.1ms preprocess, 17.9ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 22.5ms\n",
            "Speed: 3.2ms preprocess, 22.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 14.8ms\n",
            "Speed: 3.3ms preprocess, 14.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 15.4ms\n",
            "Speed: 6.6ms preprocess, 15.4ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 17.7ms\n",
            "Speed: 3.5ms preprocess, 17.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 16.0ms\n",
            "Speed: 3.2ms preprocess, 16.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 22.2ms\n",
            "Speed: 8.6ms preprocess, 22.2ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 20.1ms\n",
            "Speed: 3.4ms preprocess, 20.1ms inference, 6.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 13.6ms\n",
            "Speed: 9.3ms preprocess, 13.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.4ms\n",
            "Speed: 3.2ms preprocess, 10.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 13.7ms\n",
            "Speed: 2.9ms preprocess, 13.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9.2ms\n",
            "Speed: 3.2ms preprocess, 9.2ms inference, 7.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 14.4ms\n",
            "Speed: 7.1ms preprocess, 14.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 8.7ms\n",
            "Speed: 3.0ms preprocess, 8.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 17.7ms\n",
            "Speed: 3.7ms preprocess, 17.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 9.7ms\n",
            "Speed: 3.4ms preprocess, 9.7ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 25.5ms\n",
            "Speed: 6.5ms preprocess, 25.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 26.5ms\n",
            "Speed: 3.1ms preprocess, 26.5ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 21.0ms\n",
            "Speed: 4.5ms preprocess, 21.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 13.6ms\n",
            "Speed: 6.3ms preprocess, 13.6ms inference, 6.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 13.1ms\n",
            "Speed: 7.0ms preprocess, 13.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 25.0ms\n",
            "Speed: 7.5ms preprocess, 25.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 19.0ms\n",
            "Speed: 3.2ms preprocess, 19.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 18.0ms\n",
            "Speed: 3.2ms preprocess, 18.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 18.0ms\n",
            "Speed: 3.1ms preprocess, 18.0ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 26.7ms\n",
            "Speed: 3.1ms preprocess, 26.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 17.7ms\n",
            "Speed: 3.1ms preprocess, 17.7ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 22.9ms\n",
            "Speed: 3.2ms preprocess, 22.9ms inference, 7.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 22.2ms\n",
            "Speed: 5.5ms preprocess, 22.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 19.5ms\n",
            "Speed: 3.3ms preprocess, 19.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 18.4ms\n",
            "Speed: 3.0ms preprocess, 18.4ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 20.8ms\n",
            "Speed: 5.2ms preprocess, 20.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 15.4ms\n",
            "Speed: 3.1ms preprocess, 15.4ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 14.9ms\n",
            "Speed: 5.2ms preprocess, 14.9ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 25.5ms\n",
            "Speed: 3.2ms preprocess, 25.5ms inference, 11.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 14.2ms\n",
            "Speed: 3.1ms preprocess, 14.2ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 19.6ms\n",
            "Speed: 3.2ms preprocess, 19.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.2ms\n",
            "Speed: 3.1ms preprocess, 10.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.9ms\n",
            "Speed: 3.2ms preprocess, 10.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.2ms\n",
            "Speed: 3.3ms preprocess, 11.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 9.9ms\n",
            "Speed: 4.3ms preprocess, 9.9ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.1ms\n",
            "Speed: 3.4ms preprocess, 10.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.1ms\n",
            "Speed: 2.8ms preprocess, 10.1ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.7ms\n",
            "Speed: 3.1ms preprocess, 11.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.1ms\n",
            "Speed: 7.9ms preprocess, 10.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.2ms\n",
            "Speed: 3.2ms preprocess, 10.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.2ms\n",
            "Speed: 5.0ms preprocess, 10.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 9.8ms\n",
            "Speed: 4.1ms preprocess, 9.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.5ms\n",
            "Speed: 3.1ms preprocess, 10.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.9ms\n",
            "Speed: 2.7ms preprocess, 10.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.8ms\n",
            "Speed: 2.7ms preprocess, 10.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 13.6ms\n",
            "Speed: 4.4ms preprocess, 13.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 21.8ms\n",
            "Speed: 3.2ms preprocess, 21.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 12.3ms\n",
            "Speed: 3.4ms preprocess, 12.3ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 9.7ms\n",
            "Speed: 3.0ms preprocess, 9.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.2ms\n",
            "Speed: 3.1ms preprocess, 10.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.4ms\n",
            "Speed: 3.5ms preprocess, 10.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.4ms\n",
            "Speed: 3.2ms preprocess, 11.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.8ms\n",
            "Speed: 3.2ms preprocess, 11.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.1ms\n",
            "Speed: 5.6ms preprocess, 10.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.6ms\n",
            "Speed: 4.0ms preprocess, 11.6ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 12.1ms\n",
            "Speed: 3.1ms preprocess, 12.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.8ms\n",
            "Speed: 3.4ms preprocess, 10.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.4ms\n",
            "Speed: 3.1ms preprocess, 10.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 9.9ms\n",
            "Speed: 3.0ms preprocess, 9.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 13.0ms\n",
            "Speed: 3.1ms preprocess, 13.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.4ms\n",
            "Speed: 3.4ms preprocess, 10.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 12.5ms\n",
            "Speed: 3.2ms preprocess, 12.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.7ms\n",
            "Speed: 2.5ms preprocess, 10.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 15.0ms\n",
            "Speed: 3.2ms preprocess, 15.0ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.1ms\n",
            "Speed: 3.4ms preprocess, 10.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9.7ms\n",
            "Speed: 3.4ms preprocess, 9.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12.4ms\n",
            "Speed: 4.2ms preprocess, 12.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.9ms\n",
            "Speed: 3.0ms preprocess, 11.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.5ms\n",
            "Speed: 3.2ms preprocess, 11.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 16.4ms\n",
            "Speed: 3.4ms preprocess, 16.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.1ms\n",
            "Speed: 3.1ms preprocess, 11.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12.5ms\n",
            "Speed: 2.9ms preprocess, 12.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 13.7ms\n",
            "Speed: 3.2ms preprocess, 13.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.1ms\n",
            "Speed: 4.2ms preprocess, 10.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.5ms\n",
            "Speed: 3.1ms preprocess, 10.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 8.4ms\n",
            "Speed: 3.2ms preprocess, 8.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 14.1ms\n",
            "Speed: 3.3ms preprocess, 14.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9.8ms\n",
            "Speed: 2.7ms preprocess, 9.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.8ms\n",
            "Speed: 4.8ms preprocess, 11.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 15.7ms\n",
            "Speed: 3.3ms preprocess, 15.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12.1ms\n",
            "Speed: 3.8ms preprocess, 12.1ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.4ms\n",
            "Speed: 3.3ms preprocess, 10.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 15.4ms\n",
            "Speed: 3.1ms preprocess, 15.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.6ms\n",
            "Speed: 3.2ms preprocess, 10.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9.3ms\n",
            "Speed: 2.9ms preprocess, 9.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 7.8ms\n",
            "Speed: 3.1ms preprocess, 7.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.9ms\n",
            "Speed: 3.2ms preprocess, 11.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.0ms\n",
            "Speed: 2.9ms preprocess, 10.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.0ms\n",
            "Speed: 2.9ms preprocess, 11.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 13.1ms\n",
            "Speed: 3.3ms preprocess, 13.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.8ms\n",
            "Speed: 2.9ms preprocess, 11.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.3ms\n",
            "Speed: 3.4ms preprocess, 10.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.0ms\n",
            "Speed: 3.1ms preprocess, 10.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 9.3ms\n",
            "Speed: 3.1ms preprocess, 9.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 9.0ms\n",
            "Speed: 3.5ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12.5ms\n",
            "Speed: 5.2ms preprocess, 12.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 8.7ms\n",
            "Speed: 3.0ms preprocess, 8.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.9ms\n",
            "Speed: 4.0ms preprocess, 10.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.7ms\n",
            "Speed: 3.1ms preprocess, 10.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9.2ms\n",
            "Speed: 3.0ms preprocess, 9.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.7ms\n",
            "Speed: 3.1ms preprocess, 11.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.9ms\n",
            "Speed: 3.2ms preprocess, 10.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.7ms\n",
            "Speed: 3.1ms preprocess, 11.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 12.6ms\n",
            "Speed: 3.0ms preprocess, 12.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12.2ms\n",
            "Speed: 3.0ms preprocess, 12.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.2ms\n",
            "Speed: 3.0ms preprocess, 11.2ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.5ms\n",
            "Speed: 3.2ms preprocess, 11.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9.6ms\n",
            "Speed: 3.0ms preprocess, 9.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9.9ms\n",
            "Speed: 2.7ms preprocess, 9.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.0ms\n",
            "Speed: 3.1ms preprocess, 10.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 17.1ms\n",
            "Speed: 3.1ms preprocess, 17.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.5ms\n",
            "Speed: 4.1ms preprocess, 10.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.5ms\n",
            "Speed: 3.4ms preprocess, 11.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 9.0ms\n",
            "Speed: 4.5ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 16.4ms\n",
            "Speed: 6.6ms preprocess, 16.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.8ms\n",
            "Speed: 3.1ms preprocess, 11.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 15.6ms\n",
            "Speed: 4.5ms preprocess, 15.6ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 16.5ms\n",
            "Speed: 3.0ms preprocess, 16.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 14.8ms\n",
            "Speed: 3.4ms preprocess, 14.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 13.0ms\n",
            "Speed: 3.1ms preprocess, 13.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 13.8ms\n",
            "Speed: 3.1ms preprocess, 13.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.1ms\n",
            "Speed: 3.0ms preprocess, 11.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 45.8ms\n",
            "Speed: 4.0ms preprocess, 45.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 31.1ms\n",
            "Speed: 8.6ms preprocess, 31.1ms inference, 9.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 13.2ms\n",
            "Speed: 10.2ms preprocess, 13.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 16.4ms\n",
            "Speed: 3.2ms preprocess, 16.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 30.5ms\n",
            "Speed: 3.8ms preprocess, 30.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.4ms\n",
            "Speed: 4.0ms preprocess, 10.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 13.8ms\n",
            "Speed: 2.9ms preprocess, 13.8ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12.2ms\n",
            "Speed: 3.2ms preprocess, 12.2ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 21.2ms\n",
            "Speed: 2.9ms preprocess, 21.2ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 15.2ms\n",
            "Speed: 8.2ms preprocess, 15.2ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 34.0ms\n",
            "Speed: 3.6ms preprocess, 34.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 20.7ms\n",
            "Speed: 3.4ms preprocess, 20.7ms inference, 5.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 23.3ms\n",
            "Speed: 3.2ms preprocess, 23.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 13.6ms\n",
            "Speed: 3.1ms preprocess, 13.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 14.6ms\n",
            "Speed: 3.2ms preprocess, 14.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 27.3ms\n",
            "Speed: 6.5ms preprocess, 27.3ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 23.4ms\n",
            "Speed: 11.7ms preprocess, 23.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 69.9ms\n",
            "Speed: 5.9ms preprocess, 69.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 16.2ms\n",
            "Speed: 3.3ms preprocess, 16.2ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 30.2ms\n",
            "Speed: 15.1ms preprocess, 30.2ms inference, 6.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 13.1ms\n",
            "Speed: 3.5ms preprocess, 13.1ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 17.7ms\n",
            "Speed: 5.6ms preprocess, 17.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 13.8ms\n",
            "Speed: 3.3ms preprocess, 13.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.0ms\n",
            "Speed: 5.6ms preprocess, 11.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.8ms\n",
            "Speed: 2.8ms preprocess, 10.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.9ms\n",
            "Speed: 3.0ms preprocess, 11.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 13.2ms\n",
            "Speed: 3.2ms preprocess, 13.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 16.7ms\n",
            "Speed: 3.9ms preprocess, 16.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.3ms\n",
            "Speed: 3.0ms preprocess, 11.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9.9ms\n",
            "Speed: 2.8ms preprocess, 9.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9.5ms\n",
            "Speed: 4.2ms preprocess, 9.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 16.4ms\n",
            "Speed: 4.5ms preprocess, 16.4ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 13.4ms\n",
            "Speed: 2.9ms preprocess, 13.4ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 23.6ms\n",
            "Speed: 3.1ms preprocess, 23.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 14.2ms\n",
            "Speed: 5.2ms preprocess, 14.2ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.3ms\n",
            "Speed: 3.2ms preprocess, 10.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 15.1ms\n",
            "Speed: 3.4ms preprocess, 15.1ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 14.4ms\n",
            "Speed: 9.7ms preprocess, 14.4ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.6ms\n",
            "Speed: 3.2ms preprocess, 10.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 13.0ms\n",
            "Speed: 7.3ms preprocess, 13.0ms inference, 6.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12.2ms\n",
            "Speed: 3.3ms preprocess, 12.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 25.7ms\n",
            "Speed: 3.6ms preprocess, 25.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 20.4ms\n",
            "Speed: 6.2ms preprocess, 20.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 32.5ms\n",
            "Speed: 3.1ms preprocess, 32.5ms inference, 12.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 24.6ms\n",
            "Speed: 9.6ms preprocess, 24.6ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 13.3ms\n",
            "Speed: 3.4ms preprocess, 13.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 13.0ms\n",
            "Speed: 3.2ms preprocess, 13.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 17.4ms\n",
            "Speed: 3.7ms preprocess, 17.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 22.4ms\n",
            "Speed: 10.4ms preprocess, 22.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 18.0ms\n",
            "Speed: 3.7ms preprocess, 18.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.2ms\n",
            "Speed: 9.4ms preprocess, 11.2ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 15.3ms\n",
            "Speed: 4.5ms preprocess, 15.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 13.6ms\n",
            "Speed: 7.3ms preprocess, 13.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 16.2ms\n",
            "Speed: 7.1ms preprocess, 16.2ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 14.9ms\n",
            "Speed: 6.5ms preprocess, 14.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 18.4ms\n",
            "Speed: 3.0ms preprocess, 18.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 13.1ms\n",
            "Speed: 3.2ms preprocess, 13.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 13.3ms\n",
            "Speed: 8.5ms preprocess, 13.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 22.7ms\n",
            "Speed: 3.0ms preprocess, 22.7ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.9ms\n",
            "Speed: 3.1ms preprocess, 11.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 29.7ms\n",
            "Speed: 3.0ms preprocess, 29.7ms inference, 17.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 57.6ms\n",
            "Speed: 3.3ms preprocess, 57.6ms inference, 17.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 59.7ms\n",
            "Speed: 15.0ms preprocess, 59.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 27.2ms\n",
            "Speed: 6.0ms preprocess, 27.2ms inference, 14.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 32.0ms\n",
            "Speed: 3.1ms preprocess, 32.0ms inference, 12.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 33.1ms\n",
            "Speed: 8.3ms preprocess, 33.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 19.1ms\n",
            "Speed: 3.2ms preprocess, 19.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 25.9ms\n",
            "Speed: 11.3ms preprocess, 25.9ms inference, 12.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 14.3ms\n",
            "Speed: 11.8ms preprocess, 14.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 8.2ms\n",
            "Speed: 3.0ms preprocess, 8.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12.3ms\n",
            "Speed: 3.3ms preprocess, 12.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 9.8ms\n",
            "Speed: 3.2ms preprocess, 9.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.9ms\n",
            "Speed: 3.2ms preprocess, 10.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 15.1ms\n",
            "Speed: 3.2ms preprocess, 15.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 13.6ms\n",
            "Speed: 3.1ms preprocess, 13.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 16.8ms\n",
            "Speed: 3.2ms preprocess, 16.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.1ms\n",
            "Speed: 3.3ms preprocess, 10.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.8ms\n",
            "Speed: 3.2ms preprocess, 10.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12.1ms\n",
            "Speed: 3.2ms preprocess, 12.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.1ms\n",
            "Speed: 3.6ms preprocess, 10.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.4ms\n",
            "Speed: 2.8ms preprocess, 10.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9.6ms\n",
            "Speed: 3.2ms preprocess, 9.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 22.0ms\n",
            "Speed: 10.1ms preprocess, 22.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 7.9ms\n",
            "Speed: 3.3ms preprocess, 7.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9.8ms\n",
            "Speed: 3.3ms preprocess, 9.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 15.7ms\n",
            "Speed: 8.2ms preprocess, 15.7ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 15.3ms\n",
            "Speed: 3.2ms preprocess, 15.3ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.5ms\n",
            "Speed: 3.3ms preprocess, 10.5ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.6ms\n",
            "Speed: 3.4ms preprocess, 10.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.0ms\n",
            "Speed: 3.2ms preprocess, 11.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 21.3ms\n",
            "Speed: 7.0ms preprocess, 21.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 9.2ms\n",
            "Speed: 3.3ms preprocess, 9.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 12.3ms\n",
            "Speed: 3.4ms preprocess, 12.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.2ms\n",
            "Speed: 3.1ms preprocess, 10.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.1ms\n",
            "Speed: 2.7ms preprocess, 11.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.7ms\n",
            "Speed: 3.3ms preprocess, 10.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 16.3ms\n",
            "Speed: 3.2ms preprocess, 16.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.5ms\n",
            "Speed: 3.2ms preprocess, 10.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.8ms\n",
            "Speed: 3.3ms preprocess, 10.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.2ms\n",
            "Speed: 3.3ms preprocess, 10.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.3ms\n",
            "Speed: 3.2ms preprocess, 10.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.7ms\n",
            "Speed: 3.3ms preprocess, 10.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.7ms\n",
            "Speed: 3.3ms preprocess, 11.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.6ms\n",
            "Speed: 3.1ms preprocess, 11.6ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 15.2ms\n",
            "Speed: 3.1ms preprocess, 15.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.7ms\n",
            "Speed: 3.2ms preprocess, 11.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 17.0ms\n",
            "Speed: 3.3ms preprocess, 17.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.3ms\n",
            "Speed: 3.2ms preprocess, 10.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.2ms\n",
            "Speed: 3.9ms preprocess, 11.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 13.3ms\n",
            "Speed: 3.7ms preprocess, 13.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 17.1ms\n",
            "Speed: 3.0ms preprocess, 17.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 9.3ms\n",
            "Speed: 3.2ms preprocess, 9.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 9.9ms\n",
            "Speed: 3.0ms preprocess, 9.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 7.8ms\n",
            "Speed: 3.2ms preprocess, 7.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.1ms\n",
            "Speed: 3.4ms preprocess, 11.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9.6ms\n",
            "Speed: 3.0ms preprocess, 9.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.4ms\n",
            "Speed: 4.0ms preprocess, 10.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 7.6ms\n",
            "Speed: 3.0ms preprocess, 7.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 8.4ms\n",
            "Speed: 3.2ms preprocess, 8.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.7ms\n",
            "Speed: 3.2ms preprocess, 11.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.3ms\n",
            "Speed: 3.5ms preprocess, 11.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 16.6ms\n",
            "Speed: 3.1ms preprocess, 16.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 25.1ms\n",
            "Speed: 3.4ms preprocess, 25.1ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 15.6ms\n",
            "Speed: 3.2ms preprocess, 15.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.2ms\n",
            "Speed: 3.2ms preprocess, 11.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 15.0ms\n",
            "Speed: 3.1ms preprocess, 15.0ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 13.1ms\n",
            "Speed: 4.1ms preprocess, 13.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.7ms\n",
            "Speed: 3.0ms preprocess, 10.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 14.7ms\n",
            "Speed: 3.4ms preprocess, 14.7ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 14.5ms\n",
            "Speed: 6.2ms preprocess, 14.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.9ms\n",
            "Speed: 3.2ms preprocess, 11.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9.4ms\n",
            "Speed: 3.2ms preprocess, 9.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12.4ms\n",
            "Speed: 7.2ms preprocess, 12.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.0ms\n",
            "Speed: 4.4ms preprocess, 11.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12.5ms\n",
            "Speed: 3.2ms preprocess, 12.5ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.0ms\n",
            "Speed: 3.1ms preprocess, 11.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9.6ms\n",
            "Speed: 3.3ms preprocess, 9.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.7ms\n",
            "Speed: 3.1ms preprocess, 10.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12.2ms\n",
            "Speed: 3.1ms preprocess, 12.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.7ms\n",
            "Speed: 3.1ms preprocess, 10.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9.9ms\n",
            "Speed: 3.2ms preprocess, 9.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12.4ms\n",
            "Speed: 3.1ms preprocess, 12.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12.5ms\n",
            "Speed: 7.3ms preprocess, 12.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.4ms\n",
            "Speed: 3.2ms preprocess, 11.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.3ms\n",
            "Speed: 3.1ms preprocess, 11.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.3ms\n",
            "Speed: 3.1ms preprocess, 10.3ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.3ms\n",
            "Speed: 3.1ms preprocess, 11.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12.4ms\n",
            "Speed: 3.3ms preprocess, 12.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.2ms\n",
            "Speed: 3.3ms preprocess, 11.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9.7ms\n",
            "Speed: 3.2ms preprocess, 9.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.8ms\n",
            "Speed: 3.7ms preprocess, 11.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 13.8ms\n",
            "Speed: 3.0ms preprocess, 13.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 17.5ms\n",
            "Speed: 3.3ms preprocess, 17.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 8.3ms\n",
            "Speed: 3.1ms preprocess, 8.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 8.6ms\n",
            "Speed: 3.3ms preprocess, 8.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 8.5ms\n",
            "Speed: 3.6ms preprocess, 8.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.9ms\n",
            "Speed: 3.0ms preprocess, 11.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 17.1ms\n",
            "Speed: 4.1ms preprocess, 17.1ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12.9ms\n",
            "Speed: 6.3ms preprocess, 12.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.9ms\n",
            "Speed: 3.1ms preprocess, 11.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 20.0ms\n",
            "Speed: 3.4ms preprocess, 20.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.2ms\n",
            "Speed: 6.2ms preprocess, 11.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.8ms\n",
            "Speed: 3.4ms preprocess, 11.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.3ms\n",
            "Speed: 3.3ms preprocess, 11.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.5ms\n",
            "Speed: 3.4ms preprocess, 10.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.0ms\n",
            "Speed: 4.9ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.6ms\n",
            "Speed: 3.3ms preprocess, 10.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.5ms\n",
            "Speed: 3.0ms preprocess, 11.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.9ms\n",
            "Speed: 3.3ms preprocess, 10.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.7ms\n",
            "Speed: 3.2ms preprocess, 10.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9.6ms\n",
            "Speed: 3.4ms preprocess, 9.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.1ms\n",
            "Speed: 3.2ms preprocess, 10.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 8.4ms\n",
            "Speed: 3.4ms preprocess, 8.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.3ms\n",
            "Speed: 3.3ms preprocess, 11.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9.7ms\n",
            "Speed: 3.1ms preprocess, 9.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12.2ms\n",
            "Speed: 3.2ms preprocess, 12.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9.6ms\n",
            "Speed: 3.3ms preprocess, 9.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.2ms\n",
            "Speed: 3.5ms preprocess, 10.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.2ms\n",
            "Speed: 3.3ms preprocess, 11.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.0ms\n",
            "Speed: 3.2ms preprocess, 11.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9.4ms\n",
            "Speed: 3.3ms preprocess, 9.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12.9ms\n",
            "Speed: 3.0ms preprocess, 12.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.1ms\n",
            "Speed: 3.2ms preprocess, 10.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 13.7ms\n",
            "Speed: 3.7ms preprocess, 13.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.7ms\n",
            "Speed: 2.8ms preprocess, 10.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.8ms\n",
            "Speed: 3.1ms preprocess, 10.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12.6ms\n",
            "Speed: 3.0ms preprocess, 12.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9.6ms\n",
            "Speed: 3.1ms preprocess, 9.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.6ms\n",
            "Speed: 4.4ms preprocess, 10.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 13.6ms\n",
            "Speed: 3.1ms preprocess, 13.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 16.5ms\n",
            "Speed: 3.1ms preprocess, 16.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.6ms\n",
            "Speed: 3.2ms preprocess, 11.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 22.2ms\n",
            "Speed: 3.5ms preprocess, 22.2ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 40.6ms\n",
            "Speed: 13.9ms preprocess, 40.6ms inference, 7.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 17.2ms\n",
            "Speed: 3.0ms preprocess, 17.2ms inference, 7.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 20.3ms\n",
            "Speed: 8.0ms preprocess, 20.3ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 31.1ms\n",
            "Speed: 7.9ms preprocess, 31.1ms inference, 7.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 31.7ms\n",
            "Speed: 12.3ms preprocess, 31.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 42.3ms\n",
            "Speed: 10.1ms preprocess, 42.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 41.7ms\n",
            "Speed: 3.0ms preprocess, 41.7ms inference, 10.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 31.1ms\n",
            "Speed: 9.5ms preprocess, 31.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 29.5ms\n",
            "Speed: 4.2ms preprocess, 29.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 21.0ms\n",
            "Speed: 3.0ms preprocess, 21.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 23.6ms\n",
            "Speed: 3.0ms preprocess, 23.6ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 15.9ms\n",
            "Speed: 6.7ms preprocess, 15.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.9ms\n",
            "Speed: 3.2ms preprocess, 11.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9.9ms\n",
            "Speed: 2.9ms preprocess, 9.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 20.0ms\n",
            "Speed: 3.3ms preprocess, 20.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.9ms\n",
            "Speed: 3.1ms preprocess, 11.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9.8ms\n",
            "Speed: 3.2ms preprocess, 9.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.3ms\n",
            "Speed: 3.1ms preprocess, 10.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 27.4ms\n",
            "Speed: 3.3ms preprocess, 27.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 21.3ms\n",
            "Speed: 11.3ms preprocess, 21.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 32.7ms\n",
            "Speed: 8.1ms preprocess, 32.7ms inference, 13.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 49.5ms\n",
            "Speed: 3.3ms preprocess, 49.5ms inference, 10.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 29.5ms\n",
            "Speed: 9.3ms preprocess, 29.5ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 35.8ms\n",
            "Speed: 4.9ms preprocess, 35.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 18.3ms\n",
            "Speed: 3.2ms preprocess, 18.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 17.0ms\n",
            "Speed: 7.4ms preprocess, 17.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 24.3ms\n",
            "Speed: 3.3ms preprocess, 24.3ms inference, 7.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 25.0ms\n",
            "Speed: 3.1ms preprocess, 25.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 33.6ms\n",
            "Speed: 3.4ms preprocess, 33.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 33.5ms\n",
            "Speed: 3.4ms preprocess, 33.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 28.5ms\n",
            "Speed: 3.4ms preprocess, 28.5ms inference, 7.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 28.9ms\n",
            "Speed: 25.4ms preprocess, 28.9ms inference, 7.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 28.8ms\n",
            "Speed: 8.0ms preprocess, 28.8ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 24.4ms\n",
            "Speed: 3.2ms preprocess, 24.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 31.3ms\n",
            "Speed: 3.2ms preprocess, 31.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 22.4ms\n",
            "Speed: 3.1ms preprocess, 22.4ms inference, 10.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 21.0ms\n",
            "Speed: 13.3ms preprocess, 21.0ms inference, 8.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 17.0ms\n",
            "Speed: 3.2ms preprocess, 17.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 32.0ms\n",
            "Speed: 3.0ms preprocess, 32.0ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 32.6ms\n",
            "Speed: 3.2ms preprocess, 32.6ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 26.9ms\n",
            "Speed: 5.5ms preprocess, 26.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 26.4ms\n",
            "Speed: 3.5ms preprocess, 26.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 48.8ms\n",
            "Speed: 3.3ms preprocess, 48.8ms inference, 7.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 28.6ms\n",
            "Speed: 3.2ms preprocess, 28.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 21.9ms\n",
            "Speed: 12.7ms preprocess, 21.9ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 27.4ms\n",
            "Speed: 7.4ms preprocess, 27.4ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 40.2ms\n",
            "Speed: 8.1ms preprocess, 40.2ms inference, 10.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 19.7ms\n",
            "Speed: 10.3ms preprocess, 19.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 18.8ms\n",
            "Speed: 9.3ms preprocess, 18.8ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 51.2ms\n",
            "Speed: 7.3ms preprocess, 51.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 38.3ms\n",
            "Speed: 3.3ms preprocess, 38.3ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12.9ms\n",
            "Speed: 3.2ms preprocess, 12.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 20.2ms\n",
            "Speed: 24.9ms preprocess, 20.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 14.9ms\n",
            "Speed: 3.0ms preprocess, 14.9ms inference, 6.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 14.9ms\n",
            "Speed: 6.4ms preprocess, 14.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 15.1ms\n",
            "Speed: 31.9ms preprocess, 15.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12.7ms\n",
            "Speed: 3.5ms preprocess, 12.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 13.6ms\n",
            "Speed: 3.0ms preprocess, 13.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 15.6ms\n",
            "Speed: 6.0ms preprocess, 15.6ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 13.7ms\n",
            "Speed: 3.7ms preprocess, 13.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 13.6ms\n",
            "Speed: 4.4ms preprocess, 13.6ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 15.7ms\n",
            "Speed: 3.6ms preprocess, 15.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 20.0ms\n",
            "Speed: 2.9ms preprocess, 20.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 19.6ms\n",
            "Speed: 3.4ms preprocess, 19.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 13.5ms\n",
            "Speed: 6.1ms preprocess, 13.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.9ms\n",
            "Speed: 3.1ms preprocess, 10.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 13.9ms\n",
            "Speed: 4.0ms preprocess, 13.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.3ms\n",
            "Speed: 4.0ms preprocess, 10.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 13.5ms\n",
            "Speed: 3.9ms preprocess, 13.5ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.1ms\n",
            "Speed: 3.1ms preprocess, 11.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.3ms\n",
            "Speed: 4.1ms preprocess, 11.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.5ms\n",
            "Speed: 3.3ms preprocess, 11.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.9ms\n",
            "Speed: 5.2ms preprocess, 10.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.0ms\n",
            "Speed: 3.1ms preprocess, 11.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.3ms\n",
            "Speed: 3.3ms preprocess, 10.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 15.3ms\n",
            "Speed: 4.0ms preprocess, 15.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.5ms\n",
            "Speed: 3.2ms preprocess, 10.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.7ms\n",
            "Speed: 3.2ms preprocess, 10.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.0ms\n",
            "Speed: 3.3ms preprocess, 10.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.8ms\n",
            "Speed: 3.3ms preprocess, 10.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.4ms\n",
            "Speed: 3.3ms preprocess, 10.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.9ms\n",
            "Speed: 3.1ms preprocess, 11.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 13.4ms\n",
            "Speed: 5.7ms preprocess, 13.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 18.6ms\n",
            "Speed: 4.6ms preprocess, 18.6ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.4ms\n",
            "Speed: 4.1ms preprocess, 10.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.7ms\n",
            "Speed: 4.5ms preprocess, 11.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 13.4ms\n",
            "Speed: 3.0ms preprocess, 13.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.2ms\n",
            "Speed: 3.9ms preprocess, 10.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.1ms\n",
            "Speed: 3.1ms preprocess, 10.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9.7ms\n",
            "Speed: 3.3ms preprocess, 9.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12.2ms\n",
            "Speed: 3.2ms preprocess, 12.2ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.8ms\n",
            "Speed: 3.9ms preprocess, 11.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 17.1ms\n",
            "Speed: 2.5ms preprocess, 17.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9.3ms\n",
            "Speed: 3.1ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 8.0ms\n",
            "Speed: 3.3ms preprocess, 8.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 13.8ms\n",
            "Speed: 3.2ms preprocess, 13.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.5ms\n",
            "Speed: 4.1ms preprocess, 10.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12.2ms\n",
            "Speed: 4.0ms preprocess, 12.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.2ms\n",
            "Speed: 3.3ms preprocess, 10.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12.4ms\n",
            "Speed: 3.3ms preprocess, 12.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 15.5ms\n",
            "Speed: 3.5ms preprocess, 15.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9.3ms\n",
            "Speed: 3.2ms preprocess, 9.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 15.7ms\n",
            "Speed: 4.6ms preprocess, 15.7ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.4ms\n",
            "Speed: 3.1ms preprocess, 11.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 17.2ms\n",
            "Speed: 3.8ms preprocess, 17.2ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.8ms\n",
            "Speed: 3.1ms preprocess, 11.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9.6ms\n",
            "Speed: 3.5ms preprocess, 9.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.6ms\n",
            "Speed: 3.3ms preprocess, 10.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.7ms\n",
            "Speed: 3.3ms preprocess, 10.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12.3ms\n",
            "Speed: 4.3ms preprocess, 12.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.7ms\n",
            "Speed: 3.2ms preprocess, 10.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.1ms\n",
            "Speed: 3.9ms preprocess, 10.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.9ms\n",
            "Speed: 4.8ms preprocess, 10.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.4ms\n",
            "Speed: 3.9ms preprocess, 10.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12.2ms\n",
            "Speed: 3.4ms preprocess, 12.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.7ms\n",
            "Speed: 3.1ms preprocess, 11.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 15.0ms\n",
            "Speed: 3.5ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.4ms\n",
            "Speed: 3.0ms preprocess, 11.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.1ms\n",
            "Speed: 3.6ms preprocess, 10.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.8ms\n",
            "Speed: 4.6ms preprocess, 10.8ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 23.9ms\n",
            "Speed: 3.1ms preprocess, 23.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.6ms\n",
            "Speed: 3.1ms preprocess, 10.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 15.1ms\n",
            "Speed: 3.0ms preprocess, 15.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12.0ms\n",
            "Speed: 3.1ms preprocess, 12.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.3ms\n",
            "Speed: 2.6ms preprocess, 10.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9.6ms\n",
            "Speed: 3.2ms preprocess, 9.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.5ms\n",
            "Speed: 2.9ms preprocess, 10.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.7ms\n",
            "Speed: 4.1ms preprocess, 10.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.6ms\n",
            "Speed: 3.2ms preprocess, 10.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.4ms\n",
            "Speed: 3.2ms preprocess, 11.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.2ms\n",
            "Speed: 3.3ms preprocess, 10.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.6ms\n",
            "Speed: 3.9ms preprocess, 10.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.4ms\n",
            "Speed: 3.8ms preprocess, 10.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9.8ms\n",
            "Speed: 4.4ms preprocess, 9.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.3ms\n",
            "Speed: 2.7ms preprocess, 11.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.9ms\n",
            "Speed: 3.1ms preprocess, 10.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12.7ms\n",
            "Speed: 4.0ms preprocess, 12.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.9ms\n",
            "Speed: 3.0ms preprocess, 10.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.8ms\n",
            "Speed: 2.9ms preprocess, 11.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12.7ms\n",
            "Speed: 4.8ms preprocess, 12.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.9ms\n",
            "Speed: 4.0ms preprocess, 10.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.4ms\n",
            "Speed: 3.1ms preprocess, 11.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.2ms\n",
            "Speed: 3.3ms preprocess, 10.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9.4ms\n",
            "Speed: 3.1ms preprocess, 9.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12.1ms\n",
            "Speed: 4.5ms preprocess, 12.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.5ms\n",
            "Speed: 3.3ms preprocess, 10.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.0ms\n",
            "Speed: 3.2ms preprocess, 11.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9.4ms\n",
            "Speed: 8.4ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 8.8ms\n",
            "Speed: 2.9ms preprocess, 8.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9.5ms\n",
            "Speed: 2.8ms preprocess, 9.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 7.7ms\n",
            "Speed: 3.2ms preprocess, 7.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 15.3ms\n",
            "Speed: 2.9ms preprocess, 15.3ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9.6ms\n",
            "Speed: 3.2ms preprocess, 9.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.3ms\n",
            "Speed: 3.0ms preprocess, 11.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 13.7ms\n",
            "Speed: 3.0ms preprocess, 13.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.7ms\n",
            "Speed: 3.2ms preprocess, 10.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.7ms\n",
            "Speed: 3.2ms preprocess, 11.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12.4ms\n",
            "Speed: 3.6ms preprocess, 12.4ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.7ms\n",
            "Speed: 3.0ms preprocess, 10.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 13.5ms\n",
            "Speed: 3.2ms preprocess, 13.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-17-1633277437.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m       \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mestimation_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mestimation_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/model.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, source, stream, **kwargs)\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0;34m...\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Detected {len(r)} objects in image\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \"\"\"\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/model.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, source, stream, predictor, **kwargs)\u001b[0m\n\u001b[1;32m    553\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprompts\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"set_prompts\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# for SAM-type models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_prompts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_cli\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_cli\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m     def track(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/predictor.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, source, model, stream, *args, **kwargs)\u001b[0m\n\u001b[1;32m    225\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# merge list of Result into one\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_cli\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mgenerator_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;31m# Issuing `None` to a generator fires it up\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m                 \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/predictor.py\u001b[0m in \u001b[0;36mstream_inference\u001b[0;34m(self, source, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    328\u001b[0m                 \u001b[0;31m# Inference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mprofilers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m                     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m                         \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mpreds\u001b[0m  \u001b[0;31m# yield embedding tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/predictor.py\u001b[0m in \u001b[0;36minference\u001b[0;34m(self, im, *args, **kwargs)\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;32melse\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         )\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maugment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maugment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisualize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvisualize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpre_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/nn/autobackend.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, im, augment, visualize, embed, **kwargs)\u001b[0m\n\u001b[1;32m    642\u001b[0m         \u001b[0;31m# PyTorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpt\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn_module\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maugment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maugment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisualize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvisualize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m         \u001b[0;31m# TorchScript\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/nn/tasks.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# for cases of training and validating while training.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprofile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisualize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maugment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/nn/tasks.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, profile, visualize, augment, embed)\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0maugment\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict_augment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprofile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisualize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_predict_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprofile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisualize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/nn/tasks.py\u001b[0m in \u001b[0;36m_predict_once\u001b[0;34m(self, x, profile, visualize, embed)\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mprofile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_profile_one_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# save output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvisualize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/nn/modules/head.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[0;34m\"\"\"Perform forward pass through YOLO model and return predictions.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0mbs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# batch size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m         \u001b[0mkpt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv4\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (bs, 17*3, h*w)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    379\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDetect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/nn/modules/head.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[0;34m\"\"\"Perform forward pass through YOLO model and return predictions.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0mbs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# batch size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m         \u001b[0mkpt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv4\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (bs, 17*3, h*w)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    379\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDetect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    547\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m             )\n\u001b[0;32m--> 549\u001b[0;31m         return F.conv2d(\n\u001b[0m\u001b[1;32m    550\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m         )\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "columns = ('filename','keypoints', 'label', 'camera')\n",
        "\n",
        "data = []\n",
        "\n",
        "model = YOLO(\"yolov8n-pose.pt\")\n",
        "\n",
        "for label, cam, video_file in video_files_list:\n",
        "  cap = cv2.VideoCapture(f'{folder_path}/{label}/{cam}/{video_file}')\n",
        "\n",
        "  results  = []\n",
        "\n",
        "  while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "      break\n",
        "\n",
        "    estimation_result = model(frame)\n",
        "\n",
        "    for r in estimation_result:\n",
        "      results.append(r.keypoints.xy.cpu().numpy())\n",
        "\n",
        "  data.append((video_file, results, label, cam))\n",
        "\n",
        "  cap.release()\n",
        "\n",
        "df = pd.DataFrame(data, columns=columns)\n",
        "#df.to_csv('extracted_keypoints.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BwpZJU2wfp-z"
      },
      "outputs": [],
      "source": [
        "df.to_pickle('extracted_keypoints.pkl')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ryrBW7B0HzuK"
      },
      "source": [
        "## Selected keyframes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AOje2f_wKecw"
      },
      "outputs": [],
      "source": [
        "keyframes_dataset_path = '/drive/MyDrive/AIRTLab/'\n",
        "\n",
        "image_files_list = get_data_files(keyframes_dataset_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y7774v6aMLah",
        "outputId": "5f8c623f-9069-4b15-a1be-715ca110e5c6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('test', 'non-violent', 'v37f2.jpg')"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "image_files_list[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xh6PGEHZKpnX",
        "outputId": "8271f326-80c8-402e-fd3e-ecfe8f945c5b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/test/violent/v104f10.jpg: 384x640 4 persons, 17.1ms\n",
            "Speed: 3.3ms preprocess, 17.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        }
      ],
      "source": [
        "model = YOLO(\"yolov8n-pose.pt\")\n",
        "\n",
        "r = model(keyframes_dataset_path + 'test/violent/v104f10.jpg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ewaM3EhH1uI",
        "outputId": "248549c7-6bc6-42d2-e85c-925c92b3b23f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n-pose.pt to 'yolov8n-pose.pt': 100% ━━━━━━━━━━━━ 6.5MB 94.2MB/s 0.1s\n"
          ]
        }
      ],
      "source": [
        "columns = ('filename','keypoints', 'label', 'set_split')\n",
        "\n",
        "data = []\n",
        "\n",
        "model = YOLO(\"yolov8n-pose.pt\")\n",
        "\n",
        "for set_split, label, image_file in image_files_list:\n",
        "\n",
        "  results  = []\n",
        "\n",
        "  file_path = f'{keyframes_dataset_path}/{set_split}/{label}/{image_file}'\n",
        "\n",
        "  estimation_result = model(file_path)\n",
        "\n",
        "  for r in estimation_result:\n",
        "    results.append(r.keypoints.xy.cpu().numpy())\n",
        "\n",
        "  data.append((image_file, results, label, set_split))\n",
        "\n",
        "\n",
        "df = pd.DataFrame(data, columns=columns)\n",
        "#df.to_csv('extracted_keypoints.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqn8frqNAVqJ"
      },
      "source": [
        "# Feature Vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nUvXD1WcgHwG"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from scipy.ndimage import uniform_filter1d"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def keypoint_statistics_features(keypoints_sequence):\n",
        "    if keypoints_sequence.shape[0] < 1:\n",
        "        return None  # Not enough frames\n",
        "\n",
        "    smoothed_sequence = uniform_filter1d(keypoints_sequence, size=3, axis=0, mode='nearest')\n",
        "\n",
        "    stats = [\n",
        "        np.min(smoothed_sequence, axis=0),\n",
        "        np.max(smoothed_sequence, axis=0),\n",
        "        np.mean(smoothed_sequence, axis=0),\n",
        "        np.std(smoothed_sequence, axis=0),\n",
        "        np.median(smoothed_sequence, axis=0),\n",
        "        np.max(smoothed_sequence, axis=0) - np.min(smoothed_sequence, axis=0),\n",
        "        np.percentile(smoothed_sequence, 25, axis=0),\n",
        "        np.percentile(smoothed_sequence, 75, axis=0),\n",
        "    ]\n",
        "\n",
        "\n",
        "    features = [stat.flatten() for stat in stats]\n",
        "    return np.concatenate(features)\n",
        "\n",
        "def aggregate_video_features2(video_person_skeletons, pooling='mean'):\n",
        "    person_features = []\n",
        "\n",
        "    for keypoints_sequence in video_person_skeletons:\n",
        "        feats = keypoint_statistics_features(np.array(keypoints_sequence))\n",
        "        if feats is not None:\n",
        "            person_features.append(feats)\n",
        "\n",
        "    if not person_features:\n",
        "        return np.zeros(204)\n",
        "\n",
        "    person_features = np.array(person_features)\n",
        "\n",
        "    if pooling == 'mean':\n",
        "        return np.mean(person_features, axis=0)\n",
        "    elif pooling == 'max':\n",
        "        return np.max(person_features, axis=0)\n",
        "    else:\n",
        "        raise ValueError(\"Pooling must be 'mean' or 'max'\")"
      ],
      "metadata": {
        "id": "qRKqlFfZppa3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "z91JNbAUBRD6",
        "outputId": "a84d73ed-0dd2-479e-b151-0842c297f100"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  filename                                          keypoints    label camera\n",
              "0   49.mp4  [[[[     1300.7      665.07], [     1312.5    ...  violent   cam2\n",
              "1  104.mp4  [[[[     955.61         420], [     954.25    ...  violent   cam2\n",
              "2   84.mp4  [[[[     582.17      242.16], [     583.53    ...  violent   cam2\n",
              "3   11.mp4  [[[[     1313.6      158.94], [     1324.4    ...  violent   cam2\n",
              "4  109.mp4  [[[[     1025.4       610.7], [     1014.9    ...  violent   cam2"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5a15f284-805c-43ca-94ce-37f6d47da7e7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>keypoints</th>\n",
              "      <th>label</th>\n",
              "      <th>camera</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>49.mp4</td>\n",
              "      <td>[[[[     1300.7      665.07], [     1312.5    ...</td>\n",
              "      <td>violent</td>\n",
              "      <td>cam2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>104.mp4</td>\n",
              "      <td>[[[[     955.61         420], [     954.25    ...</td>\n",
              "      <td>violent</td>\n",
              "      <td>cam2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>84.mp4</td>\n",
              "      <td>[[[[     582.17      242.16], [     583.53    ...</td>\n",
              "      <td>violent</td>\n",
              "      <td>cam2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.mp4</td>\n",
              "      <td>[[[[     1313.6      158.94], [     1324.4    ...</td>\n",
              "      <td>violent</td>\n",
              "      <td>cam2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>109.mp4</td>\n",
              "      <td>[[[[     1025.4       610.7], [     1014.9    ...</td>\n",
              "      <td>violent</td>\n",
              "      <td>cam2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5a15f284-805c-43ca-94ce-37f6d47da7e7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5a15f284-805c-43ca-94ce-37f6d47da7e7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5a15f284-805c-43ca-94ce-37f6d47da7e7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-041c839d-5697-4919-92f8-89a04e944f26\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-041c839d-5697-4919-92f8-89a04e944f26')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-041c839d-5697-4919-92f8-89a04e944f26 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 350,\n  \"fields\": [\n    {\n      \"column\": \"filename\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 115,\n        \"samples\": [\n          \"12.mp4\",\n          \"109.mp4\",\n          \"76.mp4\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"keypoints\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"non-violent\",\n          \"violent\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"camera\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"cam1\",\n          \"cam2\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "df = pd.read_pickle('extracted_keypoints.pkl')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def extract_info(filename):\n",
        "        match = re.match(r'v(\\d+)f(\\d+)\\.jpg', filename)\n",
        "        if match:\n",
        "            return int(match.group(1)), int(match.group(2))\n",
        "        return None, None\n",
        "def create_grouped_keypoints_dataframe(df):\n",
        "    # Extract video and frame number\n",
        "\n",
        "    df[['video', 'frame']] = df['filename'].apply(lambda x: pd.Series(extract_info(x)))\n",
        "\n",
        "    # Group and sort by video and split\n",
        "    grouped = df.groupby(['video', 'set_split'])\n",
        "\n",
        "    grouped_data = []\n",
        "    for (video, split), group in grouped:\n",
        "        group_sorted = group.sort_values(by='frame')\n",
        "        keypoints_sequence = [kp[0] for kp in group_sorted['keypoints']]  # flatten single-element lists\n",
        "        grouped_data.append({\n",
        "            'videofile': f'v{video}',\n",
        "            'keypoints': keypoints_sequence,\n",
        "            'set_split': split\n",
        "        })\n",
        "\n",
        "    # Create new DataFrame\n",
        "    return pd.DataFrame(grouped_data)"
      ],
      "metadata": {
        "id": "TQzlFmO0A5O_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CbKDb0Su92YX"
      },
      "outputs": [],
      "source": [
        "keypoints_list = np.array(df['keypoints'].copy())\n",
        "video_features = []\n",
        "for video in keypoints_list:\n",
        "    # `video` is a dict: {person_id: [skeletons_per_frame]}\n",
        "    fvec = aggregate_video_features(video, pooling='max')\n",
        "    video_features.append(fvec)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keypoints_list = np.array(df['keypoints'].copy())\n",
        "video_features = []\n",
        "for video in keypoints_list:\n",
        "    # `video` is a dict: {person_id: [skeletons_per_frame]}\n",
        "    fvec = aggregate_video_features2(video, pooling='max')\n",
        "    video_features.append(fvec)"
      ],
      "metadata": {
        "id": "Z5zf1AU2p97E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['feature_vectors'] = video_features\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "ZF9868MJOXvG",
        "outputId": "22024816-e452-4d1c-9642-3c07f0430dc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    filename                                          keypoints        label  \\\n",
              "0     49.mp4  [[[[     1300.7      665.07], [     1312.5    ...      violent   \n",
              "1    104.mp4  [[[[     955.61         420], [     954.25    ...      violent   \n",
              "2     84.mp4  [[[[     582.17      242.16], [     583.53    ...      violent   \n",
              "3     11.mp4  [[[[     1313.6      158.94], [     1324.4    ...      violent   \n",
              "4    109.mp4  [[[[     1025.4       610.7], [     1014.9    ...      violent   \n",
              "..       ...                                                ...          ...   \n",
              "345   33.mp4  [[[[     1079.7      181.36], [     1093.4    ...  non-violent   \n",
              "346   39.mp4  [[[[     831.11      282.21], [     833.77    ...  non-violent   \n",
              "347   60.mp4  [[[[     1034.3      164.69], [     1046.1    ...  non-violent   \n",
              "348   20.mp4  [[[[       1041      570.82], [     1036.3    ...  non-violent   \n",
              "349   57.mp4  [[[[     1319.9      387.78], [     1314.4    ...  non-violent   \n",
              "\n",
              "    camera                                    feature_vectors  \n",
              "0     cam2  [1129.1244, 480.76425, 1134.6652, 469.11688, 1...  \n",
              "1     cam2  [1118.5825, 495.6267, 1115.4192, 488.03247, 11...  \n",
              "2     cam2  [905.5891, 345.35834, 914.1955, 334.72183, 894...  \n",
              "3     cam2  [1515.2991, 356.51144, 1520.8922, 346.67654, 1...  \n",
              "4     cam2  [924.60443, 550.16144, 925.4054, 541.961, 919....  \n",
              "..     ...                                                ...  \n",
              "345   cam1  [1019.59924, 229.0736, 1030.3308, 219.59088, 1...  \n",
              "346   cam1  [1153.6123, 432.62808, 1157.3484, 418.45932, 1...  \n",
              "347   cam1  [887.33716, 269.94238, 889.05133, 258.94016, 8...  \n",
              "348   cam1  [949.01996, 149.87105, 953.23376, 139.26009, 9...  \n",
              "349   cam1  [1106.5881, 254.0713, 1102.7256, 245.05313, 11...  \n",
              "\n",
              "[350 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cbce5692-2fb1-4543-9a1a-afaa0c1b22c8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>keypoints</th>\n",
              "      <th>label</th>\n",
              "      <th>camera</th>\n",
              "      <th>feature_vectors</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>49.mp4</td>\n",
              "      <td>[[[[     1300.7      665.07], [     1312.5    ...</td>\n",
              "      <td>violent</td>\n",
              "      <td>cam2</td>\n",
              "      <td>[1129.1244, 480.76425, 1134.6652, 469.11688, 1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>104.mp4</td>\n",
              "      <td>[[[[     955.61         420], [     954.25    ...</td>\n",
              "      <td>violent</td>\n",
              "      <td>cam2</td>\n",
              "      <td>[1118.5825, 495.6267, 1115.4192, 488.03247, 11...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>84.mp4</td>\n",
              "      <td>[[[[     582.17      242.16], [     583.53    ...</td>\n",
              "      <td>violent</td>\n",
              "      <td>cam2</td>\n",
              "      <td>[905.5891, 345.35834, 914.1955, 334.72183, 894...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.mp4</td>\n",
              "      <td>[[[[     1313.6      158.94], [     1324.4    ...</td>\n",
              "      <td>violent</td>\n",
              "      <td>cam2</td>\n",
              "      <td>[1515.2991, 356.51144, 1520.8922, 346.67654, 1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>109.mp4</td>\n",
              "      <td>[[[[     1025.4       610.7], [     1014.9    ...</td>\n",
              "      <td>violent</td>\n",
              "      <td>cam2</td>\n",
              "      <td>[924.60443, 550.16144, 925.4054, 541.961, 919....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>345</th>\n",
              "      <td>33.mp4</td>\n",
              "      <td>[[[[     1079.7      181.36], [     1093.4    ...</td>\n",
              "      <td>non-violent</td>\n",
              "      <td>cam1</td>\n",
              "      <td>[1019.59924, 229.0736, 1030.3308, 219.59088, 1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>346</th>\n",
              "      <td>39.mp4</td>\n",
              "      <td>[[[[     831.11      282.21], [     833.77    ...</td>\n",
              "      <td>non-violent</td>\n",
              "      <td>cam1</td>\n",
              "      <td>[1153.6123, 432.62808, 1157.3484, 418.45932, 1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>347</th>\n",
              "      <td>60.mp4</td>\n",
              "      <td>[[[[     1034.3      164.69], [     1046.1    ...</td>\n",
              "      <td>non-violent</td>\n",
              "      <td>cam1</td>\n",
              "      <td>[887.33716, 269.94238, 889.05133, 258.94016, 8...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>348</th>\n",
              "      <td>20.mp4</td>\n",
              "      <td>[[[[       1041      570.82], [     1036.3    ...</td>\n",
              "      <td>non-violent</td>\n",
              "      <td>cam1</td>\n",
              "      <td>[949.01996, 149.87105, 953.23376, 139.26009, 9...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>349</th>\n",
              "      <td>57.mp4</td>\n",
              "      <td>[[[[     1319.9      387.78], [     1314.4    ...</td>\n",
              "      <td>non-violent</td>\n",
              "      <td>cam1</td>\n",
              "      <td>[1106.5881, 254.0713, 1102.7256, 245.05313, 11...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>350 rows × 5 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cbce5692-2fb1-4543-9a1a-afaa0c1b22c8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-cbce5692-2fb1-4543-9a1a-afaa0c1b22c8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-cbce5692-2fb1-4543-9a1a-afaa0c1b22c8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-30a8303a-0bce-4d31-8612-5b83ecb8ceca\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-30a8303a-0bce-4d31-8612-5b83ecb8ceca')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-30a8303a-0bce-4d31-8612-5b83ecb8ceca button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_8dd19b33-b733-4899-8e41-1ca8a898051f\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_8dd19b33-b733-4899-8e41-1ca8a898051f button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 350,\n  \"fields\": [\n    {\n      \"column\": \"filename\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 115,\n        \"samples\": [\n          \"12.mp4\",\n          \"109.mp4\",\n          \"76.mp4\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"keypoints\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"non-violent\",\n          \"violent\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"camera\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"cam1\",\n          \"cam2\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"feature_vectors\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OsPpJnv68TAI"
      },
      "source": [
        "# Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QjvDfR0sL82B"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ITMX9RZhbfm"
      },
      "outputs": [],
      "source": [
        "df_classifier = df.drop(columns=['filename', 'keypoints', 'camera'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wp2QC5DZhfr5"
      },
      "outputs": [],
      "source": [
        "X = np.vstack(df_classifier['feature_vectors'])\n",
        "y = df_classifier['label']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def classify(clf):\n",
        "  clf.fit(X_train, y_train)\n",
        "\n",
        "  y_pred = clf.predict(X_test)\n",
        "\n",
        "  accuracy = accuracy_score(y_test, y_pred)\n",
        "  precision = precision_score(y_test, y_pred, average='macro')  # use 'macro' for multiclass\n",
        "  recall = recall_score(y_test, y_pred, average='macro')\n",
        "  f1 = f1_score(y_test, y_pred, average='macro')\n",
        "\n",
        "  print(f\"Accuracy:  {accuracy:.4f}\")\n",
        "  print(f\"Precision: {precision:.4f}\")\n",
        "  print(f\"Recall:    {recall:.4f}\")\n",
        "  print(f\"F1 Score:  {f1:.4f}\")"
      ],
      "metadata": {
        "id": "eXgrLL6lQJjm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "classify(RandomForestClassifier())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PxS6Fwgp2q8y",
        "outputId": "01e9c5a9-c993-4da9-daf4-b8ffce544354"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.8276\n",
            "Precision: 0.8116\n",
            "Recall:    0.7942\n",
            "F1 Score:  0.8016\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JFPT5ZTlkl73",
        "outputId": "d3121b48-7b6d-457e-aecf-6152ab122e21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.7414\n",
            "Precision: 0.7335\n",
            "Recall:    0.7609\n",
            "F1 Score:  0.7317\n"
          ]
        }
      ],
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "classify(GaussianNB())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "classify(KNeighborsClassifier(n_neighbors=5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r8oYairPO-JA",
        "outputId": "6d9c1c84-7ff6-49db-d663-cd46a86641c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.7931\n",
            "Precision: 0.7700\n",
            "Recall:    0.7872\n",
            "F1 Score:  0.7761\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "classify(make_pipeline(StandardScaler(), SVC(gamma='auto')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fixpI6WURA1Z",
        "outputId": "12945cc4-4df4-4dde-e827-77e37d327405"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.8621\n",
            "Precision: 0.8580\n",
            "Recall:    0.8265\n",
            "F1 Score:  0.8389\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CNNs"
      ],
      "metadata": {
        "id": "0OpB0wNQDr72"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Full videos"
      ],
      "metadata": {
        "id": "EzRtsF1n04qr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from ultralytics import YOLO\n",
        "import cv2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7gOadjALDt6Z",
        "outputId": "02a526fe-c00a-457a-a7f7-87a403d2a9e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_data_files(folder_path):\n",
        "    video_files = []\n",
        "\n",
        "    for root, dirs, files in os.walk(folder_path):\n",
        "        subfolder_list = root.split(os.path.sep)\n",
        "        v_nv = subfolder_list[-2]\n",
        "        c1_c2 = subfolder_list[-1]\n",
        "\n",
        "        video_files.extend([(v_nv, c1_c2, file) for file in files if file.lower().endswith(('.mp4', '.jpg'))])\n",
        "\n",
        "    return video_files"
      ],
      "metadata": {
        "id": "z4v80t80e9U_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "folder_path = '/content/A-Dataset-for-Automatic-Violence-Detection-in-Videos/violence-detection-dataset'\n",
        "\n",
        "video_files_list = get_data_files(folder_path)"
      ],
      "metadata": {
        "id": "GSBZ4nRCft5N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "video_files_list[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cHOLIlNhdvO",
        "outputId": "12b38152-a2df-49f4-dd6f-226f47466781"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('non-violent', 'cam2', '56.mp4')"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = YOLO(\"yolov8n-pose.pt\")\n",
        "\n",
        "new_dataset_path = \"skeletons_drawn_dataset\"\n",
        "\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "\n",
        "skeleton_connections = [\n",
        "    (5, 7), (7, 9),     # Left arm\n",
        "    (6, 8), (8, 10),    # Right arm\n",
        "    (5, 6),             # Shoulders\n",
        "    (11, 12),           # Hips\n",
        "    (5, 11), (6, 12),   # Torso\n",
        "    (11, 13), (13, 15), # Left leg\n",
        "    (12, 14), (14, 16)  # Right leg\n",
        "]\n",
        "\n",
        "\n",
        "for label, cam, video_file in video_files_list:\n",
        "  cap = cv2.VideoCapture(f'{folder_path}/{label}/{cam}/{video_file}')\n",
        "\n",
        "  cap_height = np.int_(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "  cap_width = np.int_(cap.get(cv2.CAP_PROP_FRAME_WIDTH ))\n",
        "  cap_fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "  out  = cv2.VideoWriter(f'{new_dataset_path}/{label}/{cam}/{\"new-\"+video_file}', fourcc, cap_fps, (cap_width, cap_height))\n",
        "\n",
        "  while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "      break\n",
        "\n",
        "    results = model(frame)\n",
        "\n",
        "    for result in results:\n",
        "        kpts = result.keypoints\n",
        "        if kpts is None:\n",
        "            continue\n",
        "\n",
        "        keypoints = kpts.xy.cpu().numpy()\n",
        "\n",
        "        for person in keypoints:\n",
        "            # Draw keypoints\n",
        "            for x, y in person:\n",
        "                cv2.circle(frame, (int(x), int(y)), 3, (0, 255, 0), -1)\n",
        "\n",
        "            # Draw connections (skeleton)\n",
        "            for idx1, idx2 in skeleton_connections:\n",
        "                x1, y1 = person[idx1]\n",
        "                x2, y2 = person[idx2]\n",
        "                if x1 > 0 and y1 > 0 and x2 > 0 and y2 > 0:  # valid points\n",
        "                    cv2.line(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 255), 2)\n",
        "\n",
        "    out.write(frame)\n",
        "\n",
        "  cap.release()\n",
        "  out.release()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dwBC1tKOfudZ",
        "outputId": "aa42a6b7-22d9-4310-c934-2df222cf162d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "0: 384x640 3 persons, 11.3ms\n",
            "Speed: 3.4ms preprocess, 11.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 15.1ms\n",
            "Speed: 3.3ms preprocess, 15.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12.3ms\n",
            "Speed: 3.4ms preprocess, 12.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.8ms\n",
            "Speed: 3.2ms preprocess, 11.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.7ms\n",
            "Speed: 3.2ms preprocess, 11.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 9.4ms\n",
            "Speed: 7.4ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.6ms\n",
            "Speed: 3.2ms preprocess, 11.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 7.5ms\n",
            "Speed: 3.2ms preprocess, 7.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 13.1ms\n",
            "Speed: 3.3ms preprocess, 13.1ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9.5ms\n",
            "Speed: 3.3ms preprocess, 9.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 13.7ms\n",
            "Speed: 3.1ms preprocess, 13.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.3ms\n",
            "Speed: 3.2ms preprocess, 11.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.0ms\n",
            "Speed: 3.4ms preprocess, 11.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12.0ms\n",
            "Speed: 3.4ms preprocess, 12.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 8.1ms\n",
            "Speed: 3.5ms preprocess, 8.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 7.6ms\n",
            "Speed: 2.9ms preprocess, 7.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9.5ms\n",
            "Speed: 7.7ms preprocess, 9.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12.8ms\n",
            "Speed: 3.7ms preprocess, 12.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 13.3ms\n",
            "Speed: 3.4ms preprocess, 13.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12.4ms\n",
            "Speed: 3.2ms preprocess, 12.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.5ms\n",
            "Speed: 3.3ms preprocess, 11.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.8ms\n",
            "Speed: 3.2ms preprocess, 11.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.9ms\n",
            "Speed: 3.4ms preprocess, 10.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 16.7ms\n",
            "Speed: 3.2ms preprocess, 16.7ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 8.1ms\n",
            "Speed: 3.5ms preprocess, 8.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 14.6ms\n",
            "Speed: 3.8ms preprocess, 14.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 13.0ms\n",
            "Speed: 3.3ms preprocess, 13.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.6ms\n",
            "Speed: 3.2ms preprocess, 11.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.3ms\n",
            "Speed: 3.5ms preprocess, 11.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 8.4ms\n",
            "Speed: 3.3ms preprocess, 8.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 9.8ms\n",
            "Speed: 7.6ms preprocess, 9.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.7ms\n",
            "Speed: 3.3ms preprocess, 10.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 18.6ms\n",
            "Speed: 4.9ms preprocess, 18.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.8ms\n",
            "Speed: 3.1ms preprocess, 11.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 7.5ms\n",
            "Speed: 2.9ms preprocess, 7.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.8ms\n",
            "Speed: 3.1ms preprocess, 11.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 11.7ms\n",
            "Speed: 3.2ms preprocess, 11.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.8ms\n",
            "Speed: 3.1ms preprocess, 11.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.5ms\n",
            "Speed: 3.3ms preprocess, 11.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 10.4ms\n",
            "Speed: 5.8ms preprocess, 10.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.1ms\n",
            "Speed: 3.3ms preprocess, 10.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.6ms\n",
            "Speed: 3.2ms preprocess, 11.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 8.6ms\n",
            "Speed: 3.4ms preprocess, 8.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 11.6ms\n",
            "Speed: 3.4ms preprocess, 11.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.7ms\n",
            "Speed: 3.3ms preprocess, 11.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.4ms\n",
            "Speed: 3.8ms preprocess, 11.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 12.6ms\n",
            "Speed: 3.4ms preprocess, 12.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 13.5ms\n",
            "Speed: 3.4ms preprocess, 13.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.3ms\n",
            "Speed: 3.5ms preprocess, 11.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 13.6ms\n",
            "Speed: 3.6ms preprocess, 13.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.6ms\n",
            "Speed: 3.6ms preprocess, 11.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 12.6ms\n",
            "Speed: 3.3ms preprocess, 12.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 12.9ms\n",
            "Speed: 3.4ms preprocess, 12.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.6ms\n",
            "Speed: 7.6ms preprocess, 10.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.6ms\n",
            "Speed: 3.2ms preprocess, 11.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.4ms\n",
            "Speed: 3.4ms preprocess, 10.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.3ms\n",
            "Speed: 3.3ms preprocess, 11.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.1ms\n",
            "Speed: 3.4ms preprocess, 11.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 13.3ms\n",
            "Speed: 3.4ms preprocess, 13.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.0ms\n",
            "Speed: 4.5ms preprocess, 11.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 11.3ms\n",
            "Speed: 3.3ms preprocess, 11.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 11.8ms\n",
            "Speed: 4.0ms preprocess, 11.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.8ms\n",
            "Speed: 3.5ms preprocess, 11.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 12.8ms\n",
            "Speed: 3.5ms preprocess, 12.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.5ms\n",
            "Speed: 3.4ms preprocess, 11.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 11.5ms\n",
            "Speed: 3.2ms preprocess, 11.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 7.4ms\n",
            "Speed: 2.9ms preprocess, 7.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 7.8ms\n",
            "Speed: 2.9ms preprocess, 7.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.3ms\n",
            "Speed: 3.4ms preprocess, 11.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 21.5ms\n",
            "Speed: 4.5ms preprocess, 21.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 11.0ms\n",
            "Speed: 3.1ms preprocess, 11.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.9ms\n",
            "Speed: 3.3ms preprocess, 11.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.6ms\n",
            "Speed: 3.3ms preprocess, 11.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.2ms\n",
            "Speed: 3.1ms preprocess, 11.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.6ms\n",
            "Speed: 4.1ms preprocess, 10.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 7.7ms\n",
            "Speed: 2.4ms preprocess, 7.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 9.8ms\n",
            "Speed: 3.3ms preprocess, 9.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.9ms\n",
            "Speed: 3.9ms preprocess, 11.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 8.8ms\n",
            "Speed: 3.3ms preprocess, 8.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 7.5ms\n",
            "Speed: 3.2ms preprocess, 7.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 8.5ms\n",
            "Speed: 11.4ms preprocess, 8.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.5ms\n",
            "Speed: 4.2ms preprocess, 11.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 13.5ms\n",
            "Speed: 3.3ms preprocess, 13.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 11.6ms\n",
            "Speed: 3.3ms preprocess, 11.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 7.8ms\n",
            "Speed: 3.4ms preprocess, 7.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 12.2ms\n",
            "Speed: 3.5ms preprocess, 12.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 12.1ms\n",
            "Speed: 3.2ms preprocess, 12.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 11.2ms\n",
            "Speed: 3.5ms preprocess, 11.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 12.8ms\n",
            "Speed: 3.1ms preprocess, 12.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.6ms\n",
            "Speed: 3.4ms preprocess, 11.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 8.9ms\n",
            "Speed: 3.2ms preprocess, 8.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 14.2ms\n",
            "Speed: 3.2ms preprocess, 14.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 12.6ms\n",
            "Speed: 3.3ms preprocess, 12.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 14.3ms\n",
            "Speed: 3.1ms preprocess, 14.3ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.2ms\n",
            "Speed: 3.3ms preprocess, 11.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 11.1ms\n",
            "Speed: 3.2ms preprocess, 11.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 13.4ms\n",
            "Speed: 3.1ms preprocess, 13.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.4ms\n",
            "Speed: 3.2ms preprocess, 11.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.9ms\n",
            "Speed: 3.2ms preprocess, 10.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 12.2ms\n",
            "Speed: 3.4ms preprocess, 12.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 11.4ms\n",
            "Speed: 3.5ms preprocess, 11.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.5ms\n",
            "Speed: 3.3ms preprocess, 11.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.2ms\n",
            "Speed: 3.3ms preprocess, 11.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.9ms\n",
            "Speed: 3.2ms preprocess, 10.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.5ms\n",
            "Speed: 3.4ms preprocess, 11.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 9.0ms\n",
            "Speed: 3.9ms preprocess, 9.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 12.4ms\n",
            "Speed: 3.3ms preprocess, 12.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.3ms\n",
            "Speed: 3.7ms preprocess, 11.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 11.8ms\n",
            "Speed: 3.4ms preprocess, 11.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 12.0ms\n",
            "Speed: 3.9ms preprocess, 12.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.3ms\n",
            "Speed: 4.0ms preprocess, 10.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.3ms\n",
            "Speed: 3.0ms preprocess, 10.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 9.2ms\n",
            "Speed: 3.3ms preprocess, 9.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 13.0ms\n",
            "Speed: 4.0ms preprocess, 13.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 13.1ms\n",
            "Speed: 3.2ms preprocess, 13.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 7.5ms\n",
            "Speed: 2.3ms preprocess, 7.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 11.8ms\n",
            "Speed: 3.2ms preprocess, 11.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 7.9ms\n",
            "Speed: 2.6ms preprocess, 7.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 12.4ms\n",
            "Speed: 3.7ms preprocess, 12.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 8.6ms\n",
            "Speed: 6.6ms preprocess, 8.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 10.3ms\n",
            "Speed: 8.9ms preprocess, 10.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.6ms\n",
            "Speed: 3.3ms preprocess, 11.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 9.7ms\n",
            "Speed: 3.3ms preprocess, 9.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.4ms\n",
            "Speed: 3.3ms preprocess, 11.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 7.8ms\n",
            "Speed: 3.3ms preprocess, 7.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 12.0ms\n",
            "Speed: 4.0ms preprocess, 12.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 9.8ms\n",
            "Speed: 3.3ms preprocess, 9.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 7.5ms\n",
            "Speed: 3.2ms preprocess, 7.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 12.1ms\n",
            "Speed: 3.3ms preprocess, 12.1ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 11.4ms\n",
            "Speed: 3.2ms preprocess, 11.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.4ms\n",
            "Speed: 3.1ms preprocess, 11.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 12.4ms\n",
            "Speed: 3.2ms preprocess, 12.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 13.0ms\n",
            "Speed: 3.5ms preprocess, 13.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 12.9ms\n",
            "Speed: 3.7ms preprocess, 12.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 8.4ms\n",
            "Speed: 3.3ms preprocess, 8.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 7.6ms\n",
            "Speed: 8.5ms preprocess, 7.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.9ms\n",
            "Speed: 3.6ms preprocess, 10.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 18.3ms\n",
            "Speed: 3.3ms preprocess, 18.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 8.0ms\n",
            "Speed: 2.8ms preprocess, 8.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.7ms\n",
            "Speed: 4.0ms preprocess, 10.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.3ms\n",
            "Speed: 3.3ms preprocess, 11.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 13.4ms\n",
            "Speed: 3.5ms preprocess, 13.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 7.6ms\n",
            "Speed: 2.9ms preprocess, 7.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 13.0ms\n",
            "Speed: 3.5ms preprocess, 13.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 9.5ms\n",
            "Speed: 5.5ms preprocess, 9.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.6ms\n",
            "Speed: 3.9ms preprocess, 10.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 8.5ms\n",
            "Speed: 3.3ms preprocess, 8.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 9.5ms\n",
            "Speed: 3.3ms preprocess, 9.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 8.7ms\n",
            "Speed: 4.2ms preprocess, 8.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.3ms\n",
            "Speed: 6.0ms preprocess, 11.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.6ms\n",
            "Speed: 3.3ms preprocess, 10.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 8.1ms\n",
            "Speed: 3.3ms preprocess, 8.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.7ms\n",
            "Speed: 3.2ms preprocess, 10.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 9.6ms\n",
            "Speed: 3.4ms preprocess, 9.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 11.3ms\n",
            "Speed: 3.2ms preprocess, 11.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 10.4ms\n",
            "Speed: 3.3ms preprocess, 10.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 8.0ms\n",
            "Speed: 4.4ms preprocess, 8.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.0ms\n",
            "Speed: 3.5ms preprocess, 10.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.7ms\n",
            "Speed: 3.2ms preprocess, 11.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 13.5ms\n",
            "Speed: 3.1ms preprocess, 13.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 8.7ms\n",
            "Speed: 3.2ms preprocess, 8.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 12.4ms\n",
            "Speed: 3.5ms preprocess, 12.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.9ms\n",
            "Speed: 3.5ms preprocess, 11.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 8.9ms\n",
            "Speed: 3.2ms preprocess, 8.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.1ms\n",
            "Speed: 3.2ms preprocess, 10.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 11.0ms\n",
            "Speed: 3.2ms preprocess, 11.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 11.5ms\n",
            "Speed: 3.2ms preprocess, 11.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 8.2ms\n",
            "Speed: 3.2ms preprocess, 8.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 11.1ms\n",
            "Speed: 3.3ms preprocess, 11.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.6ms\n",
            "Speed: 3.3ms preprocess, 10.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 14.1ms\n",
            "Speed: 3.2ms preprocess, 14.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 12.1ms\n",
            "Speed: 3.3ms preprocess, 12.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.4ms\n",
            "Speed: 3.3ms preprocess, 11.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 12.2ms\n",
            "Speed: 3.8ms preprocess, 12.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 13.3ms\n",
            "Speed: 3.3ms preprocess, 13.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.4ms\n",
            "Speed: 3.5ms preprocess, 11.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 8.2ms\n",
            "Speed: 3.3ms preprocess, 8.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.0ms\n",
            "Speed: 3.2ms preprocess, 11.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.3ms\n",
            "Speed: 3.7ms preprocess, 11.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.5ms\n",
            "Speed: 3.4ms preprocess, 10.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 12.2ms\n",
            "Speed: 3.0ms preprocess, 12.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.9ms\n",
            "Speed: 3.5ms preprocess, 11.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 18.3ms\n",
            "Speed: 8.2ms preprocess, 18.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 14.4ms\n",
            "Speed: 3.6ms preprocess, 14.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 15.9ms\n",
            "Speed: 3.2ms preprocess, 15.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 16.1ms\n",
            "Speed: 7.8ms preprocess, 16.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 20.7ms\n",
            "Speed: 3.2ms preprocess, 20.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 11.6ms\n",
            "Speed: 2.7ms preprocess, 11.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 15.1ms\n",
            "Speed: 3.7ms preprocess, 15.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 14.0ms\n",
            "Speed: 3.2ms preprocess, 14.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 17.2ms\n",
            "Speed: 3.2ms preprocess, 17.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 15.9ms\n",
            "Speed: 3.2ms preprocess, 15.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.2ms\n",
            "Speed: 3.2ms preprocess, 10.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 14.0ms\n",
            "Speed: 3.0ms preprocess, 14.0ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 19.2ms\n",
            "Speed: 4.9ms preprocess, 19.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 18.1ms\n",
            "Speed: 4.4ms preprocess, 18.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.8ms\n",
            "Speed: 3.1ms preprocess, 11.8ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.4ms\n",
            "Speed: 4.1ms preprocess, 10.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.5ms\n",
            "Speed: 4.4ms preprocess, 10.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 22.8ms\n",
            "Speed: 3.4ms preprocess, 22.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 14.3ms\n",
            "Speed: 3.2ms preprocess, 14.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.4ms\n",
            "Speed: 4.2ms preprocess, 10.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.8ms\n",
            "Speed: 3.2ms preprocess, 11.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.6ms\n",
            "Speed: 8.3ms preprocess, 11.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 17.2ms\n",
            "Speed: 3.1ms preprocess, 17.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 14.4ms\n",
            "Speed: 3.4ms preprocess, 14.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.0ms\n",
            "Speed: 3.3ms preprocess, 11.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 9.7ms\n",
            "Speed: 3.5ms preprocess, 9.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.6ms\n",
            "Speed: 3.0ms preprocess, 10.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.9ms\n",
            "Speed: 3.0ms preprocess, 10.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.6ms\n",
            "Speed: 3.2ms preprocess, 11.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.5ms\n",
            "Speed: 5.3ms preprocess, 10.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 14.9ms\n",
            "Speed: 2.7ms preprocess, 14.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.5ms\n",
            "Speed: 3.3ms preprocess, 10.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 12.2ms\n",
            "Speed: 6.2ms preprocess, 12.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.7ms\n",
            "Speed: 4.0ms preprocess, 11.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.6ms\n",
            "Speed: 3.2ms preprocess, 10.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 17.1ms\n",
            "Speed: 3.2ms preprocess, 17.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 21.2ms\n",
            "Speed: 4.3ms preprocess, 21.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 18.2ms\n",
            "Speed: 9.8ms preprocess, 18.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.2ms\n",
            "Speed: 4.4ms preprocess, 10.2ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 16.6ms\n",
            "Speed: 3.2ms preprocess, 16.6ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 20.5ms\n",
            "Speed: 3.3ms preprocess, 20.5ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 15.1ms\n",
            "Speed: 3.4ms preprocess, 15.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 16.7ms\n",
            "Speed: 3.5ms preprocess, 16.7ms inference, 6.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 14.1ms\n",
            "Speed: 5.2ms preprocess, 14.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 17.3ms\n",
            "Speed: 3.3ms preprocess, 17.3ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 20.4ms\n",
            "Speed: 3.3ms preprocess, 20.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 20.0ms\n",
            "Speed: 3.1ms preprocess, 20.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 19.1ms\n",
            "Speed: 3.2ms preprocess, 19.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 17.4ms\n",
            "Speed: 6.0ms preprocess, 17.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 21.8ms\n",
            "Speed: 3.2ms preprocess, 21.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 16.9ms\n",
            "Speed: 3.2ms preprocess, 16.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.4ms\n",
            "Speed: 4.0ms preprocess, 10.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 17.4ms\n",
            "Speed: 4.2ms preprocess, 17.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 26.2ms\n",
            "Speed: 4.2ms preprocess, 26.2ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 18.4ms\n",
            "Speed: 3.2ms preprocess, 18.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 13.0ms\n",
            "Speed: 4.0ms preprocess, 13.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 15.8ms\n",
            "Speed: 3.4ms preprocess, 15.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 17.8ms\n",
            "Speed: 3.3ms preprocess, 17.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 17.5ms\n",
            "Speed: 3.2ms preprocess, 17.5ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 15.9ms\n",
            "Speed: 4.1ms preprocess, 15.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 18.7ms\n",
            "Speed: 4.1ms preprocess, 18.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.3ms\n",
            "Speed: 3.2ms preprocess, 11.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 17.8ms\n",
            "Speed: 3.5ms preprocess, 17.8ms inference, 7.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 10.9ms\n",
            "Speed: 3.2ms preprocess, 10.9ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 17.2ms\n",
            "Speed: 3.2ms preprocess, 17.2ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 19.0ms\n",
            "Speed: 3.3ms preprocess, 19.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 15.4ms\n",
            "Speed: 3.2ms preprocess, 15.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 12.7ms\n",
            "Speed: 7.0ms preprocess, 12.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 14.5ms\n",
            "Speed: 3.2ms preprocess, 14.5ms inference, 6.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 16.4ms\n",
            "Speed: 7.3ms preprocess, 16.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 15.4ms\n",
            "Speed: 3.2ms preprocess, 15.4ms inference, 6.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 9.5ms\n",
            "Speed: 3.1ms preprocess, 9.5ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 14.6ms\n",
            "Speed: 3.2ms preprocess, 14.6ms inference, 7.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 9.7ms\n",
            "Speed: 3.4ms preprocess, 9.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.0ms\n",
            "Speed: 3.5ms preprocess, 10.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.3ms\n",
            "Speed: 4.4ms preprocess, 10.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 17.9ms\n",
            "Speed: 3.2ms preprocess, 17.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 12.2ms\n",
            "Speed: 3.2ms preprocess, 12.2ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.3ms\n",
            "Speed: 3.4ms preprocess, 10.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.9ms\n",
            "Speed: 3.1ms preprocess, 10.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 19.3ms\n",
            "Speed: 7.4ms preprocess, 19.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.9ms\n",
            "Speed: 3.4ms preprocess, 10.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.3ms\n",
            "Speed: 3.3ms preprocess, 10.3ms inference, 7.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.6ms\n",
            "Speed: 3.3ms preprocess, 11.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 12.5ms\n",
            "Speed: 3.1ms preprocess, 12.5ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 15.8ms\n",
            "Speed: 3.2ms preprocess, 15.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 14.9ms\n",
            "Speed: 5.4ms preprocess, 14.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 14.5ms\n",
            "Speed: 3.1ms preprocess, 14.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 17.3ms\n",
            "Speed: 3.4ms preprocess, 17.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 14.7ms\n",
            "Speed: 6.7ms preprocess, 14.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.1ms\n",
            "Speed: 3.3ms preprocess, 11.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 16.4ms\n",
            "Speed: 3.0ms preprocess, 16.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 17.2ms\n",
            "Speed: 3.3ms preprocess, 17.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 20.5ms\n",
            "Speed: 3.3ms preprocess, 20.5ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 13.3ms\n",
            "Speed: 3.3ms preprocess, 13.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 16.5ms\n",
            "Speed: 3.0ms preprocess, 16.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 17.2ms\n",
            "Speed: 3.1ms preprocess, 17.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 14.5ms\n",
            "Speed: 3.3ms preprocess, 14.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 14.1ms\n",
            "Speed: 9.6ms preprocess, 14.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.9ms\n",
            "Speed: 3.2ms preprocess, 11.9ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 14.7ms\n",
            "Speed: 5.1ms preprocess, 14.7ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 14.0ms\n",
            "Speed: 3.2ms preprocess, 14.0ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 14.3ms\n",
            "Speed: 3.2ms preprocess, 14.3ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.1ms\n",
            "Speed: 4.2ms preprocess, 10.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 12.8ms\n",
            "Speed: 3.2ms preprocess, 12.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.5ms\n",
            "Speed: 3.4ms preprocess, 11.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 12.5ms\n",
            "Speed: 3.0ms preprocess, 12.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.0ms\n",
            "Speed: 3.2ms preprocess, 10.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 12.1ms\n",
            "Speed: 3.6ms preprocess, 12.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 8.3ms\n",
            "Speed: 3.2ms preprocess, 8.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.9ms\n",
            "Speed: 3.4ms preprocess, 10.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 15.2ms\n",
            "Speed: 3.9ms preprocess, 15.2ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.8ms\n",
            "Speed: 3.6ms preprocess, 10.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 8.9ms\n",
            "Speed: 3.1ms preprocess, 8.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.2ms\n",
            "Speed: 3.6ms preprocess, 11.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.4ms\n",
            "Speed: 3.2ms preprocess, 11.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 13.1ms\n",
            "Speed: 3.3ms preprocess, 13.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 12.1ms\n",
            "Speed: 3.4ms preprocess, 12.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.4ms\n",
            "Speed: 3.3ms preprocess, 10.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.3ms\n",
            "Speed: 3.1ms preprocess, 11.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 9.8ms\n",
            "Speed: 3.4ms preprocess, 9.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 7.4ms\n",
            "Speed: 2.5ms preprocess, 7.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 7.7ms\n",
            "Speed: 2.5ms preprocess, 7.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 8.3ms\n",
            "Speed: 3.0ms preprocess, 8.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 9.2ms\n",
            "Speed: 3.0ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 9.3ms\n",
            "Speed: 5.5ms preprocess, 9.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.5ms\n",
            "Speed: 4.1ms preprocess, 10.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 15.1ms\n",
            "Speed: 4.0ms preprocess, 15.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.3ms\n",
            "Speed: 3.4ms preprocess, 11.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 7.7ms\n",
            "Speed: 3.5ms preprocess, 7.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.9ms\n",
            "Speed: 4.0ms preprocess, 10.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.4ms\n",
            "Speed: 4.1ms preprocess, 10.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.5ms\n",
            "Speed: 3.5ms preprocess, 11.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.1ms\n",
            "Speed: 3.4ms preprocess, 10.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.4ms\n",
            "Speed: 3.5ms preprocess, 10.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.3ms\n",
            "Speed: 3.2ms preprocess, 11.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 15.7ms\n",
            "Speed: 3.2ms preprocess, 15.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.3ms\n",
            "Speed: 4.0ms preprocess, 11.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 8.1ms\n",
            "Speed: 3.5ms preprocess, 8.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.7ms\n",
            "Speed: 3.2ms preprocess, 10.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 12.5ms\n",
            "Speed: 3.9ms preprocess, 12.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.9ms\n",
            "Speed: 4.0ms preprocess, 10.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.0ms\n",
            "Speed: 3.5ms preprocess, 10.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 9.5ms\n",
            "Speed: 3.7ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.4ms\n",
            "Speed: 3.5ms preprocess, 11.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.3ms\n",
            "Speed: 3.1ms preprocess, 11.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 13.7ms\n",
            "Speed: 3.3ms preprocess, 13.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 7.7ms\n",
            "Speed: 2.3ms preprocess, 7.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 14.1ms\n",
            "Speed: 5.6ms preprocess, 14.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 7.4ms\n",
            "Speed: 3.2ms preprocess, 7.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 15.6ms\n",
            "Speed: 3.8ms preprocess, 15.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 15.3ms\n",
            "Speed: 3.4ms preprocess, 15.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.9ms\n",
            "Speed: 3.5ms preprocess, 11.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 8.4ms\n",
            "Speed: 3.3ms preprocess, 8.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.6ms\n",
            "Speed: 3.1ms preprocess, 11.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 13.3ms\n",
            "Speed: 3.5ms preprocess, 13.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12.2ms\n",
            "Speed: 3.3ms preprocess, 12.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.3ms\n",
            "Speed: 4.5ms preprocess, 10.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.9ms\n",
            "Speed: 3.2ms preprocess, 10.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.5ms\n",
            "Speed: 3.0ms preprocess, 11.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12.5ms\n",
            "Speed: 3.2ms preprocess, 12.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.9ms\n",
            "Speed: 3.1ms preprocess, 11.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.8ms\n",
            "Speed: 3.3ms preprocess, 10.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 11.2ms\n",
            "Speed: 3.2ms preprocess, 11.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.1ms\n",
            "Speed: 3.3ms preprocess, 11.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 12.8ms\n",
            "Speed: 3.3ms preprocess, 12.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 11.5ms\n",
            "Speed: 3.2ms preprocess, 11.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 7.6ms\n",
            "Speed: 2.6ms preprocess, 7.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.0ms\n",
            "Speed: 3.2ms preprocess, 11.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.2ms\n",
            "Speed: 3.3ms preprocess, 10.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 8.7ms\n",
            "Speed: 3.5ms preprocess, 8.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.4ms\n",
            "Speed: 3.2ms preprocess, 10.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 15.0ms\n",
            "Speed: 3.2ms preprocess, 15.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.1ms\n",
            "Speed: 3.6ms preprocess, 11.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 19.1ms\n",
            "Speed: 3.1ms preprocess, 19.1ms inference, 6.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 8.3ms\n",
            "Speed: 3.3ms preprocess, 8.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.3ms\n",
            "Speed: 3.2ms preprocess, 11.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 8.9ms\n",
            "Speed: 3.3ms preprocess, 8.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 12.6ms\n",
            "Speed: 4.3ms preprocess, 12.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 7.5ms\n",
            "Speed: 2.9ms preprocess, 7.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.2ms\n",
            "Speed: 3.4ms preprocess, 11.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 11.5ms\n",
            "Speed: 3.1ms preprocess, 11.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 7.8ms\n",
            "Speed: 3.0ms preprocess, 7.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 12.3ms\n",
            "Speed: 5.3ms preprocess, 12.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12.6ms\n",
            "Speed: 3.2ms preprocess, 12.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12.8ms\n",
            "Speed: 3.3ms preprocess, 12.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 8.8ms\n",
            "Speed: 3.5ms preprocess, 8.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.5ms\n",
            "Speed: 3.4ms preprocess, 10.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.6ms\n",
            "Speed: 3.4ms preprocess, 11.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.5ms\n",
            "Speed: 3.6ms preprocess, 11.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.8ms\n",
            "Speed: 3.9ms preprocess, 10.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.6ms\n",
            "Speed: 3.9ms preprocess, 10.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 12.3ms\n",
            "Speed: 4.6ms preprocess, 12.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 12.6ms\n",
            "Speed: 3.2ms preprocess, 12.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.1ms\n",
            "Speed: 3.1ms preprocess, 11.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.3ms\n",
            "Speed: 3.0ms preprocess, 11.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12.8ms\n",
            "Speed: 4.1ms preprocess, 12.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 15.8ms\n",
            "Speed: 3.1ms preprocess, 15.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 8.7ms\n",
            "Speed: 3.2ms preprocess, 8.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.8ms\n",
            "Speed: 3.0ms preprocess, 10.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.6ms\n",
            "Speed: 3.1ms preprocess, 11.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 7.6ms\n",
            "Speed: 8.0ms preprocess, 7.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 15.4ms\n",
            "Speed: 3.3ms preprocess, 15.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.9ms\n",
            "Speed: 3.3ms preprocess, 10.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.4ms\n",
            "Speed: 3.2ms preprocess, 11.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 13.0ms\n",
            "Speed: 3.3ms preprocess, 13.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.0ms\n",
            "Speed: 3.8ms preprocess, 11.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 8.4ms\n",
            "Speed: 3.3ms preprocess, 8.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.8ms\n",
            "Speed: 3.9ms preprocess, 11.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 13.0ms\n",
            "Speed: 3.3ms preprocess, 13.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.0ms\n",
            "Speed: 3.3ms preprocess, 11.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.5ms\n",
            "Speed: 3.6ms preprocess, 11.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12.4ms\n",
            "Speed: 3.6ms preprocess, 12.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.9ms\n",
            "Speed: 3.6ms preprocess, 10.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12.1ms\n",
            "Speed: 3.5ms preprocess, 12.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.4ms\n",
            "Speed: 3.3ms preprocess, 10.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12.2ms\n",
            "Speed: 3.3ms preprocess, 12.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.6ms\n",
            "Speed: 3.1ms preprocess, 11.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.5ms\n",
            "Speed: 3.2ms preprocess, 10.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 14.5ms\n",
            "Speed: 3.1ms preprocess, 14.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.5ms\n",
            "Speed: 4.4ms preprocess, 11.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 14.7ms\n",
            "Speed: 3.7ms preprocess, 14.7ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 13.2ms\n",
            "Speed: 3.4ms preprocess, 13.2ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.3ms\n",
            "Speed: 3.3ms preprocess, 10.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.6ms\n",
            "Speed: 6.3ms preprocess, 11.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 7.3ms\n",
            "Speed: 2.8ms preprocess, 7.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.9ms\n",
            "Speed: 4.9ms preprocess, 10.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.2ms\n",
            "Speed: 3.2ms preprocess, 10.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.1ms\n",
            "Speed: 3.0ms preprocess, 11.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9.5ms\n",
            "Speed: 5.2ms preprocess, 9.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 7.7ms\n",
            "Speed: 2.3ms preprocess, 7.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 7.6ms\n",
            "Speed: 3.0ms preprocess, 7.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 8.7ms\n",
            "Speed: 7.4ms preprocess, 8.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12.1ms\n",
            "Speed: 3.5ms preprocess, 12.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9.5ms\n",
            "Speed: 3.7ms preprocess, 9.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.7ms\n",
            "Speed: 4.2ms preprocess, 11.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9.7ms\n",
            "Speed: 3.3ms preprocess, 9.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 8.1ms\n",
            "Speed: 3.7ms preprocess, 8.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9.6ms\n",
            "Speed: 3.1ms preprocess, 9.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 9.0ms\n",
            "Speed: 3.3ms preprocess, 9.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 9.9ms\n",
            "Speed: 3.4ms preprocess, 9.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 14.1ms\n",
            "Speed: 3.5ms preprocess, 14.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 9.8ms\n",
            "Speed: 3.5ms preprocess, 9.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 10.0ms\n",
            "Speed: 3.5ms preprocess, 10.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 10.5ms\n",
            "Speed: 4.2ms preprocess, 10.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 9.8ms\n",
            "Speed: 3.3ms preprocess, 9.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 9.7ms\n",
            "Speed: 3.2ms preprocess, 9.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 10.8ms\n",
            "Speed: 3.0ms preprocess, 10.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.6ms\n",
            "Speed: 3.0ms preprocess, 11.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 12.7ms\n",
            "Speed: 3.8ms preprocess, 12.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.8ms\n",
            "Speed: 3.3ms preprocess, 10.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 11.7ms\n",
            "Speed: 3.4ms preprocess, 11.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.1ms\n",
            "Speed: 3.2ms preprocess, 11.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 12.6ms\n",
            "Speed: 3.1ms preprocess, 12.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 11.5ms\n",
            "Speed: 4.0ms preprocess, 11.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 10.3ms\n",
            "Speed: 3.3ms preprocess, 10.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 7.8ms\n",
            "Speed: 3.2ms preprocess, 7.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 7.5ms\n",
            "Speed: 3.1ms preprocess, 7.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.9ms\n",
            "Speed: 3.5ms preprocess, 11.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.6ms\n",
            "Speed: 3.1ms preprocess, 11.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 14.0ms\n",
            "Speed: 3.0ms preprocess, 14.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 7.6ms\n",
            "Speed: 2.9ms preprocess, 7.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.2ms\n",
            "Speed: 3.3ms preprocess, 11.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 12.9ms\n",
            "Speed: 3.9ms preprocess, 12.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12.6ms\n",
            "Speed: 3.2ms preprocess, 12.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.4ms\n",
            "Speed: 3.7ms preprocess, 11.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.1ms\n",
            "Speed: 4.3ms preprocess, 11.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 16.0ms\n",
            "Speed: 3.3ms preprocess, 16.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.5ms\n",
            "Speed: 3.7ms preprocess, 11.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 8.2ms\n",
            "Speed: 3.1ms preprocess, 8.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 9.4ms\n",
            "Speed: 3.2ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.9ms\n",
            "Speed: 3.8ms preprocess, 11.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.8ms\n",
            "Speed: 5.3ms preprocess, 11.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.7ms\n",
            "Speed: 3.1ms preprocess, 11.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.3ms\n",
            "Speed: 3.3ms preprocess, 10.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.0ms\n",
            "Speed: 4.4ms preprocess, 11.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9.2ms\n",
            "Speed: 3.1ms preprocess, 9.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.4ms\n",
            "Speed: 3.2ms preprocess, 11.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.4ms\n",
            "Speed: 3.1ms preprocess, 11.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 7.7ms\n",
            "Speed: 2.9ms preprocess, 7.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.9ms\n",
            "Speed: 3.3ms preprocess, 10.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.4ms\n",
            "Speed: 3.1ms preprocess, 11.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.3ms\n",
            "Speed: 3.1ms preprocess, 11.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 13.6ms\n",
            "Speed: 3.1ms preprocess, 13.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12.3ms\n",
            "Speed: 3.2ms preprocess, 12.3ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 13.0ms\n",
            "Speed: 3.4ms preprocess, 13.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 20.8ms\n",
            "Speed: 3.4ms preprocess, 20.8ms inference, 6.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 15.6ms\n",
            "Speed: 3.9ms preprocess, 15.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 16.7ms\n",
            "Speed: 3.5ms preprocess, 16.7ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.8ms\n",
            "Speed: 3.4ms preprocess, 11.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 24.9ms\n",
            "Speed: 3.0ms preprocess, 24.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 13.2ms\n",
            "Speed: 3.5ms preprocess, 13.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.5ms\n",
            "Speed: 3.1ms preprocess, 11.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 13.6ms\n",
            "Speed: 3.1ms preprocess, 13.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 19.9ms\n",
            "Speed: 5.3ms preprocess, 19.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 15.2ms\n",
            "Speed: 3.2ms preprocess, 15.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12.7ms\n",
            "Speed: 3.3ms preprocess, 12.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12.4ms\n",
            "Speed: 3.2ms preprocess, 12.4ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9.9ms\n",
            "Speed: 3.3ms preprocess, 9.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 19.1ms\n",
            "Speed: 3.8ms preprocess, 19.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 15.7ms\n",
            "Speed: 8.1ms preprocess, 15.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 14.3ms\n",
            "Speed: 3.2ms preprocess, 14.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 10.7ms\n",
            "Speed: 6.6ms preprocess, 10.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 17.2ms\n",
            "Speed: 3.4ms preprocess, 17.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.9ms\n",
            "Speed: 3.4ms preprocess, 11.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 14.8ms\n",
            "Speed: 4.4ms preprocess, 14.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.0ms\n",
            "Speed: 3.3ms preprocess, 11.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 16.3ms\n",
            "Speed: 6.4ms preprocess, 16.3ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.9ms\n",
            "Speed: 3.3ms preprocess, 10.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12.0ms\n",
            "Speed: 3.6ms preprocess, 12.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 13.7ms\n",
            "Speed: 3.2ms preprocess, 13.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.6ms\n",
            "Speed: 3.1ms preprocess, 10.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.3ms\n",
            "Speed: 3.4ms preprocess, 11.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.9ms\n",
            "Speed: 3.3ms preprocess, 11.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.0ms\n",
            "Speed: 9.1ms preprocess, 10.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 15.9ms\n",
            "Speed: 5.1ms preprocess, 15.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 19.1ms\n",
            "Speed: 3.2ms preprocess, 19.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.5ms\n",
            "Speed: 4.2ms preprocess, 11.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.3ms\n",
            "Speed: 3.7ms preprocess, 10.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 13.3ms\n",
            "Speed: 3.2ms preprocess, 13.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12.2ms\n",
            "Speed: 5.8ms preprocess, 12.2ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.1ms\n",
            "Speed: 3.0ms preprocess, 10.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 14.5ms\n",
            "Speed: 3.2ms preprocess, 14.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.8ms\n",
            "Speed: 3.1ms preprocess, 11.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 15.9ms\n",
            "Speed: 3.1ms preprocess, 15.9ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 13.3ms\n",
            "Speed: 5.6ms preprocess, 13.3ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 19.9ms\n",
            "Speed: 3.3ms preprocess, 19.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12.3ms\n",
            "Speed: 5.8ms preprocess, 12.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 13.1ms\n",
            "Speed: 3.0ms preprocess, 13.1ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 17.5ms\n",
            "Speed: 3.2ms preprocess, 17.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 15.7ms\n",
            "Speed: 5.9ms preprocess, 15.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 15.2ms\n",
            "Speed: 3.4ms preprocess, 15.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 13.7ms\n",
            "Speed: 3.0ms preprocess, 13.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 15.2ms\n",
            "Speed: 3.2ms preprocess, 15.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.0ms\n",
            "Speed: 3.2ms preprocess, 11.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 15.4ms\n",
            "Speed: 3.2ms preprocess, 15.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 16.9ms\n",
            "Speed: 3.2ms preprocess, 16.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 17.0ms\n",
            "Speed: 5.3ms preprocess, 17.0ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 20.4ms\n",
            "Speed: 5.8ms preprocess, 20.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 16.2ms\n",
            "Speed: 3.2ms preprocess, 16.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 16.2ms\n",
            "Speed: 3.2ms preprocess, 16.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 13.3ms\n",
            "Speed: 4.1ms preprocess, 13.3ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 16.7ms\n",
            "Speed: 3.3ms preprocess, 16.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 25.3ms\n",
            "Speed: 6.2ms preprocess, 25.3ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 20.1ms\n",
            "Speed: 4.1ms preprocess, 20.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 13.9ms\n",
            "Speed: 4.4ms preprocess, 13.9ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.8ms\n",
            "Speed: 3.9ms preprocess, 10.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.1ms\n",
            "Speed: 3.3ms preprocess, 10.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 12.5ms\n",
            "Speed: 6.2ms preprocess, 12.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.4ms\n",
            "Speed: 3.3ms preprocess, 11.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.9ms\n",
            "Speed: 3.2ms preprocess, 10.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 8.8ms\n",
            "Speed: 7.6ms preprocess, 8.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.9ms\n",
            "Speed: 4.0ms preprocess, 10.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.1ms\n",
            "Speed: 3.9ms preprocess, 10.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.2ms\n",
            "Speed: 3.8ms preprocess, 11.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 11.4ms\n",
            "Speed: 3.3ms preprocess, 11.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.5ms\n",
            "Speed: 6.8ms preprocess, 10.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9.9ms\n",
            "Speed: 7.2ms preprocess, 9.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.4ms\n",
            "Speed: 3.7ms preprocess, 11.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.4ms\n",
            "Speed: 3.4ms preprocess, 11.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.6ms\n",
            "Speed: 3.6ms preprocess, 11.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 7.6ms\n",
            "Speed: 3.2ms preprocess, 7.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9.0ms\n",
            "Speed: 3.3ms preprocess, 9.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.1ms\n",
            "Speed: 3.1ms preprocess, 11.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 8.0ms\n",
            "Speed: 3.2ms preprocess, 8.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.9ms\n",
            "Speed: 3.4ms preprocess, 10.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.5ms\n",
            "Speed: 3.1ms preprocess, 11.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 13.0ms\n",
            "Speed: 4.0ms preprocess, 13.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.5ms\n",
            "Speed: 3.1ms preprocess, 11.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.8ms\n",
            "Speed: 3.1ms preprocess, 11.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12.4ms\n",
            "Speed: 3.3ms preprocess, 12.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.4ms\n",
            "Speed: 3.3ms preprocess, 11.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 8.1ms\n",
            "Speed: 3.2ms preprocess, 8.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.6ms\n",
            "Speed: 3.3ms preprocess, 11.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 14.3ms\n",
            "Speed: 4.1ms preprocess, 14.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 9.0ms\n",
            "Speed: 3.2ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 8.0ms\n",
            "Speed: 3.1ms preprocess, 8.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.2ms\n",
            "Speed: 3.6ms preprocess, 11.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 14.1ms\n",
            "Speed: 3.2ms preprocess, 14.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 12.8ms\n",
            "Speed: 3.3ms preprocess, 12.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 12.1ms\n",
            "Speed: 3.1ms preprocess, 12.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.4ms\n",
            "Speed: 3.1ms preprocess, 11.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.6ms\n",
            "Speed: 3.1ms preprocess, 11.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 7.5ms\n",
            "Speed: 2.9ms preprocess, 7.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.4ms\n",
            "Speed: 3.4ms preprocess, 10.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 8.3ms\n",
            "Speed: 3.4ms preprocess, 8.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.3ms\n",
            "Speed: 7.9ms preprocess, 10.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 13.0ms\n",
            "Speed: 3.4ms preprocess, 13.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.6ms\n",
            "Speed: 3.6ms preprocess, 11.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.0ms\n",
            "Speed: 3.2ms preprocess, 10.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.5ms\n",
            "Speed: 3.3ms preprocess, 11.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 8.2ms\n",
            "Speed: 10.3ms preprocess, 8.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.1ms\n",
            "Speed: 3.3ms preprocess, 11.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.6ms\n",
            "Speed: 3.1ms preprocess, 10.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.2ms\n",
            "Speed: 3.1ms preprocess, 11.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 8.3ms\n",
            "Speed: 3.3ms preprocess, 8.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 12.0ms\n",
            "Speed: 3.5ms preprocess, 12.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.3ms\n",
            "Speed: 3.9ms preprocess, 11.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.9ms\n",
            "Speed: 3.7ms preprocess, 11.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 8.8ms\n",
            "Speed: 3.2ms preprocess, 8.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.9ms\n",
            "Speed: 3.6ms preprocess, 10.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 12.8ms\n",
            "Speed: 5.3ms preprocess, 12.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.3ms\n",
            "Speed: 4.2ms preprocess, 11.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 12.1ms\n",
            "Speed: 3.8ms preprocess, 12.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 7.6ms\n",
            "Speed: 3.0ms preprocess, 7.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 13.7ms\n",
            "Speed: 3.2ms preprocess, 13.7ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.2ms\n",
            "Speed: 3.1ms preprocess, 11.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.4ms\n",
            "Speed: 3.0ms preprocess, 11.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.7ms\n",
            "Speed: 3.1ms preprocess, 11.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 14.6ms\n",
            "Speed: 7.6ms preprocess, 14.6ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.3ms\n",
            "Speed: 3.0ms preprocess, 11.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.0ms\n",
            "Speed: 3.0ms preprocess, 11.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12.5ms\n",
            "Speed: 3.1ms preprocess, 12.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.8ms\n",
            "Speed: 3.3ms preprocess, 11.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9.2ms\n",
            "Speed: 3.4ms preprocess, 9.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.5ms\n",
            "Speed: 3.2ms preprocess, 11.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 8.0ms\n",
            "Speed: 2.8ms preprocess, 8.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9.5ms\n",
            "Speed: 3.2ms preprocess, 9.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 13.2ms\n",
            "Speed: 3.4ms preprocess, 13.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 8.5ms\n",
            "Speed: 3.2ms preprocess, 8.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9.3ms\n",
            "Speed: 3.2ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 8.6ms\n",
            "Speed: 3.2ms preprocess, 8.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.9ms\n",
            "Speed: 3.9ms preprocess, 10.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 7.5ms\n",
            "Speed: 9.9ms preprocess, 7.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.4ms\n",
            "Speed: 6.9ms preprocess, 11.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.5ms\n",
            "Speed: 3.4ms preprocess, 11.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 13.3ms\n",
            "Speed: 3.2ms preprocess, 13.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 8.0ms\n",
            "Speed: 2.3ms preprocess, 8.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.3ms\n",
            "Speed: 3.0ms preprocess, 10.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 9.2ms\n",
            "Speed: 4.1ms preprocess, 9.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.2ms\n",
            "Speed: 3.3ms preprocess, 11.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 8.4ms\n",
            "Speed: 3.2ms preprocess, 8.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.8ms\n",
            "Speed: 3.2ms preprocess, 11.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.6ms\n",
            "Speed: 3.1ms preprocess, 11.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 12.4ms\n",
            "Speed: 4.5ms preprocess, 12.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 8.5ms\n",
            "Speed: 3.2ms preprocess, 8.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.3ms\n",
            "Speed: 3.3ms preprocess, 11.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.8ms\n",
            "Speed: 3.4ms preprocess, 11.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 9.5ms\n",
            "Speed: 3.0ms preprocess, 9.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.3ms\n",
            "Speed: 3.3ms preprocess, 11.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 14.1ms\n",
            "Speed: 3.7ms preprocess, 14.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 12.2ms\n",
            "Speed: 3.6ms preprocess, 12.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 8.6ms\n",
            "Speed: 6.2ms preprocess, 8.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.7ms\n",
            "Speed: 3.3ms preprocess, 10.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 13.0ms\n",
            "Speed: 3.2ms preprocess, 13.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 7.9ms\n",
            "Speed: 3.2ms preprocess, 7.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.9ms\n",
            "Speed: 3.3ms preprocess, 10.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.1ms\n",
            "Speed: 3.0ms preprocess, 11.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 14.3ms\n",
            "Speed: 3.7ms preprocess, 14.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.2ms\n",
            "Speed: 3.2ms preprocess, 11.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 12.0ms\n",
            "Speed: 3.7ms preprocess, 12.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.7ms\n",
            "Speed: 3.4ms preprocess, 10.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.2ms\n",
            "Speed: 3.2ms preprocess, 10.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.7ms\n",
            "Speed: 3.9ms preprocess, 10.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.1ms\n",
            "Speed: 5.2ms preprocess, 11.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 12.1ms\n",
            "Speed: 3.5ms preprocess, 12.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.2ms\n",
            "Speed: 3.3ms preprocess, 11.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 12.4ms\n",
            "Speed: 4.1ms preprocess, 12.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.4ms\n",
            "Speed: 3.1ms preprocess, 11.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.2ms\n",
            "Speed: 3.3ms preprocess, 11.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.7ms\n",
            "Speed: 3.3ms preprocess, 11.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.0ms\n",
            "Speed: 3.6ms preprocess, 11.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.5ms\n",
            "Speed: 3.3ms preprocess, 11.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 12.1ms\n",
            "Speed: 4.3ms preprocess, 12.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.3ms\n",
            "Speed: 3.7ms preprocess, 11.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 9.9ms\n",
            "Speed: 9.3ms preprocess, 9.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.4ms\n",
            "Speed: 3.5ms preprocess, 10.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 7.4ms\n",
            "Speed: 2.6ms preprocess, 7.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 12.2ms\n",
            "Speed: 3.3ms preprocess, 12.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.3ms\n",
            "Speed: 3.0ms preprocess, 11.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.6ms\n",
            "Speed: 3.0ms preprocess, 11.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.1ms\n",
            "Speed: 3.0ms preprocess, 10.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.0ms\n",
            "Speed: 3.3ms preprocess, 11.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 12.6ms\n",
            "Speed: 3.6ms preprocess, 12.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.5ms\n",
            "Speed: 3.3ms preprocess, 11.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 9.3ms\n",
            "Speed: 3.1ms preprocess, 9.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.8ms\n",
            "Speed: 3.5ms preprocess, 10.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 14.2ms\n",
            "Speed: 3.2ms preprocess, 14.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.8ms\n",
            "Speed: 3.0ms preprocess, 11.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.8ms\n",
            "Speed: 3.2ms preprocess, 11.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 12.0ms\n",
            "Speed: 3.3ms preprocess, 12.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.3ms\n",
            "Speed: 3.2ms preprocess, 11.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 8.6ms\n",
            "Speed: 3.2ms preprocess, 8.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 7.6ms\n",
            "Speed: 4.2ms preprocess, 7.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.5ms\n",
            "Speed: 7.4ms preprocess, 11.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.6ms\n",
            "Speed: 3.8ms preprocess, 11.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.6ms\n",
            "Speed: 5.0ms preprocess, 10.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.6ms\n",
            "Speed: 3.2ms preprocess, 10.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 12.4ms\n",
            "Speed: 3.4ms preprocess, 12.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.5ms\n",
            "Speed: 3.5ms preprocess, 11.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.9ms\n",
            "Speed: 3.2ms preprocess, 10.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 7.6ms\n",
            "Speed: 3.1ms preprocess, 7.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.0ms\n",
            "Speed: 3.2ms preprocess, 10.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.6ms\n",
            "Speed: 3.1ms preprocess, 11.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.2ms\n",
            "Speed: 3.1ms preprocess, 11.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.3ms\n",
            "Speed: 3.1ms preprocess, 11.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.2ms\n",
            "Speed: 3.4ms preprocess, 11.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 12.4ms\n",
            "Speed: 3.2ms preprocess, 12.4ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.5ms\n",
            "Speed: 3.3ms preprocess, 11.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.1ms\n",
            "Speed: 3.1ms preprocess, 11.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 16.7ms\n",
            "Speed: 3.3ms preprocess, 16.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 14.2ms\n",
            "Speed: 7.8ms preprocess, 14.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 12.6ms\n",
            "Speed: 3.3ms preprocess, 12.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.4ms\n",
            "Speed: 3.2ms preprocess, 10.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 11.4ms\n",
            "Speed: 3.1ms preprocess, 11.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 7.6ms\n",
            "Speed: 7.9ms preprocess, 7.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 12.0ms\n",
            "Speed: 3.4ms preprocess, 12.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 8.9ms\n",
            "Speed: 3.1ms preprocess, 8.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.0ms\n",
            "Speed: 3.2ms preprocess, 11.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.2ms\n",
            "Speed: 6.7ms preprocess, 11.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.1ms\n",
            "Speed: 4.2ms preprocess, 11.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 7.7ms\n",
            "Speed: 3.0ms preprocess, 7.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 12.1ms\n",
            "Speed: 6.2ms preprocess, 12.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.2ms\n",
            "Speed: 3.1ms preprocess, 11.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.3ms\n",
            "Speed: 3.1ms preprocess, 10.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.9ms\n",
            "Speed: 5.5ms preprocess, 11.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.0ms\n",
            "Speed: 3.2ms preprocess, 11.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.2ms\n",
            "Speed: 3.0ms preprocess, 11.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.8ms\n",
            "Speed: 3.2ms preprocess, 10.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.2ms\n",
            "Speed: 3.1ms preprocess, 11.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.9ms\n",
            "Speed: 3.1ms preprocess, 10.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 12.4ms\n",
            "Speed: 4.0ms preprocess, 12.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 13.2ms\n",
            "Speed: 3.4ms preprocess, 13.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 7.8ms\n",
            "Speed: 7.3ms preprocess, 7.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 12.4ms\n",
            "Speed: 4.9ms preprocess, 12.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.8ms\n",
            "Speed: 3.2ms preprocess, 11.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 11.9ms\n",
            "Speed: 3.1ms preprocess, 11.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 10.9ms\n",
            "Speed: 3.2ms preprocess, 10.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 10.4ms\n",
            "Speed: 3.3ms preprocess, 10.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 7.3ms\n",
            "Speed: 3.0ms preprocess, 7.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 10.6ms\n",
            "Speed: 3.2ms preprocess, 10.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 20.2ms\n",
            "Speed: 3.4ms preprocess, 20.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 16.8ms\n",
            "Speed: 3.2ms preprocess, 16.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 14.4ms\n",
            "Speed: 3.2ms preprocess, 14.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.3ms\n",
            "Speed: 3.0ms preprocess, 11.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 10.6ms\n",
            "Speed: 3.1ms preprocess, 10.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.5ms\n",
            "Speed: 3.2ms preprocess, 11.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 14.2ms\n",
            "Speed: 3.2ms preprocess, 14.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 12.7ms\n",
            "Speed: 3.0ms preprocess, 12.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.2ms\n",
            "Speed: 3.2ms preprocess, 11.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.4ms\n",
            "Speed: 3.2ms preprocess, 10.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.5ms\n",
            "Speed: 3.1ms preprocess, 11.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.5ms\n",
            "Speed: 3.2ms preprocess, 10.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.2ms\n",
            "Speed: 3.3ms preprocess, 11.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 16.9ms\n",
            "Speed: 3.0ms preprocess, 16.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 9.5ms\n",
            "Speed: 3.2ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 12.3ms\n",
            "Speed: 3.2ms preprocess, 12.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 13.2ms\n",
            "Speed: 9.0ms preprocess, 13.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.3ms\n",
            "Speed: 4.0ms preprocess, 11.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.6ms\n",
            "Speed: 4.1ms preprocess, 11.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 7.6ms\n",
            "Speed: 3.1ms preprocess, 7.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 14.3ms\n",
            "Speed: 3.2ms preprocess, 14.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.0ms\n",
            "Speed: 3.2ms preprocess, 11.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 8.6ms\n",
            "Speed: 3.2ms preprocess, 8.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 9.8ms\n",
            "Speed: 3.1ms preprocess, 9.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 14.1ms\n",
            "Speed: 3.2ms preprocess, 14.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.0ms\n",
            "Speed: 3.1ms preprocess, 11.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.4ms\n",
            "Speed: 5.7ms preprocess, 10.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.1ms\n",
            "Speed: 3.2ms preprocess, 11.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 9.1ms\n",
            "Speed: 6.1ms preprocess, 9.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 9.0ms\n",
            "Speed: 3.2ms preprocess, 9.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 8.8ms\n",
            "Speed: 5.9ms preprocess, 8.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.7ms\n",
            "Speed: 3.0ms preprocess, 11.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.9ms\n",
            "Speed: 3.0ms preprocess, 11.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 16.1ms\n",
            "Speed: 3.6ms preprocess, 16.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 18.6ms\n",
            "Speed: 3.2ms preprocess, 18.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 15.4ms\n",
            "Speed: 4.1ms preprocess, 15.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 17.8ms\n",
            "Speed: 3.1ms preprocess, 17.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 15.6ms\n",
            "Speed: 11.3ms preprocess, 15.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 13.4ms\n",
            "Speed: 3.4ms preprocess, 13.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 16.7ms\n",
            "Speed: 4.9ms preprocess, 16.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 12.8ms\n",
            "Speed: 3.3ms preprocess, 12.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 21.6ms\n",
            "Speed: 3.3ms preprocess, 21.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.7ms\n",
            "Speed: 3.8ms preprocess, 11.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 10.7ms\n",
            "Speed: 3.3ms preprocess, 10.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 14.3ms\n",
            "Speed: 4.8ms preprocess, 14.3ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 13.2ms\n",
            "Speed: 5.4ms preprocess, 13.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 12.5ms\n",
            "Speed: 3.1ms preprocess, 12.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 10.8ms\n",
            "Speed: 3.6ms preprocess, 10.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 11.5ms\n",
            "Speed: 3.1ms preprocess, 11.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 11.3ms\n",
            "Speed: 3.5ms preprocess, 11.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 9.9ms\n",
            "Speed: 4.1ms preprocess, 9.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.7ms\n",
            "Speed: 3.3ms preprocess, 10.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.2ms\n",
            "Speed: 4.4ms preprocess, 10.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 18.9ms\n",
            "Speed: 3.5ms preprocess, 18.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.3ms\n",
            "Speed: 5.2ms preprocess, 11.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 14.2ms\n",
            "Speed: 5.5ms preprocess, 14.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.3ms\n",
            "Speed: 3.4ms preprocess, 10.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.5ms\n",
            "Speed: 8.2ms preprocess, 10.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 9.5ms\n",
            "Speed: 3.9ms preprocess, 9.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 9.9ms\n",
            "Speed: 3.4ms preprocess, 9.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.3ms\n",
            "Speed: 3.3ms preprocess, 10.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 17.1ms\n",
            "Speed: 3.5ms preprocess, 17.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 13.6ms\n",
            "Speed: 3.2ms preprocess, 13.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 9.7ms\n",
            "Speed: 4.0ms preprocess, 9.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 9.5ms\n",
            "Speed: 4.1ms preprocess, 9.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 12.9ms\n",
            "Speed: 4.2ms preprocess, 12.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 9.8ms\n",
            "Speed: 3.9ms preprocess, 9.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 10.4ms\n",
            "Speed: 4.3ms preprocess, 10.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 10.2ms\n",
            "Speed: 4.0ms preprocess, 10.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 12.6ms\n",
            "Speed: 3.3ms preprocess, 12.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 11.9ms\n",
            "Speed: 3.3ms preprocess, 11.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 15.9ms\n",
            "Speed: 3.4ms preprocess, 15.9ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 12.6ms\n",
            "Speed: 3.1ms preprocess, 12.6ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 17.5ms\n",
            "Speed: 3.4ms preprocess, 17.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 11.3ms\n",
            "Speed: 3.3ms preprocess, 11.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 12.3ms\n",
            "Speed: 3.5ms preprocess, 12.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 13.7ms\n",
            "Speed: 6.7ms preprocess, 13.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 16.3ms\n",
            "Speed: 9.0ms preprocess, 16.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 13.4ms\n",
            "Speed: 3.1ms preprocess, 13.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.7ms\n",
            "Speed: 3.3ms preprocess, 11.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.9ms\n",
            "Speed: 3.2ms preprocess, 10.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 20.9ms\n",
            "Speed: 3.2ms preprocess, 20.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.6ms\n",
            "Speed: 3.3ms preprocess, 10.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 13.6ms\n",
            "Speed: 3.3ms preprocess, 13.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.1ms\n",
            "Speed: 3.2ms preprocess, 11.1ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 18.7ms\n",
            "Speed: 3.3ms preprocess, 18.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 13.7ms\n",
            "Speed: 3.4ms preprocess, 13.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 12.6ms\n",
            "Speed: 3.0ms preprocess, 12.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 17.0ms\n",
            "Speed: 3.3ms preprocess, 17.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 15.4ms\n",
            "Speed: 11.7ms preprocess, 15.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 19.4ms\n",
            "Speed: 3.2ms preprocess, 19.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 15.5ms\n",
            "Speed: 3.4ms preprocess, 15.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.2ms\n",
            "Speed: 3.1ms preprocess, 11.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 11.2ms\n",
            "Speed: 3.3ms preprocess, 11.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 9.0ms\n",
            "Speed: 3.3ms preprocess, 9.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 11.5ms\n",
            "Speed: 3.3ms preprocess, 11.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 6 persons, 11.0ms\n",
            "Speed: 3.3ms preprocess, 11.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 11.5ms\n",
            "Speed: 3.0ms preprocess, 11.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.9ms\n",
            "Speed: 5.7ms preprocess, 10.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 7.5ms\n",
            "Speed: 3.0ms preprocess, 7.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 7.4ms\n",
            "Speed: 2.8ms preprocess, 7.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 9.4ms\n",
            "Speed: 3.3ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.9ms\n",
            "Speed: 3.4ms preprocess, 10.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 9.9ms\n",
            "Speed: 3.6ms preprocess, 9.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 7.5ms\n",
            "Speed: 3.0ms preprocess, 7.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 14.7ms\n",
            "Speed: 3.3ms preprocess, 14.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 7.8ms\n",
            "Speed: 3.2ms preprocess, 7.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.9ms\n",
            "Speed: 3.2ms preprocess, 10.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 11.7ms\n",
            "Speed: 3.1ms preprocess, 11.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 15.1ms\n",
            "Speed: 3.4ms preprocess, 15.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 11.7ms\n",
            "Speed: 3.2ms preprocess, 11.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 7.5ms\n",
            "Speed: 2.5ms preprocess, 7.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 7.8ms\n",
            "Speed: 2.7ms preprocess, 7.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 12.0ms\n",
            "Speed: 7.6ms preprocess, 12.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 15.1ms\n",
            "Speed: 3.4ms preprocess, 15.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.0ms\n",
            "Speed: 3.1ms preprocess, 11.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.8ms\n",
            "Speed: 3.1ms preprocess, 10.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.2ms\n",
            "Speed: 3.2ms preprocess, 11.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 11.2ms\n",
            "Speed: 3.4ms preprocess, 11.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 12.4ms\n",
            "Speed: 3.3ms preprocess, 12.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.5ms\n",
            "Speed: 3.3ms preprocess, 10.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 11.0ms\n",
            "Speed: 3.3ms preprocess, 11.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.7ms\n",
            "Speed: 3.4ms preprocess, 11.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.8ms\n",
            "Speed: 3.1ms preprocess, 11.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.7ms\n",
            "Speed: 3.1ms preprocess, 11.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.4ms\n",
            "Speed: 3.3ms preprocess, 11.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.6ms\n",
            "Speed: 3.9ms preprocess, 11.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.6ms\n",
            "Speed: 3.1ms preprocess, 10.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 11.2ms\n",
            "Speed: 3.2ms preprocess, 11.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.0ms\n",
            "Speed: 3.3ms preprocess, 11.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.0ms\n",
            "Speed: 4.1ms preprocess, 10.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 11.7ms\n",
            "Speed: 3.9ms preprocess, 11.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.5ms\n",
            "Speed: 5.1ms preprocess, 10.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12.0ms\n",
            "Speed: 4.4ms preprocess, 12.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.5ms\n",
            "Speed: 5.0ms preprocess, 11.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.5ms\n",
            "Speed: 3.5ms preprocess, 10.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 8.4ms\n",
            "Speed: 4.1ms preprocess, 8.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 24.3ms\n",
            "Speed: 3.2ms preprocess, 24.3ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 13.2ms\n",
            "Speed: 3.6ms preprocess, 13.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 11.9ms\n",
            "Speed: 3.2ms preprocess, 11.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 7.8ms\n",
            "Speed: 3.2ms preprocess, 7.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 13.0ms\n",
            "Speed: 3.3ms preprocess, 13.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 8.1ms\n",
            "Speed: 3.3ms preprocess, 8.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12.8ms\n",
            "Speed: 3.2ms preprocess, 12.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12.3ms\n",
            "Speed: 3.7ms preprocess, 12.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.3ms\n",
            "Speed: 4.4ms preprocess, 11.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 7.9ms\n",
            "Speed: 2.6ms preprocess, 7.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.0ms\n",
            "Speed: 3.3ms preprocess, 10.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.0ms\n",
            "Speed: 3.5ms preprocess, 11.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 12.4ms\n",
            "Speed: 7.4ms preprocess, 12.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.9ms\n",
            "Speed: 3.2ms preprocess, 11.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.5ms\n",
            "Speed: 3.1ms preprocess, 10.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.1ms\n",
            "Speed: 3.1ms preprocess, 11.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 13.2ms\n",
            "Speed: 3.2ms preprocess, 13.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.2ms\n",
            "Speed: 3.3ms preprocess, 11.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 12.3ms\n",
            "Speed: 3.2ms preprocess, 12.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.8ms\n",
            "Speed: 3.2ms preprocess, 11.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.9ms\n",
            "Speed: 3.2ms preprocess, 10.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.1ms\n",
            "Speed: 5.3ms preprocess, 11.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.5ms\n",
            "Speed: 3.1ms preprocess, 10.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 14.1ms\n",
            "Speed: 3.4ms preprocess, 14.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 13.4ms\n",
            "Speed: 3.3ms preprocess, 13.4ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.5ms\n",
            "Speed: 3.1ms preprocess, 11.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 13.9ms\n",
            "Speed: 3.0ms preprocess, 13.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.9ms\n",
            "Speed: 3.0ms preprocess, 10.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.5ms\n",
            "Speed: 3.0ms preprocess, 10.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.8ms\n",
            "Speed: 3.3ms preprocess, 10.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 15.1ms\n",
            "Speed: 3.4ms preprocess, 15.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.2ms\n",
            "Speed: 3.1ms preprocess, 11.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.1ms\n",
            "Speed: 3.2ms preprocess, 11.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.0ms\n",
            "Speed: 3.3ms preprocess, 11.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 12.3ms\n",
            "Speed: 3.1ms preprocess, 12.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 8.2ms\n",
            "Speed: 4.4ms preprocess, 8.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 13.8ms\n",
            "Speed: 4.2ms preprocess, 13.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 8.7ms\n",
            "Speed: 3.2ms preprocess, 8.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.2ms\n",
            "Speed: 3.6ms preprocess, 11.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 9.9ms\n",
            "Speed: 3.9ms preprocess, 9.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.6ms\n",
            "Speed: 3.6ms preprocess, 11.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.2ms\n",
            "Speed: 3.6ms preprocess, 11.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 13.0ms\n",
            "Speed: 5.8ms preprocess, 13.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 13.2ms\n",
            "Speed: 3.4ms preprocess, 13.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 8.4ms\n",
            "Speed: 3.3ms preprocess, 8.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 7.6ms\n",
            "Speed: 2.2ms preprocess, 7.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 8.4ms\n",
            "Speed: 3.1ms preprocess, 8.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 20.1ms\n",
            "Speed: 5.0ms preprocess, 20.1ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 12.1ms\n",
            "Speed: 4.5ms preprocess, 12.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 12.0ms\n",
            "Speed: 3.2ms preprocess, 12.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 7.6ms\n",
            "Speed: 2.2ms preprocess, 7.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.6ms\n",
            "Speed: 3.2ms preprocess, 11.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.8ms\n",
            "Speed: 3.4ms preprocess, 11.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.2ms\n",
            "Speed: 3.3ms preprocess, 11.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 7.9ms\n",
            "Speed: 3.2ms preprocess, 7.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9.0ms\n",
            "Speed: 3.9ms preprocess, 9.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 8.2ms\n",
            "Speed: 3.2ms preprocess, 8.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 9.5ms\n",
            "Speed: 3.1ms preprocess, 9.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 9.2ms\n",
            "Speed: 3.5ms preprocess, 9.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12.4ms\n",
            "Speed: 4.1ms preprocess, 12.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12.2ms\n",
            "Speed: 3.9ms preprocess, 12.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12.6ms\n",
            "Speed: 3.5ms preprocess, 12.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.8ms\n",
            "Speed: 3.6ms preprocess, 11.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.1ms\n",
            "Speed: 3.4ms preprocess, 10.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 15.1ms\n",
            "Speed: 3.9ms preprocess, 15.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12.0ms\n",
            "Speed: 3.3ms preprocess, 12.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.8ms\n",
            "Speed: 3.9ms preprocess, 10.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.4ms\n",
            "Speed: 3.3ms preprocess, 10.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.9ms\n",
            "Speed: 3.4ms preprocess, 11.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12.2ms\n",
            "Speed: 3.5ms preprocess, 12.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 22.4ms\n",
            "Speed: 3.4ms preprocess, 22.4ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 8.2ms\n",
            "Speed: 3.2ms preprocess, 8.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.2ms\n",
            "Speed: 3.2ms preprocess, 11.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12.0ms\n",
            "Speed: 3.3ms preprocess, 12.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.4ms\n",
            "Speed: 3.1ms preprocess, 11.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.9ms\n",
            "Speed: 3.1ms preprocess, 11.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.1ms\n",
            "Speed: 3.2ms preprocess, 11.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.8ms\n",
            "Speed: 3.4ms preprocess, 11.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.6ms\n",
            "Speed: 7.2ms preprocess, 8.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.9ms\n",
            "Speed: 3.1ms preprocess, 10.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.3ms\n",
            "Speed: 3.4ms preprocess, 11.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12.9ms\n",
            "Speed: 3.8ms preprocess, 12.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.2ms\n",
            "Speed: 3.0ms preprocess, 11.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.8ms\n",
            "Speed: 3.2ms preprocess, 10.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.2ms\n",
            "Speed: 7.1ms preprocess, 11.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.8ms\n",
            "Speed: 3.2ms preprocess, 11.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.7ms\n",
            "Speed: 3.3ms preprocess, 10.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 14.2ms\n",
            "Speed: 4.5ms preprocess, 14.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 13.2ms\n",
            "Speed: 3.1ms preprocess, 13.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.2ms\n",
            "Speed: 3.1ms preprocess, 11.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.0ms\n",
            "Speed: 3.1ms preprocess, 11.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.2ms\n",
            "Speed: 3.2ms preprocess, 11.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.1ms\n",
            "Speed: 3.1ms preprocess, 11.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.2ms\n",
            "Speed: 5.0ms preprocess, 11.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 9.9ms\n",
            "Speed: 3.3ms preprocess, 9.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.5ms\n",
            "Speed: 3.9ms preprocess, 11.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 17.8ms\n",
            "Speed: 3.3ms preprocess, 17.8ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.7ms\n",
            "Speed: 3.2ms preprocess, 11.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12.4ms\n",
            "Speed: 3.2ms preprocess, 12.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.2ms\n",
            "Speed: 4.7ms preprocess, 10.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12.0ms\n",
            "Speed: 3.2ms preprocess, 12.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 8.0ms\n",
            "Speed: 3.2ms preprocess, 8.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.4ms\n",
            "Speed: 3.1ms preprocess, 11.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12.2ms\n",
            "Speed: 3.3ms preprocess, 12.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12.0ms\n",
            "Speed: 3.3ms preprocess, 12.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 8.3ms\n",
            "Speed: 3.2ms preprocess, 8.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.2ms\n",
            "Speed: 3.3ms preprocess, 10.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.5ms\n",
            "Speed: 3.2ms preprocess, 11.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.3ms\n",
            "Speed: 3.5ms preprocess, 11.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.8ms\n",
            "Speed: 3.3ms preprocess, 11.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.8ms\n",
            "Speed: 3.3ms preprocess, 10.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12.7ms\n",
            "Speed: 3.1ms preprocess, 12.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12.3ms\n",
            "Speed: 3.2ms preprocess, 12.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.9ms\n",
            "Speed: 3.8ms preprocess, 10.9ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 13.7ms\n",
            "Speed: 3.1ms preprocess, 13.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 13.3ms\n",
            "Speed: 3.3ms preprocess, 13.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 14.0ms\n",
            "Speed: 3.3ms preprocess, 14.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.5ms\n",
            "Speed: 3.1ms preprocess, 11.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 8.2ms\n",
            "Speed: 3.3ms preprocess, 8.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.2ms\n",
            "Speed: 3.7ms preprocess, 11.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.9ms\n",
            "Speed: 4.6ms preprocess, 10.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12.2ms\n",
            "Speed: 3.4ms preprocess, 12.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.3ms\n",
            "Speed: 3.3ms preprocess, 11.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.1ms\n",
            "Speed: 3.3ms preprocess, 11.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.2ms\n",
            "Speed: 3.3ms preprocess, 11.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.6ms\n",
            "Speed: 3.6ms preprocess, 11.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.1ms\n",
            "Speed: 3.4ms preprocess, 11.1ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.8ms\n",
            "Speed: 3.5ms preprocess, 10.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 13.1ms\n",
            "Speed: 3.3ms preprocess, 13.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.7ms\n",
            "Speed: 3.7ms preprocess, 11.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 8.4ms\n",
            "Speed: 6.4ms preprocess, 8.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 7.5ms\n",
            "Speed: 3.2ms preprocess, 7.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 16.5ms\n",
            "Speed: 3.3ms preprocess, 16.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 8.2ms\n",
            "Speed: 3.4ms preprocess, 8.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.2ms\n",
            "Speed: 3.2ms preprocess, 11.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.8ms\n",
            "Speed: 3.4ms preprocess, 10.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.4ms\n",
            "Speed: 3.2ms preprocess, 11.4ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.6ms\n",
            "Speed: 3.4ms preprocess, 10.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.3ms\n",
            "Speed: 3.3ms preprocess, 11.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12.8ms\n",
            "Speed: 4.4ms preprocess, 12.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.4ms\n",
            "Speed: 3.2ms preprocess, 11.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.8ms\n",
            "Speed: 3.4ms preprocess, 11.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.2ms\n",
            "Speed: 3.2ms preprocess, 11.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 16.7ms\n",
            "Speed: 6.9ms preprocess, 16.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 12.0ms\n",
            "Speed: 3.4ms preprocess, 12.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.2ms\n",
            "Speed: 3.3ms preprocess, 11.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.2ms\n",
            "Speed: 3.2ms preprocess, 11.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.5ms\n",
            "Speed: 3.3ms preprocess, 10.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 27.5ms\n",
            "Speed: 12.7ms preprocess, 27.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.2ms\n",
            "Speed: 3.5ms preprocess, 11.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12.3ms\n",
            "Speed: 3.5ms preprocess, 12.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 7.9ms\n",
            "Speed: 2.9ms preprocess, 7.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.3ms\n",
            "Speed: 3.2ms preprocess, 11.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 8.5ms\n",
            "Speed: 9.0ms preprocess, 8.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.4ms\n",
            "Speed: 3.1ms preprocess, 7.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.0ms\n",
            "Speed: 3.3ms preprocess, 8.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.4ms\n",
            "Speed: 3.7ms preprocess, 11.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.2ms\n",
            "Speed: 3.2ms preprocess, 10.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.9ms\n",
            "Speed: 3.1ms preprocess, 10.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.7ms\n",
            "Speed: 3.2ms preprocess, 10.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.2ms\n",
            "Speed: 3.3ms preprocess, 11.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 9.4ms\n",
            "Speed: 3.2ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12.1ms\n",
            "Speed: 3.5ms preprocess, 12.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.7ms\n",
            "Speed: 3.2ms preprocess, 10.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 9.3ms\n",
            "Speed: 3.3ms preprocess, 9.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 15.8ms\n",
            "Speed: 3.5ms preprocess, 15.8ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 15.2ms\n",
            "Speed: 3.3ms preprocess, 15.2ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.9ms\n",
            "Speed: 3.9ms preprocess, 10.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 8.5ms\n",
            "Speed: 6.6ms preprocess, 8.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.6ms\n",
            "Speed: 3.4ms preprocess, 11.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.6ms\n",
            "Speed: 2.6ms preprocess, 7.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.1ms\n",
            "Speed: 3.4ms preprocess, 11.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.4ms\n",
            "Speed: 3.3ms preprocess, 10.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12.0ms\n",
            "Speed: 3.5ms preprocess, 12.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 9.1ms\n",
            "Speed: 7.7ms preprocess, 9.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 20.2ms\n",
            "Speed: 4.8ms preprocess, 20.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12.0ms\n",
            "Speed: 3.5ms preprocess, 12.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 20.9ms\n",
            "Speed: 3.0ms preprocess, 20.9ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 15.9ms\n",
            "Speed: 7.5ms preprocess, 15.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.1ms\n",
            "Speed: 3.4ms preprocess, 11.1ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.5ms\n",
            "Speed: 4.5ms preprocess, 11.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.3ms\n",
            "Speed: 3.2ms preprocess, 11.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 20.5ms\n",
            "Speed: 5.5ms preprocess, 20.5ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.8ms\n",
            "Speed: 3.3ms preprocess, 10.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 13.9ms\n",
            "Speed: 10.4ms preprocess, 13.9ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 16.1ms\n",
            "Speed: 3.3ms preprocess, 16.1ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.2ms\n",
            "Speed: 5.4ms preprocess, 11.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.8ms\n",
            "Speed: 2.9ms preprocess, 10.8ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 16.9ms\n",
            "Speed: 7.6ms preprocess, 16.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.0ms\n",
            "Speed: 3.4ms preprocess, 10.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.0ms\n",
            "Speed: 2.6ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.1ms\n",
            "Speed: 3.3ms preprocess, 11.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 16.6ms\n",
            "Speed: 4.1ms preprocess, 16.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12.1ms\n",
            "Speed: 3.3ms preprocess, 12.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.5ms\n",
            "Speed: 3.3ms preprocess, 11.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.3ms\n",
            "Speed: 3.2ms preprocess, 10.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 16.7ms\n",
            "Speed: 3.8ms preprocess, 16.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.3ms\n",
            "Speed: 4.3ms preprocess, 13.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 13.3ms\n",
            "Speed: 3.3ms preprocess, 13.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.9ms\n",
            "Speed: 3.3ms preprocess, 10.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 13.0ms\n",
            "Speed: 3.3ms preprocess, 13.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 20.7ms\n",
            "Speed: 3.4ms preprocess, 20.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.8ms\n",
            "Speed: 3.5ms preprocess, 10.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.6ms\n",
            "Speed: 3.2ms preprocess, 10.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 19.8ms\n",
            "Speed: 3.2ms preprocess, 19.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.3ms\n",
            "Speed: 3.3ms preprocess, 12.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.6ms\n",
            "Speed: 3.3ms preprocess, 11.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.7ms\n",
            "Speed: 3.3ms preprocess, 10.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.6ms\n",
            "Speed: 3.4ms preprocess, 15.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.7ms\n",
            "Speed: 3.4ms preprocess, 10.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.2ms\n",
            "Speed: 3.3ms preprocess, 14.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.5ms\n",
            "Speed: 3.2ms preprocess, 10.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.5ms\n",
            "Speed: 3.3ms preprocess, 15.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.3ms\n",
            "Speed: 4.1ms preprocess, 13.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.5ms\n",
            "Speed: 4.1ms preprocess, 11.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.1ms\n",
            "Speed: 6.0ms preprocess, 13.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.9ms\n",
            "Speed: 3.3ms preprocess, 13.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 14.3ms\n",
            "Speed: 3.4ms preprocess, 14.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 18.7ms\n",
            "Speed: 3.2ms preprocess, 18.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 14.7ms\n",
            "Speed: 3.6ms preprocess, 14.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 14.3ms\n",
            "Speed: 8.1ms preprocess, 14.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 16.5ms\n",
            "Speed: 3.3ms preprocess, 16.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.7ms\n",
            "Speed: 3.9ms preprocess, 11.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12.5ms\n",
            "Speed: 3.4ms preprocess, 12.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 19.3ms\n",
            "Speed: 3.4ms preprocess, 19.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 17.6ms\n",
            "Speed: 3.4ms preprocess, 17.6ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12.7ms\n",
            "Speed: 4.1ms preprocess, 12.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 13.9ms\n",
            "Speed: 4.8ms preprocess, 13.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 13.8ms\n",
            "Speed: 3.4ms preprocess, 13.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 17.1ms\n",
            "Speed: 4.3ms preprocess, 17.1ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 16.3ms\n",
            "Speed: 3.7ms preprocess, 16.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12.7ms\n",
            "Speed: 3.6ms preprocess, 12.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 15.5ms\n",
            "Speed: 3.7ms preprocess, 15.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 21.1ms\n",
            "Speed: 3.6ms preprocess, 21.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 15.7ms\n",
            "Speed: 4.8ms preprocess, 15.7ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 15.1ms\n",
            "Speed: 3.3ms preprocess, 15.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 19.1ms\n",
            "Speed: 5.4ms preprocess, 19.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 8.8ms\n",
            "Speed: 3.3ms preprocess, 8.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12.6ms\n",
            "Speed: 6.1ms preprocess, 12.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12.9ms\n",
            "Speed: 3.3ms preprocess, 12.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.3ms\n",
            "Speed: 3.4ms preprocess, 11.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 19.0ms\n",
            "Speed: 3.2ms preprocess, 19.0ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.3ms\n",
            "Speed: 3.5ms preprocess, 11.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 9.4ms\n",
            "Speed: 5.3ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.2ms\n",
            "Speed: 3.3ms preprocess, 11.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12.5ms\n",
            "Speed: 3.3ms preprocess, 12.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 7.8ms\n",
            "Speed: 3.2ms preprocess, 7.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12.6ms\n",
            "Speed: 3.2ms preprocess, 12.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.4ms\n",
            "Speed: 3.3ms preprocess, 10.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.6ms\n",
            "Speed: 3.2ms preprocess, 11.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.2ms\n",
            "Speed: 4.2ms preprocess, 11.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 9.3ms\n",
            "Speed: 3.2ms preprocess, 9.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.6ms\n",
            "Speed: 3.5ms preprocess, 11.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 9.0ms\n",
            "Speed: 5.6ms preprocess, 9.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 8.4ms\n",
            "Speed: 4.7ms preprocess, 8.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.7ms\n",
            "Speed: 3.8ms preprocess, 10.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 9.7ms\n",
            "Speed: 3.3ms preprocess, 9.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.9ms\n",
            "Speed: 3.6ms preprocess, 11.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.0ms\n",
            "Speed: 3.5ms preprocess, 11.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 13.1ms\n",
            "Speed: 3.1ms preprocess, 13.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.3ms\n",
            "Speed: 3.4ms preprocess, 11.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 8.1ms\n",
            "Speed: 2.6ms preprocess, 8.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.9ms\n",
            "Speed: 3.3ms preprocess, 10.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 9.0ms\n",
            "Speed: 3.3ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 14.0ms\n",
            "Speed: 5.3ms preprocess, 14.0ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 15.4ms\n",
            "Speed: 3.3ms preprocess, 15.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 7.4ms\n",
            "Speed: 2.8ms preprocess, 7.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.8ms\n",
            "Speed: 3.6ms preprocess, 11.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.5ms\n",
            "Speed: 3.3ms preprocess, 11.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 8.5ms\n",
            "Speed: 3.2ms preprocess, 8.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.1ms\n",
            "Speed: 3.2ms preprocess, 11.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 8.3ms\n",
            "Speed: 3.4ms preprocess, 8.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 9.5ms\n",
            "Speed: 3.3ms preprocess, 9.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 7.9ms\n",
            "Speed: 3.7ms preprocess, 7.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.7ms\n",
            "Speed: 3.5ms preprocess, 10.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.3ms\n",
            "Speed: 3.4ms preprocess, 10.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.7ms\n",
            "Speed: 3.4ms preprocess, 11.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12.2ms\n",
            "Speed: 3.4ms preprocess, 12.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12.7ms\n",
            "Speed: 3.5ms preprocess, 12.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.7ms\n",
            "Speed: 3.6ms preprocess, 10.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 16.8ms\n",
            "Speed: 3.2ms preprocess, 16.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.0ms\n",
            "Speed: 3.3ms preprocess, 11.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 9.4ms\n",
            "Speed: 3.2ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 7.9ms\n",
            "Speed: 3.1ms preprocess, 7.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 15.0ms\n",
            "Speed: 3.2ms preprocess, 15.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 14.4ms\n",
            "Speed: 3.2ms preprocess, 14.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 7.8ms\n",
            "Speed: 3.2ms preprocess, 7.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 15.7ms\n",
            "Speed: 3.1ms preprocess, 15.7ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 13.0ms\n",
            "Speed: 5.4ms preprocess, 13.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 9.9ms\n",
            "Speed: 7.4ms preprocess, 9.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.4ms\n",
            "Speed: 3.1ms preprocess, 11.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.5ms\n",
            "Speed: 3.3ms preprocess, 11.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.0ms\n",
            "Speed: 3.2ms preprocess, 11.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.5ms\n",
            "Speed: 3.2ms preprocess, 11.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9.3ms\n",
            "Speed: 4.0ms preprocess, 9.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.4ms\n",
            "Speed: 3.3ms preprocess, 10.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.7ms\n",
            "Speed: 3.2ms preprocess, 12.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12.6ms\n",
            "Speed: 3.4ms preprocess, 12.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 16.4ms\n",
            "Speed: 3.2ms preprocess, 16.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.7ms\n",
            "Speed: 3.1ms preprocess, 11.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12.9ms\n",
            "Speed: 3.5ms preprocess, 12.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.3ms\n",
            "Speed: 3.2ms preprocess, 8.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.7ms\n",
            "Speed: 2.7ms preprocess, 7.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.3ms\n",
            "Speed: 3.1ms preprocess, 11.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.4ms\n",
            "Speed: 3.3ms preprocess, 11.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.1ms\n",
            "Speed: 8.3ms preprocess, 11.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.6ms\n",
            "Speed: 3.2ms preprocess, 7.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.3ms\n",
            "Speed: 3.6ms preprocess, 11.3ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.7ms\n",
            "Speed: 3.8ms preprocess, 11.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.5ms\n",
            "Speed: 3.6ms preprocess, 11.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 13.6ms\n",
            "Speed: 3.3ms preprocess, 13.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.7ms\n",
            "Speed: 3.1ms preprocess, 11.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.8ms\n",
            "Speed: 3.3ms preprocess, 11.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.5ms\n",
            "Speed: 3.3ms preprocess, 11.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.0ms\n",
            "Speed: 3.1ms preprocess, 11.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.8ms\n",
            "Speed: 3.1ms preprocess, 14.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.3ms\n",
            "Speed: 3.8ms preprocess, 11.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.9ms\n",
            "Speed: 5.5ms preprocess, 11.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.4ms\n",
            "Speed: 3.3ms preprocess, 11.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.4ms\n",
            "Speed: 3.4ms preprocess, 10.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.2ms\n",
            "Speed: 3.4ms preprocess, 11.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.2ms\n",
            "Speed: 3.5ms preprocess, 12.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.5ms\n",
            "Speed: 3.5ms preprocess, 12.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.8ms\n",
            "Speed: 3.0ms preprocess, 12.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.6ms\n",
            "Speed: 3.2ms preprocess, 10.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.5ms\n",
            "Speed: 3.4ms preprocess, 11.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.7ms\n",
            "Speed: 3.1ms preprocess, 11.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.9ms\n",
            "Speed: 3.2ms preprocess, 10.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9.8ms\n",
            "Speed: 3.3ms preprocess, 9.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.4ms\n",
            "Speed: 3.3ms preprocess, 13.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.8ms\n",
            "Speed: 3.2ms preprocess, 11.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12.2ms\n",
            "Speed: 3.2ms preprocess, 12.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 9.5ms\n",
            "Speed: 3.2ms preprocess, 9.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.5ms\n",
            "Speed: 3.2ms preprocess, 12.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 17.0ms\n",
            "Speed: 3.3ms preprocess, 17.0ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.2ms\n",
            "Speed: 3.3ms preprocess, 11.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 13.9ms\n",
            "Speed: 3.3ms preprocess, 13.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.8ms\n",
            "Speed: 3.2ms preprocess, 11.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.9ms\n",
            "Speed: 3.1ms preprocess, 10.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.9ms\n",
            "Speed: 3.6ms preprocess, 10.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12.8ms\n",
            "Speed: 3.3ms preprocess, 12.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.5ms\n",
            "Speed: 3.5ms preprocess, 11.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.7ms\n",
            "Speed: 3.4ms preprocess, 10.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.4ms\n",
            "Speed: 3.3ms preprocess, 11.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.4ms\n",
            "Speed: 3.8ms preprocess, 11.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9.6ms\n",
            "Speed: 3.6ms preprocess, 9.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.6ms\n",
            "Speed: 3.3ms preprocess, 10.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.4ms\n",
            "Speed: 4.1ms preprocess, 10.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.5ms\n",
            "Speed: 3.7ms preprocess, 11.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 8.3ms\n",
            "Speed: 3.2ms preprocess, 8.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 8.4ms\n",
            "Speed: 3.2ms preprocess, 8.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.5ms\n",
            "Speed: 3.8ms preprocess, 10.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.0ms\n",
            "Speed: 3.2ms preprocess, 11.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12.4ms\n",
            "Speed: 3.3ms preprocess, 12.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.2ms\n",
            "Speed: 5.8ms preprocess, 10.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9.8ms\n",
            "Speed: 3.3ms preprocess, 9.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.9ms\n",
            "Speed: 3.9ms preprocess, 10.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.4ms\n",
            "Speed: 3.2ms preprocess, 11.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 18.8ms\n",
            "Speed: 3.3ms preprocess, 18.8ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12.2ms\n",
            "Speed: 3.1ms preprocess, 12.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.1ms\n",
            "Speed: 3.1ms preprocess, 11.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.2ms\n",
            "Speed: 3.2ms preprocess, 11.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.0ms\n",
            "Speed: 3.1ms preprocess, 11.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.7ms\n",
            "Speed: 3.1ms preprocess, 10.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.5ms\n",
            "Speed: 3.2ms preprocess, 11.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12.1ms\n",
            "Speed: 3.3ms preprocess, 12.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12.1ms\n",
            "Speed: 3.1ms preprocess, 12.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.3ms\n",
            "Speed: 3.6ms preprocess, 11.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12.0ms\n",
            "Speed: 3.3ms preprocess, 12.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.0ms\n",
            "Speed: 3.6ms preprocess, 11.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.8ms\n",
            "Speed: 3.2ms preprocess, 10.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 14.7ms\n",
            "Speed: 3.1ms preprocess, 14.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.8ms\n",
            "Speed: 3.1ms preprocess, 10.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.3ms\n",
            "Speed: 3.1ms preprocess, 11.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 7.7ms\n",
            "Speed: 2.7ms preprocess, 7.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.6ms\n",
            "Speed: 3.4ms preprocess, 11.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12.1ms\n",
            "Speed: 3.2ms preprocess, 12.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.0ms\n",
            "Speed: 4.5ms preprocess, 10.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.9ms\n",
            "Speed: 3.1ms preprocess, 11.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.0ms\n",
            "Speed: 3.1ms preprocess, 10.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12.2ms\n",
            "Speed: 3.2ms preprocess, 12.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 7.5ms\n",
            "Speed: 3.2ms preprocess, 7.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12.8ms\n",
            "Speed: 3.2ms preprocess, 12.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 7.6ms\n",
            "Speed: 2.8ms preprocess, 7.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 15.7ms\n",
            "Speed: 3.3ms preprocess, 15.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.0ms\n",
            "Speed: 3.1ms preprocess, 11.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 16.9ms\n",
            "Speed: 3.4ms preprocess, 16.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 8.1ms\n",
            "Speed: 2.9ms preprocess, 8.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.1ms\n",
            "Speed: 4.6ms preprocess, 11.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.4ms\n",
            "Speed: 3.2ms preprocess, 11.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.2ms\n",
            "Speed: 4.0ms preprocess, 10.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12.8ms\n",
            "Speed: 3.2ms preprocess, 12.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.5ms\n",
            "Speed: 3.7ms preprocess, 11.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.8ms\n",
            "Speed: 3.0ms preprocess, 12.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.2ms\n",
            "Speed: 4.3ms preprocess, 11.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.8ms\n",
            "Speed: 3.3ms preprocess, 10.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9.8ms\n",
            "Speed: 3.2ms preprocess, 9.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.9ms\n",
            "Speed: 3.7ms preprocess, 10.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.7ms\n",
            "Speed: 3.2ms preprocess, 10.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 9.9ms\n",
            "Speed: 3.1ms preprocess, 9.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.8ms\n",
            "Speed: 3.7ms preprocess, 10.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9.3ms\n",
            "Speed: 6.7ms preprocess, 9.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 7.4ms\n",
            "Speed: 2.4ms preprocess, 7.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 9.6ms\n",
            "Speed: 3.7ms preprocess, 9.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 13.3ms\n",
            "Speed: 5.8ms preprocess, 13.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 15.3ms\n",
            "Speed: 3.1ms preprocess, 15.3ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 15.0ms\n",
            "Speed: 3.0ms preprocess, 15.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12.6ms\n",
            "Speed: 3.4ms preprocess, 12.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.6ms\n",
            "Speed: 3.1ms preprocess, 11.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 14.3ms\n",
            "Speed: 3.2ms preprocess, 14.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 9.6ms\n",
            "Speed: 3.4ms preprocess, 9.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.6ms\n",
            "Speed: 3.8ms preprocess, 10.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12.2ms\n",
            "Speed: 3.6ms preprocess, 12.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.7ms\n",
            "Speed: 3.3ms preprocess, 11.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.6ms\n",
            "Speed: 3.2ms preprocess, 10.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 9.7ms\n",
            "Speed: 3.2ms preprocess, 9.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.2ms\n",
            "Speed: 3.3ms preprocess, 11.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.6ms\n",
            "Speed: 3.1ms preprocess, 11.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.0ms\n",
            "Speed: 3.0ms preprocess, 10.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 7.7ms\n",
            "Speed: 2.2ms preprocess, 7.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.2ms\n",
            "Speed: 3.4ms preprocess, 11.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12.2ms\n",
            "Speed: 3.3ms preprocess, 12.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.9ms\n",
            "Speed: 3.3ms preprocess, 11.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.0ms\n",
            "Speed: 3.2ms preprocess, 11.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12.8ms\n",
            "Speed: 4.5ms preprocess, 12.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.0ms\n",
            "Speed: 3.3ms preprocess, 11.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.2ms\n",
            "Speed: 3.4ms preprocess, 11.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.5ms\n",
            "Speed: 3.2ms preprocess, 11.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.4ms\n",
            "Speed: 3.2ms preprocess, 11.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 8.0ms\n",
            "Speed: 2.8ms preprocess, 8.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 8.4ms\n",
            "Speed: 3.4ms preprocess, 8.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.8ms\n",
            "Speed: 3.6ms preprocess, 10.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12.8ms\n",
            "Speed: 3.3ms preprocess, 12.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.1ms\n",
            "Speed: 3.5ms preprocess, 11.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 9.5ms\n",
            "Speed: 3.1ms preprocess, 9.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.1ms\n",
            "Speed: 3.2ms preprocess, 11.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12.3ms\n",
            "Speed: 3.4ms preprocess, 12.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12.0ms\n",
            "Speed: 3.3ms preprocess, 12.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 7.7ms\n",
            "Speed: 3.0ms preprocess, 7.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 7.9ms\n",
            "Speed: 2.5ms preprocess, 7.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.8ms\n",
            "Speed: 3.0ms preprocess, 11.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 7.8ms\n",
            "Speed: 3.3ms preprocess, 7.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 13.3ms\n",
            "Speed: 5.6ms preprocess, 13.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.6ms\n",
            "Speed: 3.3ms preprocess, 10.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 14.1ms\n",
            "Speed: 3.3ms preprocess, 14.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 7.4ms\n",
            "Speed: 3.1ms preprocess, 7.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.0ms\n",
            "Speed: 3.2ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.9ms\n",
            "Speed: 3.3ms preprocess, 11.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 13.1ms\n",
            "Speed: 6.6ms preprocess, 13.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.7ms\n",
            "Speed: 3.0ms preprocess, 11.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.7ms\n",
            "Speed: 3.5ms preprocess, 10.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 8.6ms\n",
            "Speed: 3.4ms preprocess, 8.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.5ms\n",
            "Speed: 3.3ms preprocess, 11.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12.1ms\n",
            "Speed: 3.1ms preprocess, 12.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.3ms\n",
            "Speed: 3.4ms preprocess, 11.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.6ms\n",
            "Speed: 3.3ms preprocess, 10.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 15.2ms\n",
            "Speed: 3.3ms preprocess, 15.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.1ms\n",
            "Speed: 3.2ms preprocess, 11.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.7ms\n",
            "Speed: 3.8ms preprocess, 11.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.2ms\n",
            "Speed: 3.3ms preprocess, 10.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 13.9ms\n",
            "Speed: 3.3ms preprocess, 13.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.3ms\n",
            "Speed: 3.3ms preprocess, 11.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 13.1ms\n",
            "Speed: 2.8ms preprocess, 13.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 13.0ms\n",
            "Speed: 3.1ms preprocess, 13.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 15.8ms\n",
            "Speed: 3.2ms preprocess, 15.8ms inference, 7.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 15.0ms\n",
            "Speed: 3.4ms preprocess, 15.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.4ms\n",
            "Speed: 3.2ms preprocess, 11.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12.4ms\n",
            "Speed: 3.8ms preprocess, 12.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.6ms\n",
            "Speed: 3.6ms preprocess, 11.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 15.4ms\n",
            "Speed: 5.8ms preprocess, 15.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.0ms\n",
            "Speed: 3.9ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 13.6ms\n",
            "Speed: 3.0ms preprocess, 13.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 13.0ms\n",
            "Speed: 3.3ms preprocess, 13.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 17.0ms\n",
            "Speed: 4.3ms preprocess, 17.0ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12.6ms\n",
            "Speed: 3.3ms preprocess, 12.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.2ms\n",
            "Speed: 3.3ms preprocess, 10.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.5ms\n",
            "Speed: 3.2ms preprocess, 10.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.4ms\n",
            "Speed: 3.2ms preprocess, 10.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.3ms\n",
            "Speed: 3.1ms preprocess, 10.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 9.3ms\n",
            "Speed: 2.9ms preprocess, 9.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 19.6ms\n",
            "Speed: 5.0ms preprocess, 19.6ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.3ms\n",
            "Speed: 3.3ms preprocess, 10.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.3ms\n",
            "Speed: 4.6ms preprocess, 10.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 18.1ms\n",
            "Speed: 5.0ms preprocess, 18.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 16.1ms\n",
            "Speed: 4.2ms preprocess, 16.1ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.0ms\n",
            "Speed: 4.3ms preprocess, 11.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.2ms\n",
            "Speed: 3.6ms preprocess, 11.2ms inference, 6.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.2ms\n",
            "Speed: 3.1ms preprocess, 11.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.0ms\n",
            "Speed: 3.1ms preprocess, 11.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.5ms\n",
            "Speed: 4.3ms preprocess, 11.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 13.3ms\n",
            "Speed: 3.2ms preprocess, 13.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.6ms\n",
            "Speed: 3.1ms preprocess, 11.6ms inference, 6.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 17.3ms\n",
            "Speed: 3.1ms preprocess, 17.3ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 14.5ms\n",
            "Speed: 3.4ms preprocess, 14.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 20.3ms\n",
            "Speed: 3.3ms preprocess, 20.3ms inference, 6.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 13.5ms\n",
            "Speed: 3.2ms preprocess, 13.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.5ms\n",
            "Speed: 3.7ms preprocess, 11.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 17.6ms\n",
            "Speed: 5.6ms preprocess, 17.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 13.6ms\n",
            "Speed: 3.5ms preprocess, 13.6ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 17.3ms\n",
            "Speed: 3.1ms preprocess, 17.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 14.4ms\n",
            "Speed: 3.4ms preprocess, 14.4ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 17.9ms\n",
            "Speed: 3.2ms preprocess, 17.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 14.4ms\n",
            "Speed: 3.1ms preprocess, 14.4ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 17.4ms\n",
            "Speed: 5.1ms preprocess, 17.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12.2ms\n",
            "Speed: 3.2ms preprocess, 12.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.6ms\n",
            "Speed: 3.1ms preprocess, 11.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 18.4ms\n",
            "Speed: 3.1ms preprocess, 18.4ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 16.8ms\n",
            "Speed: 3.3ms preprocess, 16.8ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 9.8ms\n",
            "Speed: 3.9ms preprocess, 9.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.9ms\n",
            "Speed: 4.1ms preprocess, 11.9ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.3ms\n",
            "Speed: 3.1ms preprocess, 11.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 18.4ms\n",
            "Speed: 6.8ms preprocess, 18.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.7ms\n",
            "Speed: 5.7ms preprocess, 11.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 13.4ms\n",
            "Speed: 3.4ms preprocess, 13.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 17.5ms\n",
            "Speed: 3.2ms preprocess, 17.5ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.5ms\n",
            "Speed: 3.1ms preprocess, 10.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 13.0ms\n",
            "Speed: 3.3ms preprocess, 13.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 16.8ms\n",
            "Speed: 3.2ms preprocess, 16.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 14.9ms\n",
            "Speed: 7.3ms preprocess, 14.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 13.9ms\n",
            "Speed: 5.2ms preprocess, 13.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 15.4ms\n",
            "Speed: 3.3ms preprocess, 15.4ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 16.8ms\n",
            "Speed: 3.2ms preprocess, 16.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 17.0ms\n",
            "Speed: 7.3ms preprocess, 17.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 8.3ms\n",
            "Speed: 3.4ms preprocess, 8.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.3ms\n",
            "Speed: 3.1ms preprocess, 11.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12.0ms\n",
            "Speed: 3.7ms preprocess, 12.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.4ms\n",
            "Speed: 3.3ms preprocess, 11.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12.9ms\n",
            "Speed: 4.0ms preprocess, 12.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.2ms\n",
            "Speed: 4.6ms preprocess, 10.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.8ms\n",
            "Speed: 3.2ms preprocess, 11.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 9.7ms\n",
            "Speed: 3.2ms preprocess, 9.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.1ms\n",
            "Speed: 3.3ms preprocess, 11.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12.6ms\n",
            "Speed: 3.1ms preprocess, 12.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.6ms\n",
            "Speed: 3.0ms preprocess, 10.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.1ms\n",
            "Speed: 3.1ms preprocess, 11.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.6ms\n",
            "Speed: 3.2ms preprocess, 10.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.7ms\n",
            "Speed: 3.0ms preprocess, 10.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 13.8ms\n",
            "Speed: 3.0ms preprocess, 13.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.6ms\n",
            "Speed: 6.8ms preprocess, 10.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.3ms\n",
            "Speed: 3.1ms preprocess, 11.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.5ms\n",
            "Speed: 3.0ms preprocess, 10.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 8.2ms\n",
            "Speed: 3.9ms preprocess, 8.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 9.2ms\n",
            "Speed: 3.3ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.4ms\n",
            "Speed: 3.1ms preprocess, 11.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 8.3ms\n",
            "Speed: 6.6ms preprocess, 8.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.6ms\n",
            "Speed: 3.3ms preprocess, 11.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12.9ms\n",
            "Speed: 3.4ms preprocess, 12.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12.0ms\n",
            "Speed: 3.2ms preprocess, 12.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.3ms\n",
            "Speed: 3.1ms preprocess, 11.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.9ms\n",
            "Speed: 3.2ms preprocess, 10.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12.4ms\n",
            "Speed: 3.3ms preprocess, 12.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.9ms\n",
            "Speed: 3.7ms preprocess, 11.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.8ms\n",
            "Speed: 3.1ms preprocess, 10.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.8ms\n",
            "Speed: 3.3ms preprocess, 11.8ms inference, 6.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.6ms\n",
            "Speed: 3.4ms preprocess, 11.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.2ms\n",
            "Speed: 3.2ms preprocess, 11.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.4ms\n",
            "Speed: 3.2ms preprocess, 11.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.3ms\n",
            "Speed: 3.3ms preprocess, 10.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 9.6ms\n",
            "Speed: 3.2ms preprocess, 9.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 9.8ms\n",
            "Speed: 3.2ms preprocess, 9.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 7.5ms\n",
            "Speed: 3.2ms preprocess, 7.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.1ms\n",
            "Speed: 3.1ms preprocess, 11.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.2ms\n",
            "Speed: 3.4ms preprocess, 11.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 13.3ms\n",
            "Speed: 3.9ms preprocess, 13.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 11.2ms\n",
            "Speed: 3.3ms preprocess, 11.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.6ms\n",
            "Speed: 3.2ms preprocess, 11.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 10.9ms\n",
            "Speed: 3.3ms preprocess, 10.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 12.0ms\n",
            "Speed: 3.4ms preprocess, 12.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.2ms\n",
            "Speed: 6.4ms preprocess, 10.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.7ms\n",
            "Speed: 3.3ms preprocess, 11.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.4ms\n",
            "Speed: 3.3ms preprocess, 11.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.1ms\n",
            "Speed: 4.6ms preprocess, 11.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.6ms\n",
            "Speed: 3.2ms preprocess, 11.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.1ms\n",
            "Speed: 3.1ms preprocess, 11.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.9ms\n",
            "Speed: 3.5ms preprocess, 11.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 7.6ms\n",
            "Speed: 3.2ms preprocess, 7.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 13.9ms\n",
            "Speed: 3.2ms preprocess, 13.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.1ms\n",
            "Speed: 5.6ms preprocess, 11.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.2ms\n",
            "Speed: 3.2ms preprocess, 10.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 8.2ms\n",
            "Speed: 3.2ms preprocess, 8.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 7.9ms\n",
            "Speed: 2.9ms preprocess, 7.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.1ms\n",
            "Speed: 3.2ms preprocess, 11.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.1ms\n",
            "Speed: 3.3ms preprocess, 11.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 13.0ms\n",
            "Speed: 4.3ms preprocess, 13.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.8ms\n",
            "Speed: 3.6ms preprocess, 10.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.5ms\n",
            "Speed: 3.9ms preprocess, 10.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 13.4ms\n",
            "Speed: 3.2ms preprocess, 13.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.2ms\n",
            "Speed: 3.1ms preprocess, 11.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.1ms\n",
            "Speed: 3.2ms preprocess, 10.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12.1ms\n",
            "Speed: 3.0ms preprocess, 12.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.5ms\n",
            "Speed: 3.2ms preprocess, 11.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.3ms\n",
            "Speed: 2.9ms preprocess, 11.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.2ms\n",
            "Speed: 3.1ms preprocess, 11.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.5ms\n",
            "Speed: 3.0ms preprocess, 11.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.3ms\n",
            "Speed: 3.1ms preprocess, 11.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12.8ms\n",
            "Speed: 3.0ms preprocess, 12.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 7.6ms\n",
            "Speed: 10.1ms preprocess, 7.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12.5ms\n",
            "Speed: 3.2ms preprocess, 12.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 8.8ms\n",
            "Speed: 3.3ms preprocess, 8.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 8.6ms\n",
            "Speed: 7.2ms preprocess, 8.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 15.3ms\n",
            "Speed: 3.2ms preprocess, 15.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 17.9ms\n",
            "Speed: 3.2ms preprocess, 17.9ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.6ms\n",
            "Speed: 3.0ms preprocess, 11.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9.7ms\n",
            "Speed: 8.2ms preprocess, 9.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 9.0ms\n",
            "Speed: 3.2ms preprocess, 9.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.4ms\n",
            "Speed: 3.2ms preprocess, 10.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.8ms\n",
            "Speed: 3.3ms preprocess, 10.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12.0ms\n",
            "Speed: 3.6ms preprocess, 12.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12.3ms\n",
            "Speed: 3.4ms preprocess, 12.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.7ms\n",
            "Speed: 3.3ms preprocess, 10.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 12.2ms\n",
            "Speed: 3.3ms preprocess, 12.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.3ms\n",
            "Speed: 3.2ms preprocess, 11.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 8.5ms\n",
            "Speed: 6.7ms preprocess, 8.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.7ms\n",
            "Speed: 3.6ms preprocess, 11.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.1ms\n",
            "Speed: 3.4ms preprocess, 11.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 8.1ms\n",
            "Speed: 3.1ms preprocess, 8.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 8.4ms\n",
            "Speed: 3.4ms preprocess, 8.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 8.6ms\n",
            "Speed: 3.1ms preprocess, 8.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.5ms\n",
            "Speed: 3.1ms preprocess, 10.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.5ms\n",
            "Speed: 3.3ms preprocess, 10.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12.9ms\n",
            "Speed: 3.1ms preprocess, 12.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 13.8ms\n",
            "Speed: 3.5ms preprocess, 13.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12.2ms\n",
            "Speed: 3.1ms preprocess, 12.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.9ms\n",
            "Speed: 3.6ms preprocess, 10.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 17.8ms\n",
            "Speed: 3.2ms preprocess, 17.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 14.2ms\n",
            "Speed: 3.6ms preprocess, 14.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.4ms\n",
            "Speed: 3.4ms preprocess, 11.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.7ms\n",
            "Speed: 3.5ms preprocess, 10.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12.4ms\n",
            "Speed: 3.3ms preprocess, 12.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 8.7ms\n",
            "Speed: 3.6ms preprocess, 8.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.0ms\n",
            "Speed: 3.3ms preprocess, 10.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12.1ms\n",
            "Speed: 3.4ms preprocess, 12.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.7ms\n",
            "Speed: 3.7ms preprocess, 11.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.3ms\n",
            "Speed: 3.6ms preprocess, 11.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12.6ms\n",
            "Speed: 3.4ms preprocess, 12.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12.1ms\n",
            "Speed: 3.1ms preprocess, 12.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12.7ms\n",
            "Speed: 3.3ms preprocess, 12.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.3ms\n",
            "Speed: 3.3ms preprocess, 11.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.1ms\n",
            "Speed: 3.1ms preprocess, 11.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.6ms\n",
            "Speed: 3.2ms preprocess, 10.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.5ms\n",
            "Speed: 3.0ms preprocess, 11.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.1ms\n",
            "Speed: 3.3ms preprocess, 13.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9.0ms\n",
            "Speed: 7.9ms preprocess, 9.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12.0ms\n",
            "Speed: 3.3ms preprocess, 12.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.0ms\n",
            "Speed: 8.1ms preprocess, 10.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.0ms\n",
            "Speed: 3.1ms preprocess, 11.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.0ms\n",
            "Speed: 3.2ms preprocess, 11.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 18.4ms\n",
            "Speed: 4.7ms preprocess, 18.4ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.0ms\n",
            "Speed: 3.1ms preprocess, 11.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.8ms\n",
            "Speed: 3.0ms preprocess, 11.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.0ms\n",
            "Speed: 3.0ms preprocess, 11.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 8.4ms\n",
            "Speed: 6.9ms preprocess, 8.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.1ms\n",
            "Speed: 3.1ms preprocess, 11.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.3ms\n",
            "Speed: 3.2ms preprocess, 11.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.6ms\n",
            "Speed: 3.0ms preprocess, 11.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.3ms\n",
            "Speed: 3.3ms preprocess, 10.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.9ms\n",
            "Speed: 3.2ms preprocess, 10.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.4ms\n",
            "Speed: 3.2ms preprocess, 12.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.5ms\n",
            "Speed: 2.6ms preprocess, 7.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.8ms\n",
            "Speed: 3.4ms preprocess, 11.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.0ms\n",
            "Speed: 3.2ms preprocess, 12.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.3ms\n",
            "Speed: 3.4ms preprocess, 12.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9.6ms\n",
            "Speed: 3.0ms preprocess, 9.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9.5ms\n",
            "Speed: 3.3ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.0ms\n",
            "Speed: 3.2ms preprocess, 10.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.7ms\n",
            "Speed: 3.3ms preprocess, 12.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.2ms\n",
            "Speed: 3.2ms preprocess, 10.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.9ms\n",
            "Speed: 3.1ms preprocess, 10.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.6ms\n",
            "Speed: 3.4ms preprocess, 11.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.5ms\n",
            "Speed: 3.0ms preprocess, 11.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.1ms\n",
            "Speed: 3.2ms preprocess, 10.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 8.2ms\n",
            "Speed: 3.0ms preprocess, 8.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 13.0ms\n",
            "Speed: 3.3ms preprocess, 13.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 8.8ms\n",
            "Speed: 7.0ms preprocess, 8.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.2ms\n",
            "Speed: 3.2ms preprocess, 10.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 7.5ms\n",
            "Speed: 2.8ms preprocess, 7.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.0ms\n",
            "Speed: 3.1ms preprocess, 11.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 9.4ms\n",
            "Speed: 4.5ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.4ms\n",
            "Speed: 3.1ms preprocess, 11.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.0ms\n",
            "Speed: 3.2ms preprocess, 11.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.2ms\n",
            "Speed: 3.1ms preprocess, 11.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 16.6ms\n",
            "Speed: 3.5ms preprocess, 16.6ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.5ms\n",
            "Speed: 3.2ms preprocess, 11.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.5ms\n",
            "Speed: 6.2ms preprocess, 11.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.2ms\n",
            "Speed: 4.2ms preprocess, 11.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.6ms\n",
            "Speed: 3.2ms preprocess, 11.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.6ms\n",
            "Speed: 3.1ms preprocess, 10.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.8ms\n",
            "Speed: 3.0ms preprocess, 11.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.1ms\n",
            "Speed: 3.1ms preprocess, 11.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 13.0ms\n",
            "Speed: 4.2ms preprocess, 13.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 10.1ms\n",
            "Speed: 3.3ms preprocess, 10.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.7ms\n",
            "Speed: 2.9ms preprocess, 7.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.0ms\n",
            "Speed: 3.2ms preprocess, 11.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.7ms\n",
            "Speed: 4.2ms preprocess, 10.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.7ms\n",
            "Speed: 3.4ms preprocess, 11.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 15.3ms\n",
            "Speed: 4.4ms preprocess, 15.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 22.6ms\n",
            "Speed: 3.7ms preprocess, 22.6ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 9.7ms\n",
            "Speed: 4.0ms preprocess, 9.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12.4ms\n",
            "Speed: 3.7ms preprocess, 12.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.7ms\n",
            "Speed: 4.0ms preprocess, 11.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12.7ms\n",
            "Speed: 3.9ms preprocess, 12.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.9ms\n",
            "Speed: 3.3ms preprocess, 10.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 9.4ms\n",
            "Speed: 2.5ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 8.5ms\n",
            "Speed: 3.1ms preprocess, 8.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.3ms\n",
            "Speed: 3.2ms preprocess, 11.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.4ms\n",
            "Speed: 3.7ms preprocess, 11.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.4ms\n",
            "Speed: 3.2ms preprocess, 11.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 9.7ms\n",
            "Speed: 3.3ms preprocess, 9.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.2ms\n",
            "Speed: 3.3ms preprocess, 10.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.8ms\n",
            "Speed: 3.4ms preprocess, 10.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 11.0ms\n",
            "Speed: 3.2ms preprocess, 11.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 7.6ms\n",
            "Speed: 7.2ms preprocess, 7.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12.5ms\n",
            "Speed: 4.0ms preprocess, 12.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.7ms\n",
            "Speed: 3.6ms preprocess, 10.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.7ms\n",
            "Speed: 3.1ms preprocess, 10.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.5ms\n",
            "Speed: 3.2ms preprocess, 10.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 11.0ms\n",
            "Speed: 3.2ms preprocess, 11.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.1ms\n",
            "Speed: 3.0ms preprocess, 10.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 8.5ms\n",
            "Speed: 3.4ms preprocess, 8.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 12.4ms\n",
            "Speed: 3.6ms preprocess, 12.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 10.0ms\n",
            "Speed: 3.2ms preprocess, 10.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.2ms\n",
            "Speed: 3.3ms preprocess, 10.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.7ms\n",
            "Speed: 3.3ms preprocess, 11.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 14.5ms\n",
            "Speed: 4.2ms preprocess, 14.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 9.5ms\n",
            "Speed: 3.6ms preprocess, 9.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 11.3ms\n",
            "Speed: 3.5ms preprocess, 11.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.6ms\n",
            "Speed: 3.3ms preprocess, 11.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 13.9ms\n",
            "Speed: 3.2ms preprocess, 13.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.5ms\n",
            "Speed: 3.1ms preprocess, 11.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.0ms\n",
            "Speed: 3.1ms preprocess, 11.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 12.7ms\n",
            "Speed: 3.7ms preprocess, 12.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 12.2ms\n",
            "Speed: 4.7ms preprocess, 12.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 12.1ms\n",
            "Speed: 3.2ms preprocess, 12.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.9ms\n",
            "Speed: 3.0ms preprocess, 10.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 7.5ms\n",
            "Speed: 3.1ms preprocess, 7.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 9.9ms\n",
            "Speed: 5.0ms preprocess, 9.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.5ms\n",
            "Speed: 4.8ms preprocess, 10.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.0ms\n",
            "Speed: 3.6ms preprocess, 11.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 12.8ms\n",
            "Speed: 3.4ms preprocess, 12.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.4ms\n",
            "Speed: 3.8ms preprocess, 11.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.7ms\n",
            "Speed: 3.2ms preprocess, 11.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.7ms\n",
            "Speed: 3.2ms preprocess, 10.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 12.8ms\n",
            "Speed: 3.3ms preprocess, 12.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 18.6ms\n",
            "Speed: 3.2ms preprocess, 18.6ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 14.2ms\n",
            "Speed: 3.2ms preprocess, 14.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 10.5ms\n",
            "Speed: 3.1ms preprocess, 10.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.0ms\n",
            "Speed: 3.1ms preprocess, 11.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 9.4ms\n",
            "Speed: 3.3ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 17.4ms\n",
            "Speed: 3.2ms preprocess, 17.4ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 17.4ms\n",
            "Speed: 3.2ms preprocess, 17.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 15.2ms\n",
            "Speed: 6.0ms preprocess, 15.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 13.1ms\n",
            "Speed: 3.8ms preprocess, 13.1ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 18.5ms\n",
            "Speed: 3.7ms preprocess, 18.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 15.4ms\n",
            "Speed: 3.1ms preprocess, 15.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 15.7ms\n",
            "Speed: 7.8ms preprocess, 15.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 13.7ms\n",
            "Speed: 7.9ms preprocess, 13.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 13.6ms\n",
            "Speed: 6.8ms preprocess, 13.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 9.3ms\n",
            "Speed: 4.6ms preprocess, 9.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 9.9ms\n",
            "Speed: 3.5ms preprocess, 9.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 17.1ms\n",
            "Speed: 4.8ms preprocess, 17.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 9.9ms\n",
            "Speed: 3.8ms preprocess, 9.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 13.1ms\n",
            "Speed: 5.2ms preprocess, 13.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 13.0ms\n",
            "Speed: 6.3ms preprocess, 13.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 11.2ms\n",
            "Speed: 3.2ms preprocess, 11.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 12.7ms\n",
            "Speed: 6.1ms preprocess, 12.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 13.7ms\n",
            "Speed: 3.2ms preprocess, 13.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.3ms\n",
            "Speed: 4.5ms preprocess, 10.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.7ms\n",
            "Speed: 3.4ms preprocess, 10.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.8ms\n",
            "Speed: 2.8ms preprocess, 10.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 12.6ms\n",
            "Speed: 5.7ms preprocess, 12.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.7ms\n",
            "Speed: 6.5ms preprocess, 11.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.2ms\n",
            "Speed: 3.4ms preprocess, 10.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.0ms\n",
            "Speed: 6.0ms preprocess, 10.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 12.7ms\n",
            "Speed: 4.0ms preprocess, 12.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.7ms\n",
            "Speed: 3.6ms preprocess, 10.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 13.3ms\n",
            "Speed: 4.1ms preprocess, 13.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 12.6ms\n",
            "Speed: 6.7ms preprocess, 12.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.1ms\n",
            "Speed: 3.2ms preprocess, 11.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 9.7ms\n",
            "Speed: 4.8ms preprocess, 9.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.3ms\n",
            "Speed: 3.2ms preprocess, 11.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.0ms\n",
            "Speed: 6.4ms preprocess, 10.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 13.2ms\n",
            "Speed: 7.6ms preprocess, 13.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 12.0ms\n",
            "Speed: 3.5ms preprocess, 12.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 12.1ms\n",
            "Speed: 3.2ms preprocess, 12.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.7ms\n",
            "Speed: 5.1ms preprocess, 10.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.5ms\n",
            "Speed: 3.1ms preprocess, 11.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 13.0ms\n",
            "Speed: 3.4ms preprocess, 13.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 11.3ms\n",
            "Speed: 4.9ms preprocess, 11.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 12.2ms\n",
            "Speed: 5.3ms preprocess, 12.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 13.8ms\n",
            "Speed: 6.8ms preprocess, 13.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.5ms\n",
            "Speed: 3.3ms preprocess, 10.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 13.8ms\n",
            "Speed: 4.3ms preprocess, 13.8ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.2ms\n",
            "Speed: 3.3ms preprocess, 11.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 12.1ms\n",
            "Speed: 4.8ms preprocess, 12.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 20.1ms\n",
            "Speed: 5.4ms preprocess, 20.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 15.3ms\n",
            "Speed: 4.2ms preprocess, 15.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 13.6ms\n",
            "Speed: 4.2ms preprocess, 13.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.0ms\n",
            "Speed: 3.2ms preprocess, 10.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 13.0ms\n",
            "Speed: 4.4ms preprocess, 13.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.7ms\n",
            "Speed: 3.2ms preprocess, 11.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 10.0ms\n",
            "Speed: 3.1ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 16.7ms\n",
            "Speed: 4.1ms preprocess, 16.7ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 16.7ms\n",
            "Speed: 3.5ms preprocess, 16.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 21.7ms\n",
            "Speed: 3.3ms preprocess, 21.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 14.4ms\n",
            "Speed: 3.1ms preprocess, 14.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 12.1ms\n",
            "Speed: 3.2ms preprocess, 12.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 11.0ms\n",
            "Speed: 3.1ms preprocess, 11.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 17.0ms\n",
            "Speed: 6.9ms preprocess, 17.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 16.1ms\n",
            "Speed: 3.4ms preprocess, 16.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 13.2ms\n",
            "Speed: 3.2ms preprocess, 13.2ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 15.4ms\n",
            "Speed: 3.1ms preprocess, 15.4ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 13.4ms\n",
            "Speed: 3.1ms preprocess, 13.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 20.6ms\n",
            "Speed: 3.9ms preprocess, 20.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 8.7ms\n",
            "Speed: 6.1ms preprocess, 8.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 8.5ms\n",
            "Speed: 3.2ms preprocess, 8.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 9.9ms\n",
            "Speed: 3.0ms preprocess, 9.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 8.1ms\n",
            "Speed: 3.3ms preprocess, 8.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/skeletons_drawn_dataset/ /content/drive/MyDrive/"
      ],
      "metadata": {
        "id": "cdjheNLxmh2T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Selected Keyframes"
      ],
      "metadata": {
        "id": "jme2M8_107F5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "keyframes_dataset_path = '/content/drive/MyDrive/AIRTLab/'\n",
        "\n",
        "image_files_list = get_data_files(keyframes_dataset_path)"
      ],
      "metadata": {
        "id": "rUjDv5_g1Wv8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = YOLO(\"yolov8n-pose.pt\")\n",
        "\n",
        "set_split, label, image_file = image_files_list[0]\n",
        "\n",
        "file_path = f'{keyframes_dataset_path}/{set_split}/{label}/{image_file}'\n",
        "\n",
        "estimation_result = model(keyframes_dataset_path + 'test/violent/v104f10.jpg')\n",
        "\n",
        "image = cv2.imread(file_path)\n",
        "\n",
        "for result in estimation_result:\n",
        "  kpts = result.keypoints\n",
        "  if kpts is None:\n",
        "      continue\n",
        "\n",
        "  keypoints = kpts.xy.cpu().numpy()\n",
        "\n",
        "  for person in keypoints:\n",
        "      # Draw keypoints\n",
        "      for x, y in person:\n",
        "          cv2.circle(image, (int(x), int(y)), 3, (0, 255, 0), -1)\n",
        "\n",
        "      # Draw connections (skeleton)\n",
        "      for idx1, idx2 in skeleton_connections:\n",
        "          x1, y1 = person[idx1]\n",
        "          x2, y2 = person[idx2]\n",
        "          if x1 > 0 and y1 > 0 and x2 > 0 and y2 > 0:  # valid points\n",
        "              cv2.line(image, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 255), 2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9QwVjWW31jJ8",
        "outputId": "2544c1b9-cc1b-445c-9cb5-bae682bcb4bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/test/violent/v104f10.jpg: 384x640 4 persons, 9.0ms\n",
            "Speed: 2.2ms preprocess, 9.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = YOLO(\"yolov8n-pose.pt\")\n",
        "\n",
        "new_keyframes_dataset_path = \"skeletons_drawn_keyframes\"\n",
        "\n",
        "skeleton_connections = [\n",
        "    (5, 7), (7, 9),     # Left arm\n",
        "    (6, 8), (8, 10),    # Right arm\n",
        "    (5, 6),             # Shoulders\n",
        "    (11, 12),           # Hips\n",
        "    (5, 11), (6, 12),   # Torso\n",
        "    (11, 13), (13, 15), # Left leg\n",
        "    (12, 14), (14, 16)  # Right leg\n",
        "]\n",
        "\n",
        "for set_split, label, image_file in image_files_list:\n",
        "\n",
        "  results  = []\n",
        "\n",
        "  file_path = f'{keyframes_dataset_path}/{set_split}/{label}/{image_file}'\n",
        "\n",
        "  estimation_result = model(file_path)\n",
        "\n",
        "  image = cv2.imread(file_path)\n",
        "\n",
        "  for result in estimation_result:\n",
        "    kpts = result.keypoints\n",
        "    if kpts is None:\n",
        "        continue\n",
        "\n",
        "    keypoints = kpts.xy.cpu().numpy()\n",
        "\n",
        "    for person in keypoints:\n",
        "        # Draw keypoints\n",
        "        for x, y in person:\n",
        "            cv2.circle(image, (int(x), int(y)), 3, (0, 255, 0), -1)\n",
        "\n",
        "        # Draw connections (skeleton)\n",
        "        for idx1, idx2 in skeleton_connections:\n",
        "            x1, y1 = person[idx1]\n",
        "            x2, y2 = person[idx2]\n",
        "            if x1 > 0 and y1 > 0 and x2 > 0 and y2 > 0:  # valid points\n",
        "                cv2.line(image, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 255), 2)\n",
        "    cv2.imwrite(f'{new_keyframes_dataset_path}/{set_split}/{label}/{image_file}', image)\n",
        "\n",
        "#df = pd.DataFrame(data, columns=columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3HvhTgSi1s7t",
        "outputId": "d28e31c6-a034-49f2-8d78-d37e93865843"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v61f112.jpg: 384x640 4 persons, 11.8ms\n",
            "Speed: 2.4ms preprocess, 11.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v61f109.jpg: 384x640 4 persons, 8.2ms\n",
            "Speed: 2.3ms preprocess, 8.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v61f114.jpg: 384x640 4 persons, 10.9ms\n",
            "Speed: 2.3ms preprocess, 10.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v61f105.jpg: 384x640 3 persons, 8.4ms\n",
            "Speed: 2.3ms preprocess, 8.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v61f83.jpg: 384x640 4 persons, 8.1ms\n",
            "Speed: 2.3ms preprocess, 8.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v61f72.jpg: 384x640 4 persons, 18.8ms\n",
            "Speed: 3.9ms preprocess, 18.8ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v61f108.jpg: 384x640 4 persons, 10.7ms\n",
            "Speed: 2.3ms preprocess, 10.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v61f159.jpg: 384x640 4 persons, 8.3ms\n",
            "Speed: 2.2ms preprocess, 8.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v61f164.jpg: 384x640 4 persons, 8.1ms\n",
            "Speed: 2.4ms preprocess, 8.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v9f5.jpg: 384x640 4 persons, 8.3ms\n",
            "Speed: 2.1ms preprocess, 8.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v9f6.jpg: 384x640 4 persons, 8.3ms\n",
            "Speed: 2.2ms preprocess, 8.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v61f148.jpg: 384x640 4 persons, 12.1ms\n",
            "Speed: 3.5ms preprocess, 12.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v9f14.jpg: 384x640 5 persons, 7.9ms\n",
            "Speed: 2.3ms preprocess, 7.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v61f143.jpg: 384x640 4 persons, 8.1ms\n",
            "Speed: 2.2ms preprocess, 8.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v61f149.jpg: 384x640 4 persons, 8.6ms\n",
            "Speed: 2.3ms preprocess, 8.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v9f3.jpg: 384x640 4 persons, 8.4ms\n",
            "Speed: 2.1ms preprocess, 8.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v61f165.jpg: 384x640 4 persons, 8.3ms\n",
            "Speed: 2.5ms preprocess, 8.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v9f47.jpg: 384x640 4 persons, 8.0ms\n",
            "Speed: 2.3ms preprocess, 8.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v9f55.jpg: 384x640 5 persons, 14.4ms\n",
            "Speed: 4.1ms preprocess, 14.4ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v9f34.jpg: 384x640 6 persons, 8.5ms\n",
            "Speed: 2.3ms preprocess, 8.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v9f49.jpg: 384x640 5 persons, 8.6ms\n",
            "Speed: 2.4ms preprocess, 8.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v9f30.jpg: 384x640 5 persons, 8.2ms\n",
            "Speed: 2.3ms preprocess, 8.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v9f41.jpg: 384x640 6 persons, 8.3ms\n",
            "Speed: 2.2ms preprocess, 8.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v9f58.jpg: 384x640 5 persons, 8.2ms\n",
            "Speed: 2.4ms preprocess, 8.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v9f60.jpg: 384x640 6 persons, 8.2ms\n",
            "Speed: 2.4ms preprocess, 8.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v9f61.jpg: 384x640 6 persons, 10.6ms\n",
            "Speed: 3.7ms preprocess, 10.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v9f45.jpg: 384x640 6 persons, 8.2ms\n",
            "Speed: 2.3ms preprocess, 8.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v9f70.jpg: 384x640 5 persons, 8.4ms\n",
            "Speed: 2.2ms preprocess, 8.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v9f94.jpg: 384x640 3 persons, 8.6ms\n",
            "Speed: 2.4ms preprocess, 8.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v9f104.jpg: 384x640 5 persons, 8.5ms\n",
            "Speed: 2.3ms preprocess, 8.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v9f102.jpg: 384x640 5 persons, 8.3ms\n",
            "Speed: 2.3ms preprocess, 8.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v9f88.jpg: 384x640 6 persons, 10.7ms\n",
            "Speed: 2.4ms preprocess, 10.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v9f83.jpg: 384x640 5 persons, 10.3ms\n",
            "Speed: 4.5ms preprocess, 10.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v9f119.jpg: 384x640 4 persons, 9.4ms\n",
            "Speed: 2.2ms preprocess, 9.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v9f124.jpg: 384x640 4 persons, 9.8ms\n",
            "Speed: 2.4ms preprocess, 9.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v9f67.jpg: 384x640 5 persons, 9.4ms\n",
            "Speed: 2.4ms preprocess, 9.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v9f109.jpg: 384x640 6 persons, 8.6ms\n",
            "Speed: 2.4ms preprocess, 8.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v70f5.jpg: 384x640 4 persons, 8.4ms\n",
            "Speed: 2.3ms preprocess, 8.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v9f149.jpg: 384x640 4 persons, 8.3ms\n",
            "Speed: 2.2ms preprocess, 8.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v9f151.jpg: 384x640 4 persons, 14.9ms\n",
            "Speed: 3.6ms preprocess, 14.9ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v9f125.jpg: 384x640 4 persons, 8.2ms\n",
            "Speed: 2.3ms preprocess, 8.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v9f128.jpg: 384x640 4 persons, 8.3ms\n",
            "Speed: 2.3ms preprocess, 8.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v9f142.jpg: 384x640 3 persons, 14.0ms\n",
            "Speed: 2.3ms preprocess, 14.0ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v9f146.jpg: 384x640 3 persons, 8.3ms\n",
            "Speed: 2.2ms preprocess, 8.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v70f18.jpg: 384x640 4 persons, 8.4ms\n",
            "Speed: 2.3ms preprocess, 8.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v70f0.jpg: 384x640 4 persons, 11.4ms\n",
            "Speed: 3.8ms preprocess, 11.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v9f130.jpg: 384x640 4 persons, 8.8ms\n",
            "Speed: 2.4ms preprocess, 8.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v70f7.jpg: 384x640 4 persons, 8.1ms\n",
            "Speed: 2.3ms preprocess, 8.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v70f14.jpg: 384x640 4 persons, 8.5ms\n",
            "Speed: 2.4ms preprocess, 8.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v9f145.jpg: 384x640 3 persons, 8.1ms\n",
            "Speed: 2.2ms preprocess, 8.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v70f11.jpg: 384x640 4 persons, 8.5ms\n",
            "Speed: 2.5ms preprocess, 8.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v70f45.jpg: 384x640 4 persons, 8.2ms\n",
            "Speed: 2.4ms preprocess, 8.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v70f67.jpg: 384x640 4 persons, 8.3ms\n",
            "Speed: 2.2ms preprocess, 8.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v70f54.jpg: 384x640 4 persons, 10.8ms\n",
            "Speed: 3.6ms preprocess, 10.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v70f50.jpg: 384x640 5 persons, 8.8ms\n",
            "Speed: 2.3ms preprocess, 8.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v70f56.jpg: 384x640 4 persons, 8.3ms\n",
            "Speed: 2.3ms preprocess, 8.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v70f24.jpg: 384x640 4 persons, 9.0ms\n",
            "Speed: 2.5ms preprocess, 9.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v70f25.jpg: 384x640 4 persons, 8.5ms\n",
            "Speed: 2.3ms preprocess, 8.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v70f66.jpg: 384x640 4 persons, 8.1ms\n",
            "Speed: 2.2ms preprocess, 8.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v70f68.jpg: 384x640 4 persons, 8.8ms\n",
            "Speed: 2.6ms preprocess, 8.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v70f20.jpg: 384x640 4 persons, 15.2ms\n",
            "Speed: 4.0ms preprocess, 15.2ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v70f74.jpg: 384x640 4 persons, 14.4ms\n",
            "Speed: 3.3ms preprocess, 14.4ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v52f26.jpg: 384x640 3 persons, 8.3ms\n",
            "Speed: 2.4ms preprocess, 8.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v70f85.jpg: 384x640 4 persons, 8.6ms\n",
            "Speed: 2.3ms preprocess, 8.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v52f2.jpg: 384x640 2 persons, 8.6ms\n",
            "Speed: 2.4ms preprocess, 8.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v52f6.jpg: 384x640 2 persons, 8.1ms\n",
            "Speed: 2.1ms preprocess, 8.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v52f20.jpg: 384x640 2 persons, 8.2ms\n",
            "Speed: 2.4ms preprocess, 8.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v52f32.jpg: 384x640 2 persons, 11.2ms\n",
            "Speed: 3.6ms preprocess, 11.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v52f19.jpg: 384x640 2 persons, 14.8ms\n",
            "Speed: 3.6ms preprocess, 14.8ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v52f14.jpg: 384x640 2 persons, 8.1ms\n",
            "Speed: 2.6ms preprocess, 8.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v52f52.jpg: 384x640 1 person, 9.0ms\n",
            "Speed: 2.6ms preprocess, 9.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v52f58.jpg: 384x640 1 person, 8.4ms\n",
            "Speed: 2.2ms preprocess, 8.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v52f82.jpg: 384x640 2 persons, 8.5ms\n",
            "Speed: 2.2ms preprocess, 8.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v52f76.jpg: 384x640 2 persons, 8.8ms\n",
            "Speed: 2.4ms preprocess, 8.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v52f69.jpg: 384x640 1 person, 16.9ms\n",
            "Speed: 3.6ms preprocess, 16.9ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v52f85.jpg: 384x640 2 persons, 8.6ms\n",
            "Speed: 2.2ms preprocess, 8.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v52f74.jpg: 384x640 1 person, 8.7ms\n",
            "Speed: 2.5ms preprocess, 8.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v52f38.jpg: 384x640 3 persons, 9.0ms\n",
            "Speed: 2.3ms preprocess, 9.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v52f54.jpg: 384x640 1 person, 8.3ms\n",
            "Speed: 2.3ms preprocess, 8.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v52f68.jpg: 384x640 2 persons, 8.4ms\n",
            "Speed: 2.3ms preprocess, 8.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v52f72.jpg: 384x640 1 person, 10.5ms\n",
            "Speed: 2.5ms preprocess, 10.5ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v52f42.jpg: 384x640 2 persons, 10.4ms\n",
            "Speed: 3.8ms preprocess, 10.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v52f51.jpg: 384x640 1 person, 8.5ms\n",
            "Speed: 2.4ms preprocess, 8.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v52f92.jpg: 384x640 2 persons, 8.3ms\n",
            "Speed: 2.3ms preprocess, 8.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v52f98.jpg: 384x640 3 persons, 9.1ms\n",
            "Speed: 2.3ms preprocess, 9.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v86f17.jpg: 384x640 4 persons, 8.9ms\n",
            "Speed: 2.4ms preprocess, 8.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v52f104.jpg: 384x640 3 persons, 8.9ms\n",
            "Speed: 2.4ms preprocess, 8.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v52f100.jpg: 384x640 4 persons, 8.5ms\n",
            "Speed: 2.3ms preprocess, 8.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v86f4.jpg: 384x640 4 persons, 10.6ms\n",
            "Speed: 3.7ms preprocess, 10.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v52f96.jpg: 384x640 2 persons, 14.6ms\n",
            "Speed: 3.6ms preprocess, 14.6ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v52f87.jpg: 384x640 2 persons, 9.2ms\n",
            "Speed: 2.5ms preprocess, 9.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v52f90.jpg: 384x640 2 persons, 10.2ms\n",
            "Speed: 3.6ms preprocess, 10.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v86f40.jpg: 384x640 4 persons, 8.4ms\n",
            "Speed: 2.3ms preprocess, 8.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v86f67.jpg: 384x640 4 persons, 8.5ms\n",
            "Speed: 2.2ms preprocess, 8.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v86f51.jpg: 384x640 4 persons, 8.4ms\n",
            "Speed: 2.3ms preprocess, 8.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v86f47.jpg: 384x640 4 persons, 14.3ms\n",
            "Speed: 3.8ms preprocess, 14.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v86f36.jpg: 384x640 4 persons, 10.1ms\n",
            "Speed: 2.6ms preprocess, 10.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v86f104.jpg: 384x640 3 persons, 10.9ms\n",
            "Speed: 2.6ms preprocess, 10.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v86f93.jpg: 384x640 3 persons, 8.1ms\n",
            "Speed: 2.3ms preprocess, 8.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v86f114.jpg: 384x640 3 persons, 8.4ms\n",
            "Speed: 2.4ms preprocess, 8.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v86f92.jpg: 384x640 3 persons, 9.1ms\n",
            "Speed: 2.1ms preprocess, 9.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v86f137.jpg: 384x640 4 persons, 17.8ms\n",
            "Speed: 3.6ms preprocess, 17.8ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v86f147.jpg: 384x640 6 persons, 14.4ms\n",
            "Speed: 3.5ms preprocess, 14.4ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v86f136.jpg: 384x640 4 persons, 8.2ms\n",
            "Speed: 2.2ms preprocess, 8.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v86f217.jpg: 384x640 3 persons, 8.5ms\n",
            "Speed: 2.4ms preprocess, 8.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v86f189.jpg: 384x640 3 persons, 8.4ms\n",
            "Speed: 2.2ms preprocess, 8.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v86f206.jpg: 384x640 3 persons, 8.4ms\n",
            "Speed: 2.2ms preprocess, 8.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v86f201.jpg: 384x640 2 persons, 8.7ms\n",
            "Speed: 2.3ms preprocess, 8.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v86f248.jpg: 384x640 3 persons, 14.3ms\n",
            "Speed: 3.7ms preprocess, 14.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v86f241.jpg: 384x640 2 persons, 16.2ms\n",
            "Speed: 3.3ms preprocess, 16.2ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v86f265.jpg: 384x640 3 persons, 8.2ms\n",
            "Speed: 2.3ms preprocess, 8.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v86f275.jpg: 384x640 4 persons, 9.3ms\n",
            "Speed: 2.3ms preprocess, 9.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v86f303.jpg: 384x640 3 persons, 8.4ms\n",
            "Speed: 2.3ms preprocess, 8.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v86f297.jpg: 384x640 3 persons, 8.3ms\n",
            "Speed: 2.4ms preprocess, 8.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v86f348.jpg: 384x640 4 persons, 8.7ms\n",
            "Speed: 2.3ms preprocess, 8.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v47f16.jpg: 384x640 4 persons, 8.8ms\n",
            "Speed: 2.3ms preprocess, 8.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v86f333.jpg: 384x640 5 persons, 10.4ms\n",
            "Speed: 3.5ms preprocess, 10.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v47f10.jpg: 384x640 4 persons, 8.6ms\n",
            "Speed: 2.4ms preprocess, 8.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v86f317.jpg: 384x640 3 persons, 8.3ms\n",
            "Speed: 2.3ms preprocess, 8.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v86f319.jpg: 384x640 3 persons, 8.8ms\n",
            "Speed: 2.3ms preprocess, 8.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v86f339.jpg: 384x640 4 persons, 8.3ms\n",
            "Speed: 2.3ms preprocess, 8.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v47f4.jpg: 384x640 4 persons, 8.1ms\n",
            "Speed: 2.2ms preprocess, 8.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v47f24.jpg: 384x640 5 persons, 8.9ms\n",
            "Speed: 2.4ms preprocess, 8.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v47f46.jpg: 384x640 3 persons, 11.4ms\n",
            "Speed: 3.4ms preprocess, 11.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v47f18.jpg: 384x640 4 persons, 8.5ms\n",
            "Speed: 2.4ms preprocess, 8.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v47f47.jpg: 384x640 3 persons, 12.0ms\n",
            "Speed: 3.5ms preprocess, 12.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v47f27.jpg: 384x640 4 persons, 8.2ms\n",
            "Speed: 2.3ms preprocess, 8.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v47f28.jpg: 384x640 4 persons, 8.3ms\n",
            "Speed: 2.2ms preprocess, 8.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v47f22.jpg: 384x640 4 persons, 8.2ms\n",
            "Speed: 2.4ms preprocess, 8.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v47f34.jpg: 384x640 4 persons, 9.3ms\n",
            "Speed: 2.3ms preprocess, 9.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v47f38.jpg: 384x640 4 persons, 11.4ms\n",
            "Speed: 3.7ms preprocess, 11.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v47f51.jpg: 384x640 3 persons, 14.7ms\n",
            "Speed: 4.7ms preprocess, 14.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v47f57.jpg: 384x640 4 persons, 8.1ms\n",
            "Speed: 2.5ms preprocess, 8.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v47f53.jpg: 384x640 3 persons, 8.3ms\n",
            "Speed: 2.1ms preprocess, 8.3ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v47f59.jpg: 384x640 4 persons, 9.4ms\n",
            "Speed: 2.5ms preprocess, 9.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v47f90.jpg: 384x640 4 persons, 8.3ms\n",
            "Speed: 2.4ms preprocess, 8.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v47f83.jpg: 384x640 4 persons, 8.5ms\n",
            "Speed: 2.6ms preprocess, 8.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v47f66.jpg: 384x640 4 persons, 11.4ms\n",
            "Speed: 3.8ms preprocess, 11.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v47f81.jpg: 384x640 4 persons, 14.6ms\n",
            "Speed: 3.6ms preprocess, 14.6ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v47f102.jpg: 384x640 4 persons, 8.3ms\n",
            "Speed: 2.2ms preprocess, 8.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v47f72.jpg: 384x640 4 persons, 8.5ms\n",
            "Speed: 2.4ms preprocess, 8.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v47f77.jpg: 384x640 4 persons, 8.8ms\n",
            "Speed: 2.4ms preprocess, 8.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v47f61.jpg: 384x640 4 persons, 14.2ms\n",
            "Speed: 2.3ms preprocess, 14.2ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v47f80.jpg: 384x640 4 persons, 10.3ms\n",
            "Speed: 2.5ms preprocess, 10.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v47f100.jpg: 384x640 4 persons, 10.2ms\n",
            "Speed: 3.7ms preprocess, 10.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v47f119.jpg: 384x640 4 persons, 8.7ms\n",
            "Speed: 2.3ms preprocess, 8.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v47f145.jpg: 384x640 4 persons, 10.8ms\n",
            "Speed: 2.3ms preprocess, 10.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v47f149.jpg: 384x640 4 persons, 7.9ms\n",
            "Speed: 2.2ms preprocess, 7.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v47f135.jpg: 384x640 5 persons, 8.1ms\n",
            "Speed: 2.4ms preprocess, 8.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v47f105.jpg: 384x640 4 persons, 13.7ms\n",
            "Speed: 3.3ms preprocess, 13.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v47f107.jpg: 384x640 4 persons, 8.0ms\n",
            "Speed: 2.5ms preprocess, 8.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v47f151.jpg: 384x640 4 persons, 10.3ms\n",
            "Speed: 3.6ms preprocess, 10.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v18f2.jpg: 384x640 2 persons, 14.6ms\n",
            "Speed: 3.4ms preprocess, 14.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v18f7.jpg: 384x640 3 persons, 8.7ms\n",
            "Speed: 2.5ms preprocess, 8.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v18f21.jpg: 384x640 2 persons, 8.4ms\n",
            "Speed: 2.3ms preprocess, 8.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v18f23.jpg: 384x640 2 persons, 8.9ms\n",
            "Speed: 3.3ms preprocess, 8.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v47f162.jpg: 384x640 4 persons, 8.8ms\n",
            "Speed: 2.4ms preprocess, 8.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v47f160.jpg: 384x640 4 persons, 9.0ms\n",
            "Speed: 2.3ms preprocess, 9.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v18f22.jpg: 384x640 2 persons, 8.2ms\n",
            "Speed: 2.3ms preprocess, 8.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v18f32.jpg: 384x640 2 persons, 11.5ms\n",
            "Speed: 3.6ms preprocess, 11.5ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v18f75.jpg: 384x640 2 persons, 8.4ms\n",
            "Speed: 2.4ms preprocess, 8.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v18f76.jpg: 384x640 2 persons, 8.6ms\n",
            "Speed: 2.3ms preprocess, 8.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v18f121.jpg: 384x640 3 persons, 8.2ms\n",
            "Speed: 2.5ms preprocess, 8.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v18f78.jpg: 384x640 2 persons, 8.2ms\n",
            "Speed: 2.8ms preprocess, 8.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v18f111.jpg: 384x640 3 persons, 8.4ms\n",
            "Speed: 2.4ms preprocess, 8.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v18f120.jpg: 384x640 3 persons, 8.4ms\n",
            "Speed: 2.4ms preprocess, 8.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v18f112.jpg: 384x640 3 persons, 11.3ms\n",
            "Speed: 3.8ms preprocess, 11.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v18f109.jpg: 384x640 3 persons, 11.2ms\n",
            "Speed: 3.7ms preprocess, 11.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v18f99.jpg: 384x640 2 persons, 8.5ms\n",
            "Speed: 2.3ms preprocess, 8.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v18f113.jpg: 384x640 3 persons, 8.3ms\n",
            "Speed: 2.2ms preprocess, 8.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v18f166.jpg: 384x640 2 persons, 9.3ms\n",
            "Speed: 2.4ms preprocess, 9.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v18f130.jpg: 384x640 3 persons, 8.2ms\n",
            "Speed: 2.4ms preprocess, 8.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v18f146.jpg: 384x640 4 persons, 8.1ms\n",
            "Speed: 2.3ms preprocess, 8.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v18f148.jpg: 384x640 3 persons, 8.2ms\n",
            "Speed: 2.3ms preprocess, 8.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v18f178.jpg: 384x640 3 persons, 12.2ms\n",
            "Speed: 3.8ms preprocess, 12.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v7f0.jpg: 384x640 3 persons, 8.6ms\n",
            "Speed: 2.1ms preprocess, 8.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v18f174.jpg: 384x640 3 persons, 8.1ms\n",
            "Speed: 2.2ms preprocess, 8.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v18f133.jpg: 384x640 3 persons, 8.3ms\n",
            "Speed: 2.2ms preprocess, 8.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v7f22.jpg: 384x640 2 persons, 8.3ms\n",
            "Speed: 2.4ms preprocess, 8.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v7f71.jpg: 384x640 3 persons, 8.7ms\n",
            "Speed: 2.3ms preprocess, 8.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v7f63.jpg: 384x640 2 persons, 8.2ms\n",
            "Speed: 2.2ms preprocess, 8.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v7f88.jpg: 384x640 4 persons, 17.7ms\n",
            "Speed: 3.8ms preprocess, 17.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v7f56.jpg: 384x640 2 persons, 8.4ms\n",
            "Speed: 2.3ms preprocess, 8.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v93f3.jpg: 384x640 4 persons, 10.1ms\n",
            "Speed: 2.6ms preprocess, 10.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v7f113.jpg: 384x640 3 persons, 8.0ms\n",
            "Speed: 2.3ms preprocess, 8.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v93f10.jpg: 384x640 4 persons, 8.1ms\n",
            "Speed: 2.2ms preprocess, 8.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v93f4.jpg: 384x640 5 persons, 8.3ms\n",
            "Speed: 2.4ms preprocess, 8.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v7f124.jpg: 384x640 3 persons, 8.1ms\n",
            "Speed: 2.3ms preprocess, 8.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v93f9.jpg: 384x640 4 persons, 15.0ms\n",
            "Speed: 3.7ms preprocess, 15.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v93f59.jpg: 384x640 4 persons, 8.5ms\n",
            "Speed: 2.3ms preprocess, 8.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v93f17.jpg: 384x640 4 persons, 8.5ms\n",
            "Speed: 2.2ms preprocess, 8.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v93f18.jpg: 384x640 4 persons, 8.2ms\n",
            "Speed: 2.3ms preprocess, 8.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v93f58.jpg: 384x640 4 persons, 8.5ms\n",
            "Speed: 2.2ms preprocess, 8.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v93f39.jpg: 384x640 4 persons, 8.2ms\n",
            "Speed: 2.4ms preprocess, 8.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v93f26.jpg: 384x640 4 persons, 14.8ms\n",
            "Speed: 3.6ms preprocess, 14.8ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v93f25.jpg: 384x640 4 persons, 14.6ms\n",
            "Speed: 3.7ms preprocess, 14.6ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v93f53.jpg: 384x640 4 persons, 8.7ms\n",
            "Speed: 2.2ms preprocess, 8.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v93f28.jpg: 384x640 4 persons, 8.6ms\n",
            "Speed: 2.3ms preprocess, 8.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v93f46.jpg: 384x640 4 persons, 8.1ms\n",
            "Speed: 2.4ms preprocess, 8.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v48f3.jpg: 384x640 4 persons, 8.4ms\n",
            "Speed: 2.3ms preprocess, 8.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v48f24.jpg: 384x640 4 persons, 14.7ms\n",
            "Speed: 3.5ms preprocess, 14.7ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v93f68.jpg: 384x640 4 persons, 10.4ms\n",
            "Speed: 3.6ms preprocess, 10.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v93f78.jpg: 384x640 4 persons, 9.5ms\n",
            "Speed: 3.6ms preprocess, 9.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/violent/v93f74.jpg: 384x640 4 persons, 8.2ms\n",
            "Speed: 2.2ms preprocess, 8.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v32f155.jpg: 384x640 1 person, 8.2ms\n",
            "Speed: 2.4ms preprocess, 8.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v32f161.jpg: 384x640 1 person, 8.6ms\n",
            "Speed: 2.2ms preprocess, 8.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v32f167.jpg: 384x640 2 persons, 8.5ms\n",
            "Speed: 2.3ms preprocess, 8.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v32f145.jpg: 384x640 2 persons, 9.4ms\n",
            "Speed: 2.7ms preprocess, 9.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v32f153.jpg: 384x640 1 person, 10.5ms\n",
            "Speed: 4.3ms preprocess, 10.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v32f165.jpg: 384x640 2 persons, 8.4ms\n",
            "Speed: 2.5ms preprocess, 8.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v32f151.jpg: 384x640 1 person, 8.2ms\n",
            "Speed: 2.3ms preprocess, 8.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v32f156.jpg: 384x640 1 person, 9.1ms\n",
            "Speed: 2.2ms preprocess, 9.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v18f13.jpg: 384x640 4 persons, 8.7ms\n",
            "Speed: 2.5ms preprocess, 8.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v18f26.jpg: 384x640 4 persons, 8.4ms\n",
            "Speed: 2.3ms preprocess, 8.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v18f27.jpg: 384x640 4 persons, 14.7ms\n",
            "Speed: 4.2ms preprocess, 14.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v18f32.jpg: 384x640 4 persons, 14.5ms\n",
            "Speed: 3.5ms preprocess, 14.5ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v18f19.jpg: 384x640 4 persons, 8.8ms\n",
            "Speed: 3.5ms preprocess, 8.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v18f39.jpg: 384x640 4 persons, 8.7ms\n",
            "Speed: 2.4ms preprocess, 8.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v18f28.jpg: 384x640 4 persons, 8.4ms\n",
            "Speed: 2.3ms preprocess, 8.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v32f182.jpg: 384x640 3 persons, 8.8ms\n",
            "Speed: 2.4ms preprocess, 8.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v18f17.jpg: 384x640 4 persons, 10.2ms\n",
            "Speed: 3.7ms preprocess, 10.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v32f190.jpg: 384x640 4 persons, 8.5ms\n",
            "Speed: 2.2ms preprocess, 8.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v32f186.jpg: 384x640 4 persons, 14.3ms\n",
            "Speed: 3.8ms preprocess, 14.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v18f1.jpg: 384x640 4 persons, 10.9ms\n",
            "Speed: 2.9ms preprocess, 10.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v32f191.jpg: 384x640 3 persons, 14.5ms\n",
            "Speed: 3.5ms preprocess, 14.5ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v32f183.jpg: 384x640 3 persons, 8.3ms\n",
            "Speed: 2.3ms preprocess, 8.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v18f31.jpg: 384x640 4 persons, 7.9ms\n",
            "Speed: 2.4ms preprocess, 7.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v18f12.jpg: 384x640 4 persons, 8.5ms\n",
            "Speed: 2.5ms preprocess, 8.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v18f72.jpg: 384x640 4 persons, 10.5ms\n",
            "Speed: 3.7ms preprocess, 10.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v18f81.jpg: 384x640 7 persons, 8.0ms\n",
            "Speed: 2.2ms preprocess, 8.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v18f68.jpg: 384x640 4 persons, 8.2ms\n",
            "Speed: 2.4ms preprocess, 8.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v18f48.jpg: 384x640 4 persons, 8.2ms\n",
            "Speed: 2.4ms preprocess, 8.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v18f42.jpg: 384x640 4 persons, 8.5ms\n",
            "Speed: 2.3ms preprocess, 8.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v18f77.jpg: 384x640 4 persons, 8.0ms\n",
            "Speed: 2.2ms preprocess, 8.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v18f54.jpg: 384x640 4 persons, 8.4ms\n",
            "Speed: 2.3ms preprocess, 8.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v18f91.jpg: 384x640 5 persons, 11.5ms\n",
            "Speed: 3.8ms preprocess, 11.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v18f89.jpg: 384x640 5 persons, 8.2ms\n",
            "Speed: 2.3ms preprocess, 8.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v18f86.jpg: 384x640 4 persons, 8.3ms\n",
            "Speed: 2.2ms preprocess, 8.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v18f67.jpg: 384x640 4 persons, 8.3ms\n",
            "Speed: 2.3ms preprocess, 8.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v18f78.jpg: 384x640 4 persons, 8.5ms\n",
            "Speed: 2.2ms preprocess, 8.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v18f65.jpg: 384x640 4 persons, 9.9ms\n",
            "Speed: 2.2ms preprocess, 9.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v18f125.jpg: 384x640 4 persons, 16.7ms\n",
            "Speed: 3.7ms preprocess, 16.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v18f100.jpg: 384x640 3 persons, 9.1ms\n",
            "Speed: 2.6ms preprocess, 9.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v18f116.jpg: 384x640 5 persons, 8.2ms\n",
            "Speed: 2.3ms preprocess, 8.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v18f120.jpg: 384x640 4 persons, 8.2ms\n",
            "Speed: 2.1ms preprocess, 8.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v18f111.jpg: 384x640 3 persons, 8.4ms\n",
            "Speed: 2.3ms preprocess, 8.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v18f138.jpg: 384x640 5 persons, 15.1ms\n",
            "Speed: 3.6ms preprocess, 15.1ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v18f110.jpg: 384x640 3 persons, 9.7ms\n",
            "Speed: 2.1ms preprocess, 9.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v18f140.jpg: 384x640 4 persons, 11.4ms\n",
            "Speed: 3.9ms preprocess, 11.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v18f115.jpg: 384x640 4 persons, 9.0ms\n",
            "Speed: 3.5ms preprocess, 9.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v18f126.jpg: 384x640 4 persons, 8.4ms\n",
            "Speed: 2.3ms preprocess, 8.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v18f134.jpg: 384x640 4 persons, 11.7ms\n",
            "Speed: 3.0ms preprocess, 11.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v18f92.jpg: 384x640 4 persons, 8.5ms\n",
            "Speed: 2.3ms preprocess, 8.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v18f99.jpg: 384x640 4 persons, 8.0ms\n",
            "Speed: 2.2ms preprocess, 8.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v18f183.jpg: 384x640 3 persons, 8.1ms\n",
            "Speed: 2.2ms preprocess, 8.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v18f154.jpg: 384x640 4 persons, 11.2ms\n",
            "Speed: 3.9ms preprocess, 11.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v18f157.jpg: 384x640 4 persons, 8.5ms\n",
            "Speed: 2.3ms preprocess, 8.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v18f151.jpg: 384x640 4 persons, 9.4ms\n",
            "Speed: 3.5ms preprocess, 9.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v18f150.jpg: 384x640 4 persons, 8.8ms\n",
            "Speed: 2.6ms preprocess, 8.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v18f166.jpg: 384x640 4 persons, 8.5ms\n",
            "Speed: 2.3ms preprocess, 8.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v18f174.jpg: 384x640 5 persons, 8.4ms\n",
            "Speed: 2.2ms preprocess, 8.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v18f155.jpg: 384x640 4 persons, 10.2ms\n",
            "Speed: 3.4ms preprocess, 10.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v18f158.jpg: 384x640 4 persons, 8.8ms\n",
            "Speed: 2.2ms preprocess, 8.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v18f172.jpg: 384x640 4 persons, 8.5ms\n",
            "Speed: 2.3ms preprocess, 8.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v18f152.jpg: 384x640 4 persons, 14.1ms\n",
            "Speed: 2.6ms preprocess, 14.1ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v18f189.jpg: 384x640 3 persons, 8.1ms\n",
            "Speed: 2.2ms preprocess, 8.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v18f161.jpg: 384x640 4 persons, 8.4ms\n",
            "Speed: 2.2ms preprocess, 8.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v18f178.jpg: 384x640 4 persons, 10.7ms\n",
            "Speed: 3.8ms preprocess, 10.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v18f164.jpg: 384x640 5 persons, 14.5ms\n",
            "Speed: 3.9ms preprocess, 14.5ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v18f187.jpg: 384x640 3 persons, 9.4ms\n",
            "Speed: 2.4ms preprocess, 9.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v18f167.jpg: 384x640 4 persons, 8.2ms\n",
            "Speed: 2.2ms preprocess, 8.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v18f156.jpg: 384x640 4 persons, 8.1ms\n",
            "Speed: 2.1ms preprocess, 8.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v18f175.jpg: 384x640 5 persons, 8.2ms\n",
            "Speed: 2.3ms preprocess, 8.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v18f168.jpg: 384x640 4 persons, 14.7ms\n",
            "Speed: 3.6ms preprocess, 14.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v48f30.jpg: 384x640 3 persons, 23.1ms\n",
            "Speed: 3.8ms preprocess, 23.1ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v48f46.jpg: 384x640 4 persons, 8.1ms\n",
            "Speed: 2.2ms preprocess, 8.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v48f29.jpg: 384x640 4 persons, 10.8ms\n",
            "Speed: 2.3ms preprocess, 10.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v48f23.jpg: 384x640 4 persons, 9.2ms\n",
            "Speed: 2.3ms preprocess, 9.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v48f27.jpg: 384x640 4 persons, 8.2ms\n",
            "Speed: 2.4ms preprocess, 8.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v48f22.jpg: 384x640 4 persons, 8.9ms\n",
            "Speed: 2.4ms preprocess, 8.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v48f28.jpg: 384x640 4 persons, 14.3ms\n",
            "Speed: 3.9ms preprocess, 14.3ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v48f7.jpg: 384x640 3 persons, 11.1ms\n",
            "Speed: 3.6ms preprocess, 11.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v48f20.jpg: 384x640 4 persons, 8.5ms\n",
            "Speed: 2.3ms preprocess, 8.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v48f18.jpg: 384x640 3 persons, 8.7ms\n",
            "Speed: 2.4ms preprocess, 8.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v48f15.jpg: 384x640 3 persons, 8.3ms\n",
            "Speed: 2.4ms preprocess, 8.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v48f41.jpg: 384x640 3 persons, 8.1ms\n",
            "Speed: 2.2ms preprocess, 8.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v48f11.jpg: 384x640 3 persons, 8.4ms\n",
            "Speed: 2.3ms preprocess, 8.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v48f31.jpg: 384x640 3 persons, 11.4ms\n",
            "Speed: 3.7ms preprocess, 11.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v48f32.jpg: 384x640 3 persons, 18.8ms\n",
            "Speed: 4.3ms preprocess, 18.8ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v48f34.jpg: 384x640 3 persons, 9.0ms\n",
            "Speed: 2.3ms preprocess, 9.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v48f49.jpg: 384x640 4 persons, 8.5ms\n",
            "Speed: 2.3ms preprocess, 8.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v48f13.jpg: 384x640 3 persons, 16.3ms\n",
            "Speed: 3.6ms preprocess, 16.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v48f25.jpg: 384x640 4 persons, 8.2ms\n",
            "Speed: 2.4ms preprocess, 8.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v48f106.jpg: 384x640 3 persons, 8.5ms\n",
            "Speed: 2.4ms preprocess, 8.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v48f79.jpg: 384x640 3 persons, 10.2ms\n",
            "Speed: 3.6ms preprocess, 10.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v48f95.jpg: 384x640 3 persons, 8.4ms\n",
            "Speed: 2.4ms preprocess, 8.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v48f94.jpg: 384x640 3 persons, 15.0ms\n",
            "Speed: 3.6ms preprocess, 15.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v48f58.jpg: 384x640 4 persons, 8.3ms\n",
            "Speed: 2.3ms preprocess, 8.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v48f87.jpg: 384x640 3 persons, 8.3ms\n",
            "Speed: 2.2ms preprocess, 8.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v48f75.jpg: 384x640 3 persons, 8.5ms\n",
            "Speed: 2.5ms preprocess, 8.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v48f51.jpg: 384x640 4 persons, 8.2ms\n",
            "Speed: 2.3ms preprocess, 8.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v48f74.jpg: 384x640 3 persons, 11.1ms\n",
            "Speed: 3.8ms preprocess, 11.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v48f71.jpg: 384x640 3 persons, 8.3ms\n",
            "Speed: 2.2ms preprocess, 8.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v48f68.jpg: 384x640 3 persons, 8.5ms\n",
            "Speed: 2.3ms preprocess, 8.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v48f85.jpg: 384x640 3 persons, 8.3ms\n",
            "Speed: 2.2ms preprocess, 8.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v48f78.jpg: 384x640 3 persons, 8.6ms\n",
            "Speed: 2.3ms preprocess, 8.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v48f90.jpg: 384x640 3 persons, 8.3ms\n",
            "Speed: 2.3ms preprocess, 8.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v48f50.jpg: 384x640 3 persons, 8.5ms\n",
            "Speed: 2.2ms preprocess, 8.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v48f89.jpg: 384x640 3 persons, 10.8ms\n",
            "Speed: 3.5ms preprocess, 10.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v48f82.jpg: 384x640 3 persons, 9.1ms\n",
            "Speed: 2.7ms preprocess, 9.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v48f67.jpg: 384x640 3 persons, 10.8ms\n",
            "Speed: 3.7ms preprocess, 10.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v48f101.jpg: 384x640 3 persons, 8.3ms\n",
            "Speed: 2.3ms preprocess, 8.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v48f113.jpg: 384x640 3 persons, 8.4ms\n",
            "Speed: 2.3ms preprocess, 8.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v55f8.jpg: 384x640 3 persons, 9.0ms\n",
            "Speed: 2.4ms preprocess, 9.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v55f23.jpg: 384x640 3 persons, 8.2ms\n",
            "Speed: 2.3ms preprocess, 8.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v48f108.jpg: 384x640 3 persons, 11.6ms\n",
            "Speed: 3.8ms preprocess, 11.6ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v55f15.jpg: 384x640 3 persons, 8.2ms\n",
            "Speed: 2.4ms preprocess, 8.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v55f33.jpg: 384x640 3 persons, 8.1ms\n",
            "Speed: 2.3ms preprocess, 8.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v55f29.jpg: 384x640 3 persons, 8.5ms\n",
            "Speed: 2.4ms preprocess, 8.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v55f17.jpg: 384x640 3 persons, 8.3ms\n",
            "Speed: 2.2ms preprocess, 8.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v55f12.jpg: 384x640 3 persons, 8.7ms\n",
            "Speed: 2.3ms preprocess, 8.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v48f112.jpg: 384x640 3 persons, 15.2ms\n",
            "Speed: 3.8ms preprocess, 15.2ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v55f1.jpg: 384x640 3 persons, 8.3ms\n",
            "Speed: 2.5ms preprocess, 8.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v55f19.jpg: 384x640 3 persons, 8.5ms\n",
            "Speed: 2.2ms preprocess, 8.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v55f0.jpg: 384x640 3 persons, 8.8ms\n",
            "Speed: 2.3ms preprocess, 8.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v55f10.jpg: 384x640 3 persons, 9.4ms\n",
            "Speed: 2.2ms preprocess, 9.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v55f38.jpg: 384x640 3 persons, 8.5ms\n",
            "Speed: 2.3ms preprocess, 8.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v55f4.jpg: 384x640 3 persons, 8.5ms\n",
            "Speed: 2.5ms preprocess, 8.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v55f58.jpg: 384x640 3 persons, 10.5ms\n",
            "Speed: 3.9ms preprocess, 10.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v55f82.jpg: 384x640 3 persons, 10.3ms\n",
            "Speed: 2.4ms preprocess, 10.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v55f43.jpg: 384x640 3 persons, 9.2ms\n",
            "Speed: 2.4ms preprocess, 9.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v55f70.jpg: 384x640 4 persons, 8.2ms\n",
            "Speed: 2.3ms preprocess, 8.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v55f41.jpg: 384x640 3 persons, 8.6ms\n",
            "Speed: 2.2ms preprocess, 8.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v55f68.jpg: 384x640 4 persons, 8.0ms\n",
            "Speed: 2.3ms preprocess, 8.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v55f75.jpg: 384x640 3 persons, 11.7ms\n",
            "Speed: 3.9ms preprocess, 11.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v55f62.jpg: 384x640 3 persons, 8.1ms\n",
            "Speed: 2.3ms preprocess, 8.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v55f47.jpg: 384x640 3 persons, 8.3ms\n",
            "Speed: 2.3ms preprocess, 8.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v55f42.jpg: 384x640 3 persons, 8.8ms\n",
            "Speed: 2.1ms preprocess, 8.8ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v55f61.jpg: 384x640 3 persons, 8.8ms\n",
            "Speed: 2.4ms preprocess, 8.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v55f80.jpg: 384x640 3 persons, 8.3ms\n",
            "Speed: 2.1ms preprocess, 8.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v55f78.jpg: 384x640 4 persons, 10.7ms\n",
            "Speed: 3.5ms preprocess, 10.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v55f81.jpg: 384x640 3 persons, 18.2ms\n",
            "Speed: 3.5ms preprocess, 18.2ms inference, 6.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v55f79.jpg: 384x640 3 persons, 14.3ms\n",
            "Speed: 3.5ms preprocess, 14.3ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v55f60.jpg: 384x640 3 persons, 8.2ms\n",
            "Speed: 2.3ms preprocess, 8.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v55f49.jpg: 384x640 3 persons, 8.6ms\n",
            "Speed: 2.4ms preprocess, 8.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v55f89.jpg: 384x640 3 persons, 9.1ms\n",
            "Speed: 2.3ms preprocess, 9.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v55f53.jpg: 384x640 3 persons, 8.0ms\n",
            "Speed: 2.4ms preprocess, 8.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v55f50.jpg: 384x640 3 persons, 8.5ms\n",
            "Speed: 2.6ms preprocess, 8.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v55f52.jpg: 384x640 3 persons, 12.8ms\n",
            "Speed: 3.9ms preprocess, 12.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v55f54.jpg: 384x640 3 persons, 8.0ms\n",
            "Speed: 2.4ms preprocess, 8.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v55f107.jpg: 384x640 4 persons, 8.1ms\n",
            "Speed: 2.2ms preprocess, 8.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v55f109.jpg: 384x640 4 persons, 8.3ms\n",
            "Speed: 2.2ms preprocess, 8.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v55f113.jpg: 384x640 3 persons, 9.1ms\n",
            "Speed: 2.6ms preprocess, 9.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v55f99.jpg: 384x640 4 persons, 8.7ms\n",
            "Speed: 2.3ms preprocess, 8.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v13f8.jpg: 384x640 4 persons, 11.9ms\n",
            "Speed: 3.9ms preprocess, 11.9ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v13f12.jpg: 384x640 4 persons, 14.5ms\n",
            "Speed: 4.7ms preprocess, 14.5ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v55f106.jpg: 384x640 4 persons, 8.5ms\n",
            "Speed: 2.2ms preprocess, 8.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v55f122.jpg: 384x640 3 persons, 8.3ms\n",
            "Speed: 2.2ms preprocess, 8.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v13f1.jpg: 384x640 4 persons, 8.1ms\n",
            "Speed: 2.2ms preprocess, 8.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v13f5.jpg: 384x640 4 persons, 8.8ms\n",
            "Speed: 2.4ms preprocess, 8.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v55f126.jpg: 384x640 3 persons, 8.3ms\n",
            "Speed: 2.3ms preprocess, 8.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v55f129.jpg: 384x640 3 persons, 11.0ms\n",
            "Speed: 3.6ms preprocess, 11.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v55f119.jpg: 384x640 3 persons, 14.7ms\n",
            "Speed: 3.7ms preprocess, 14.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v55f108.jpg: 384x640 4 persons, 9.1ms\n",
            "Speed: 2.3ms preprocess, 9.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v55f110.jpg: 384x640 4 persons, 8.8ms\n",
            "Speed: 2.5ms preprocess, 8.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v13f10.jpg: 384x640 4 persons, 7.8ms\n",
            "Speed: 2.2ms preprocess, 7.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v55f121.jpg: 384x640 3 persons, 7.9ms\n",
            "Speed: 2.4ms preprocess, 7.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v55f104.jpg: 384x640 4 persons, 8.1ms\n",
            "Speed: 2.2ms preprocess, 8.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v13f16.jpg: 384x640 4 persons, 10.6ms\n",
            "Speed: 3.7ms preprocess, 10.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v13f54.jpg: 384x640 4 persons, 8.6ms\n",
            "Speed: 2.5ms preprocess, 8.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v13f61.jpg: 384x640 4 persons, 8.5ms\n",
            "Speed: 2.4ms preprocess, 8.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v13f24.jpg: 384x640 4 persons, 8.0ms\n",
            "Speed: 2.3ms preprocess, 8.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v13f38.jpg: 384x640 4 persons, 8.4ms\n",
            "Speed: 2.3ms preprocess, 8.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v13f45.jpg: 384x640 4 persons, 9.4ms\n",
            "Speed: 2.8ms preprocess, 9.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v13f51.jpg: 384x640 4 persons, 11.7ms\n",
            "Speed: 3.6ms preprocess, 11.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v13f37.jpg: 384x640 4 persons, 17.3ms\n",
            "Speed: 3.5ms preprocess, 17.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v13f22.jpg: 384x640 5 persons, 8.9ms\n",
            "Speed: 2.3ms preprocess, 8.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v13f53.jpg: 384x640 4 persons, 7.9ms\n",
            "Speed: 2.2ms preprocess, 7.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v13f59.jpg: 384x640 5 persons, 8.2ms\n",
            "Speed: 2.2ms preprocess, 8.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v13f20.jpg: 384x640 5 persons, 8.3ms\n",
            "Speed: 2.3ms preprocess, 8.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v13f18.jpg: 384x640 4 persons, 10.1ms\n",
            "Speed: 2.5ms preprocess, 10.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v13f41.jpg: 384x640 4 persons, 10.4ms\n",
            "Speed: 3.7ms preprocess, 10.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v13f33.jpg: 384x640 4 persons, 15.3ms\n",
            "Speed: 3.8ms preprocess, 15.3ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v13f60.jpg: 384x640 5 persons, 8.3ms\n",
            "Speed: 2.4ms preprocess, 8.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v13f83.jpg: 384x640 4 persons, 8.2ms\n",
            "Speed: 2.3ms preprocess, 8.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v13f84.jpg: 384x640 4 persons, 8.2ms\n",
            "Speed: 2.4ms preprocess, 8.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v13f85.jpg: 384x640 4 persons, 8.2ms\n",
            "Speed: 3.1ms preprocess, 8.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v13f96.jpg: 384x640 4 persons, 9.8ms\n",
            "Speed: 2.3ms preprocess, 9.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v13f66.jpg: 384x640 4 persons, 10.4ms\n",
            "Speed: 3.5ms preprocess, 10.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v13f95.jpg: 384x640 4 persons, 8.2ms\n",
            "Speed: 2.3ms preprocess, 8.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v13f87.jpg: 384x640 5 persons, 8.4ms\n",
            "Speed: 2.3ms preprocess, 8.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v13f103.jpg: 384x640 4 persons, 8.1ms\n",
            "Speed: 2.2ms preprocess, 8.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v13f63.jpg: 384x640 4 persons, 8.6ms\n",
            "Speed: 2.4ms preprocess, 8.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v13f99.jpg: 384x640 4 persons, 8.3ms\n",
            "Speed: 2.3ms preprocess, 8.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v13f76.jpg: 384x640 4 persons, 8.1ms\n",
            "Speed: 2.2ms preprocess, 8.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v13f70.jpg: 384x640 4 persons, 14.6ms\n",
            "Speed: 6.1ms preprocess, 14.6ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v13f91.jpg: 384x640 4 persons, 8.2ms\n",
            "Speed: 2.4ms preprocess, 8.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v13f69.jpg: 384x640 4 persons, 8.5ms\n",
            "Speed: 2.1ms preprocess, 8.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v13f73.jpg: 384x640 4 persons, 8.7ms\n",
            "Speed: 2.1ms preprocess, 8.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v13f101.jpg: 384x640 4 persons, 7.8ms\n",
            "Speed: 2.2ms preprocess, 7.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v13f77.jpg: 384x640 4 persons, 8.8ms\n",
            "Speed: 2.3ms preprocess, 8.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v13f88.jpg: 384x640 5 persons, 18.1ms\n",
            "Speed: 5.6ms preprocess, 18.1ms inference, 8.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v13f148.jpg: 384x640 4 persons, 13.5ms\n",
            "Speed: 2.3ms preprocess, 13.5ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v13f126.jpg: 384x640 4 persons, 7.9ms\n",
            "Speed: 2.2ms preprocess, 7.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v13f110.jpg: 384x640 4 persons, 8.1ms\n",
            "Speed: 2.4ms preprocess, 8.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v13f149.jpg: 384x640 3 persons, 8.0ms\n",
            "Speed: 2.1ms preprocess, 8.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v13f104.jpg: 384x640 4 persons, 8.1ms\n",
            "Speed: 2.1ms preprocess, 8.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v13f107.jpg: 384x640 4 persons, 8.1ms\n",
            "Speed: 2.1ms preprocess, 8.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v13f132.jpg: 384x640 4 persons, 14.7ms\n",
            "Speed: 4.1ms preprocess, 14.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v13f112.jpg: 384x640 5 persons, 7.9ms\n",
            "Speed: 2.2ms preprocess, 7.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v13f128.jpg: 384x640 4 persons, 8.0ms\n",
            "Speed: 2.3ms preprocess, 8.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v13f138.jpg: 384x640 6 persons, 8.3ms\n",
            "Speed: 2.2ms preprocess, 8.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v13f113.jpg: 384x640 5 persons, 9.1ms\n",
            "Speed: 2.4ms preprocess, 9.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v13f144.jpg: 384x640 4 persons, 8.3ms\n",
            "Speed: 2.2ms preprocess, 8.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v13f139.jpg: 384x640 3 persons, 14.8ms\n",
            "Speed: 3.5ms preprocess, 14.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v13f130.jpg: 384x640 4 persons, 14.3ms\n",
            "Speed: 3.6ms preprocess, 14.3ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v13f116.jpg: 384x640 5 persons, 14.0ms\n",
            "Speed: 3.6ms preprocess, 14.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v13f106.jpg: 384x640 4 persons, 8.7ms\n",
            "Speed: 2.4ms preprocess, 8.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v13f142.jpg: 384x640 3 persons, 8.2ms\n",
            "Speed: 2.5ms preprocess, 8.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v13f122.jpg: 384x640 4 persons, 8.9ms\n",
            "Speed: 2.3ms preprocess, 8.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v13f114.jpg: 384x640 5 persons, 8.2ms\n",
            "Speed: 2.3ms preprocess, 8.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v13f176.jpg: 384x640 4 persons, 10.2ms\n",
            "Speed: 3.7ms preprocess, 10.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v13f181.jpg: 384x640 4 persons, 9.9ms\n",
            "Speed: 2.5ms preprocess, 9.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v13f166.jpg: 384x640 5 persons, 8.8ms\n",
            "Speed: 2.4ms preprocess, 8.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v13f178.jpg: 384x640 4 persons, 9.3ms\n",
            "Speed: 2.2ms preprocess, 9.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v13f154.jpg: 384x640 3 persons, 8.7ms\n",
            "Speed: 2.2ms preprocess, 8.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v13f160.jpg: 384x640 4 persons, 8.3ms\n",
            "Speed: 2.3ms preprocess, 8.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v13f195.jpg: 384x640 3 persons, 8.4ms\n",
            "Speed: 2.2ms preprocess, 8.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v13f157.jpg: 384x640 4 persons, 10.3ms\n",
            "Speed: 3.8ms preprocess, 10.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v13f177.jpg: 384x640 4 persons, 10.1ms\n",
            "Speed: 2.2ms preprocess, 10.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v13f203.jpg: 384x640 4 persons, 8.9ms\n",
            "Speed: 2.3ms preprocess, 8.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v13f204.jpg: 384x640 4 persons, 8.2ms\n",
            "Speed: 2.3ms preprocess, 8.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v13f205.jpg: 384x640 5 persons, 7.9ms\n",
            "Speed: 2.3ms preprocess, 7.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v13f196.jpg: 384x640 3 persons, 8.5ms\n",
            "Speed: 2.2ms preprocess, 8.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v13f202.jpg: 384x640 5 persons, 14.2ms\n",
            "Speed: 2.4ms preprocess, 14.2ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v13f164.jpg: 384x640 5 persons, 10.4ms\n",
            "Speed: 3.7ms preprocess, 10.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v13f213.jpg: 384x640 4 persons, 8.7ms\n",
            "Speed: 3.5ms preprocess, 8.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v13f210.jpg: 384x640 4 persons, 8.1ms\n",
            "Speed: 2.3ms preprocess, 8.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v13f246.jpg: 384x640 5 persons, 8.4ms\n",
            "Speed: 2.2ms preprocess, 8.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v13f215.jpg: 384x640 5 persons, 8.2ms\n",
            "Speed: 2.1ms preprocess, 8.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v13f249.jpg: 384x640 4 persons, 8.2ms\n",
            "Speed: 2.3ms preprocess, 8.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v13f225.jpg: 384x640 4 persons, 14.4ms\n",
            "Speed: 3.7ms preprocess, 14.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v13f207.jpg: 384x640 4 persons, 16.9ms\n",
            "Speed: 3.6ms preprocess, 16.9ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v13f237.jpg: 384x640 4 persons, 11.2ms\n",
            "Speed: 2.4ms preprocess, 11.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v13f227.jpg: 384x640 4 persons, 8.4ms\n",
            "Speed: 2.4ms preprocess, 8.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v13f254.jpg: 384x640 4 persons, 8.4ms\n",
            "Speed: 2.3ms preprocess, 8.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v13f218.jpg: 384x640 4 persons, 8.5ms\n",
            "Speed: 2.4ms preprocess, 8.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v13f233.jpg: 384x640 4 persons, 8.9ms\n",
            "Speed: 2.1ms preprocess, 8.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v13f247.jpg: 384x640 4 persons, 17.3ms\n",
            "Speed: 3.6ms preprocess, 17.3ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v13f226.jpg: 384x640 4 persons, 9.0ms\n",
            "Speed: 2.5ms preprocess, 9.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v13f229.jpg: 384x640 4 persons, 8.5ms\n",
            "Speed: 2.3ms preprocess, 8.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v13f243.jpg: 384x640 4 persons, 8.2ms\n",
            "Speed: 2.1ms preprocess, 8.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v21f0.jpg: 384x640 4 persons, 8.3ms\n",
            "Speed: 2.3ms preprocess, 8.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v21f42.jpg: 384x640 4 persons, 8.8ms\n",
            "Speed: 2.2ms preprocess, 8.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v13f256.jpg: 384x640 4 persons, 8.8ms\n",
            "Speed: 3.3ms preprocess, 8.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v21f27.jpg: 384x640 4 persons, 10.6ms\n",
            "Speed: 3.6ms preprocess, 10.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v21f29.jpg: 384x640 4 persons, 8.0ms\n",
            "Speed: 2.3ms preprocess, 8.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v21f14.jpg: 384x640 4 persons, 7.9ms\n",
            "Speed: 2.3ms preprocess, 7.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v21f2.jpg: 384x640 4 persons, 8.5ms\n",
            "Speed: 2.4ms preprocess, 8.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v21f20.jpg: 384x640 4 persons, 7.8ms\n",
            "Speed: 2.3ms preprocess, 7.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v21f12.jpg: 384x640 4 persons, 8.5ms\n",
            "Speed: 2.3ms preprocess, 8.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v21f30.jpg: 384x640 4 persons, 8.6ms\n",
            "Speed: 2.4ms preprocess, 8.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v21f3.jpg: 384x640 4 persons, 7.9ms\n",
            "Speed: 2.4ms preprocess, 7.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v21f10.jpg: 384x640 4 persons, 11.3ms\n",
            "Speed: 6.9ms preprocess, 11.3ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v21f72.jpg: 384x640 4 persons, 14.5ms\n",
            "Speed: 3.4ms preprocess, 14.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v21f87.jpg: 384x640 4 persons, 10.1ms\n",
            "Speed: 3.0ms preprocess, 10.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v21f78.jpg: 384x640 4 persons, 9.1ms\n",
            "Speed: 2.2ms preprocess, 9.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v21f60.jpg: 384x640 4 persons, 8.2ms\n",
            "Speed: 2.4ms preprocess, 8.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v21f86.jpg: 384x640 4 persons, 9.5ms\n",
            "Speed: 2.4ms preprocess, 9.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v21f82.jpg: 384x640 4 persons, 8.7ms\n",
            "Speed: 2.2ms preprocess, 8.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v21f59.jpg: 384x640 4 persons, 11.7ms\n",
            "Speed: 4.9ms preprocess, 11.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v21f58.jpg: 384x640 4 persons, 8.8ms\n",
            "Speed: 2.4ms preprocess, 8.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v21f73.jpg: 384x640 4 persons, 8.4ms\n",
            "Speed: 2.2ms preprocess, 8.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v21f52.jpg: 384x640 4 persons, 8.0ms\n",
            "Speed: 2.3ms preprocess, 8.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v21f44.jpg: 384x640 4 persons, 8.0ms\n",
            "Speed: 2.4ms preprocess, 8.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v21f83.jpg: 384x640 4 persons, 8.0ms\n",
            "Speed: 2.3ms preprocess, 8.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v21f67.jpg: 384x640 4 persons, 11.1ms\n",
            "Speed: 3.8ms preprocess, 11.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v21f65.jpg: 384x640 4 persons, 9.8ms\n",
            "Speed: 2.2ms preprocess, 9.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v21f56.jpg: 384x640 4 persons, 8.2ms\n",
            "Speed: 2.3ms preprocess, 8.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v21f70.jpg: 384x640 4 persons, 8.1ms\n",
            "Speed: 2.3ms preprocess, 8.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v21f80.jpg: 384x640 4 persons, 8.3ms\n",
            "Speed: 2.3ms preprocess, 8.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v21f53.jpg: 384x640 4 persons, 8.7ms\n",
            "Speed: 2.5ms preprocess, 8.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v21f50.jpg: 384x640 4 persons, 8.5ms\n",
            "Speed: 2.3ms preprocess, 8.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v21f75.jpg: 384x640 4 persons, 12.3ms\n",
            "Speed: 3.8ms preprocess, 12.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v21f48.jpg: 384x640 4 persons, 8.2ms\n",
            "Speed: 2.2ms preprocess, 8.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v21f63.jpg: 384x640 4 persons, 8.0ms\n",
            "Speed: 2.4ms preprocess, 8.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v21f100.jpg: 384x640 4 persons, 8.4ms\n",
            "Speed: 2.4ms preprocess, 8.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v21f125.jpg: 384x640 4 persons, 8.4ms\n",
            "Speed: 2.3ms preprocess, 8.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v21f131.jpg: 384x640 4 persons, 11.2ms\n",
            "Speed: 2.5ms preprocess, 11.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v21f111.jpg: 384x640 4 persons, 10.6ms\n",
            "Speed: 2.3ms preprocess, 10.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v21f124.jpg: 384x640 4 persons, 11.1ms\n",
            "Speed: 3.6ms preprocess, 11.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v21f103.jpg: 384x640 4 persons, 8.0ms\n",
            "Speed: 2.4ms preprocess, 8.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v21f89.jpg: 384x640 4 persons, 9.7ms\n",
            "Speed: 3.5ms preprocess, 9.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v21f104.jpg: 384x640 4 persons, 8.6ms\n",
            "Speed: 2.3ms preprocess, 8.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v21f90.jpg: 384x640 4 persons, 8.1ms\n",
            "Speed: 2.4ms preprocess, 8.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v21f98.jpg: 384x640 4 persons, 8.5ms\n",
            "Speed: 2.1ms preprocess, 8.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v21f107.jpg: 384x640 4 persons, 10.3ms\n",
            "Speed: 3.7ms preprocess, 10.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v21f118.jpg: 384x640 4 persons, 8.6ms\n",
            "Speed: 2.2ms preprocess, 8.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v21f139.jpg: 384x640 4 persons, 8.7ms\n",
            "Speed: 2.3ms preprocess, 8.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v21f115.jpg: 384x640 4 persons, 7.9ms\n",
            "Speed: 2.5ms preprocess, 7.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v21f134.jpg: 384x640 4 persons, 8.3ms\n",
            "Speed: 2.6ms preprocess, 8.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v21f109.jpg: 384x640 4 persons, 8.8ms\n",
            "Speed: 2.1ms preprocess, 8.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v21f128.jpg: 384x640 4 persons, 7.8ms\n",
            "Speed: 2.3ms preprocess, 7.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v21f120.jpg: 384x640 4 persons, 11.2ms\n",
            "Speed: 3.7ms preprocess, 11.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v21f112.jpg: 384x640 4 persons, 8.1ms\n",
            "Speed: 2.4ms preprocess, 8.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v21f151.jpg: 384x640 4 persons, 8.4ms\n",
            "Speed: 2.3ms preprocess, 8.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v20f5.jpg: 384x640 5 persons, 9.4ms\n",
            "Speed: 2.7ms preprocess, 9.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v20f29.jpg: 384x640 4 persons, 8.9ms\n",
            "Speed: 2.3ms preprocess, 8.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v20f13.jpg: 384x640 4 persons, 8.7ms\n",
            "Speed: 2.4ms preprocess, 8.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v20f12.jpg: 384x640 4 persons, 8.2ms\n",
            "Speed: 2.2ms preprocess, 8.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v20f26.jpg: 384x640 4 persons, 11.0ms\n",
            "Speed: 3.6ms preprocess, 11.0ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v20f40.jpg: 384x640 4 persons, 8.5ms\n",
            "Speed: 2.4ms preprocess, 8.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v20f28.jpg: 384x640 4 persons, 10.7ms\n",
            "Speed: 3.6ms preprocess, 10.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v20f42.jpg: 384x640 4 persons, 8.3ms\n",
            "Speed: 2.4ms preprocess, 8.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v20f23.jpg: 384x640 4 persons, 8.1ms\n",
            "Speed: 2.4ms preprocess, 8.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v20f39.jpg: 384x640 4 persons, 10.5ms\n",
            "Speed: 3.6ms preprocess, 10.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v20f21.jpg: 384x640 4 persons, 8.5ms\n",
            "Speed: 2.4ms preprocess, 8.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v20f19.jpg: 384x640 4 persons, 8.1ms\n",
            "Speed: 2.3ms preprocess, 8.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v21f149.jpg: 384x640 4 persons, 8.3ms\n",
            "Speed: 2.5ms preprocess, 8.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v20f4.jpg: 384x640 4 persons, 8.6ms\n",
            "Speed: 2.2ms preprocess, 8.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v20f14.jpg: 384x640 4 persons, 8.5ms\n",
            "Speed: 2.4ms preprocess, 8.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v21f143.jpg: 384x640 4 persons, 8.3ms\n",
            "Speed: 2.3ms preprocess, 8.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v20f27.jpg: 384x640 4 persons, 8.4ms\n",
            "Speed: 2.4ms preprocess, 8.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v20f84.jpg: 384x640 4 persons, 8.9ms\n",
            "Speed: 2.4ms preprocess, 8.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v20f53.jpg: 384x640 4 persons, 8.8ms\n",
            "Speed: 2.3ms preprocess, 8.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v20f62.jpg: 384x640 4 persons, 8.4ms\n",
            "Speed: 2.3ms preprocess, 8.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v20f87.jpg: 384x640 4 persons, 8.4ms\n",
            "Speed: 2.2ms preprocess, 8.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v20f69.jpg: 384x640 4 persons, 8.6ms\n",
            "Speed: 2.2ms preprocess, 8.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v20f64.jpg: 384x640 4 persons, 8.2ms\n",
            "Speed: 2.3ms preprocess, 8.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v20f67.jpg: 384x640 4 persons, 15.6ms\n",
            "Speed: 3.5ms preprocess, 15.6ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v20f83.jpg: 384x640 4 persons, 15.7ms\n",
            "Speed: 3.9ms preprocess, 15.7ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v20f76.jpg: 384x640 4 persons, 8.4ms\n",
            "Speed: 2.1ms preprocess, 8.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v20f81.jpg: 384x640 4 persons, 8.1ms\n",
            "Speed: 2.3ms preprocess, 8.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v20f58.jpg: 384x640 4 persons, 8.4ms\n",
            "Speed: 2.4ms preprocess, 8.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v20f61.jpg: 384x640 4 persons, 14.1ms\n",
            "Speed: 2.8ms preprocess, 14.1ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v20f88.jpg: 384x640 4 persons, 8.9ms\n",
            "Speed: 2.3ms preprocess, 8.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v20f99.jpg: 384x640 4 persons, 10.6ms\n",
            "Speed: 3.7ms preprocess, 10.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v20f98.jpg: 384x640 4 persons, 8.5ms\n",
            "Speed: 2.2ms preprocess, 8.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v20f65.jpg: 384x640 4 persons, 8.2ms\n",
            "Speed: 2.5ms preprocess, 8.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v20f49.jpg: 384x640 4 persons, 8.6ms\n",
            "Speed: 2.3ms preprocess, 8.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v20f80.jpg: 384x640 4 persons, 8.1ms\n",
            "Speed: 2.3ms preprocess, 8.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v20f66.jpg: 384x640 4 persons, 8.3ms\n",
            "Speed: 2.2ms preprocess, 8.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v35f14.jpg: 384x640 4 persons, 14.8ms\n",
            "Speed: 3.4ms preprocess, 14.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v35f1.jpg: 384x640 4 persons, 10.6ms\n",
            "Speed: 3.5ms preprocess, 10.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v35f29.jpg: 384x640 3 persons, 8.5ms\n",
            "Speed: 2.3ms preprocess, 8.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v35f18.jpg: 384x640 2 persons, 8.3ms\n",
            "Speed: 2.9ms preprocess, 8.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v35f33.jpg: 384x640 2 persons, 8.5ms\n",
            "Speed: 2.9ms preprocess, 8.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v35f41.jpg: 384x640 3 persons, 8.6ms\n",
            "Speed: 2.1ms preprocess, 8.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v35f24.jpg: 384x640 3 persons, 8.4ms\n",
            "Speed: 2.2ms preprocess, 8.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v35f46.jpg: 384x640 4 persons, 15.9ms\n",
            "Speed: 3.8ms preprocess, 15.9ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v35f15.jpg: 384x640 4 persons, 8.4ms\n",
            "Speed: 2.7ms preprocess, 8.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v35f26.jpg: 384x640 3 persons, 8.5ms\n",
            "Speed: 2.4ms preprocess, 8.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v35f3.jpg: 384x640 5 persons, 8.9ms\n",
            "Speed: 2.5ms preprocess, 8.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v35f19.jpg: 384x640 2 persons, 8.1ms\n",
            "Speed: 2.4ms preprocess, 8.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v35f37.jpg: 384x640 4 persons, 8.5ms\n",
            "Speed: 2.2ms preprocess, 8.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v35f21.jpg: 384x640 2 persons, 8.9ms\n",
            "Speed: 2.2ms preprocess, 8.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v35f11.jpg: 384x640 2 persons, 10.3ms\n",
            "Speed: 3.8ms preprocess, 10.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v35f42.jpg: 384x640 2 persons, 13.5ms\n",
            "Speed: 3.5ms preprocess, 13.5ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v35f16.jpg: 384x640 2 persons, 14.4ms\n",
            "Speed: 3.5ms preprocess, 14.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v35f17.jpg: 384x640 2 persons, 10.2ms\n",
            "Speed: 2.3ms preprocess, 10.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v35f2.jpg: 384x640 4 persons, 8.2ms\n",
            "Speed: 2.5ms preprocess, 8.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v35f106.jpg: 384x640 2 persons, 8.1ms\n",
            "Speed: 2.3ms preprocess, 8.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v35f82.jpg: 384x640 2 persons, 8.5ms\n",
            "Speed: 2.2ms preprocess, 8.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v35f93.jpg: 384x640 3 persons, 10.7ms\n",
            "Speed: 7.6ms preprocess, 10.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v35f49.jpg: 384x640 2 persons, 8.4ms\n",
            "Speed: 2.3ms preprocess, 8.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v35f110.jpg: 384x640 2 persons, 11.3ms\n",
            "Speed: 3.5ms preprocess, 11.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v35f54.jpg: 384x640 4 persons, 8.3ms\n",
            "Speed: 2.2ms preprocess, 8.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v35f89.jpg: 384x640 3 persons, 9.2ms\n",
            "Speed: 2.6ms preprocess, 9.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v35f86.jpg: 384x640 2 persons, 9.6ms\n",
            "Speed: 3.6ms preprocess, 9.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v35f51.jpg: 384x640 3 persons, 8.4ms\n",
            "Speed: 2.6ms preprocess, 8.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v35f85.jpg: 384x640 2 persons, 15.6ms\n",
            "Speed: 3.7ms preprocess, 15.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v35f114.jpg: 384x640 2 persons, 11.4ms\n",
            "Speed: 6.3ms preprocess, 11.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v35f99.jpg: 384x640 2 persons, 8.5ms\n",
            "Speed: 2.3ms preprocess, 8.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v35f64.jpg: 384x640 2 persons, 8.0ms\n",
            "Speed: 2.4ms preprocess, 8.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v35f112.jpg: 384x640 2 persons, 7.9ms\n",
            "Speed: 2.4ms preprocess, 7.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v35f77.jpg: 384x640 3 persons, 8.7ms\n",
            "Speed: 2.4ms preprocess, 8.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v35f55.jpg: 384x640 3 persons, 8.8ms\n",
            "Speed: 2.2ms preprocess, 8.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v35f117.jpg: 384x640 2 persons, 12.2ms\n",
            "Speed: 3.9ms preprocess, 12.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v35f154.jpg: 384x640 2 persons, 11.5ms\n",
            "Speed: 3.5ms preprocess, 11.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v35f166.jpg: 384x640 4 persons, 8.0ms\n",
            "Speed: 2.1ms preprocess, 8.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v35f123.jpg: 384x640 2 persons, 8.3ms\n",
            "Speed: 2.5ms preprocess, 8.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v35f119.jpg: 384x640 2 persons, 8.8ms\n",
            "Speed: 2.5ms preprocess, 8.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v35f147.jpg: 384x640 2 persons, 8.2ms\n",
            "Speed: 2.1ms preprocess, 8.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v35f118.jpg: 384x640 2 persons, 9.7ms\n",
            "Speed: 2.4ms preprocess, 9.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v35f139.jpg: 384x640 2 persons, 8.1ms\n",
            "Speed: 2.3ms preprocess, 8.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v35f155.jpg: 384x640 2 persons, 10.8ms\n",
            "Speed: 3.6ms preprocess, 10.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v35f149.jpg: 384x640 2 persons, 9.3ms\n",
            "Speed: 2.3ms preprocess, 9.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v35f134.jpg: 384x640 2 persons, 14.4ms\n",
            "Speed: 3.8ms preprocess, 14.4ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v35f127.jpg: 384x640 1 person, 14.0ms\n",
            "Speed: 3.8ms preprocess, 14.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v35f163.jpg: 384x640 2 persons, 8.3ms\n",
            "Speed: 2.1ms preprocess, 8.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v35f164.jpg: 384x640 2 persons, 8.2ms\n",
            "Speed: 2.4ms preprocess, 8.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v35f120.jpg: 384x640 2 persons, 8.9ms\n",
            "Speed: 2.4ms preprocess, 8.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v35f132.jpg: 384x640 2 persons, 17.2ms\n",
            "Speed: 4.3ms preprocess, 17.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v35f126.jpg: 384x640 2 persons, 15.9ms\n",
            "Speed: 3.5ms preprocess, 15.9ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v35f162.jpg: 384x640 3 persons, 8.3ms\n",
            "Speed: 2.6ms preprocess, 8.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v35f144.jpg: 384x640 2 persons, 8.7ms\n",
            "Speed: 2.3ms preprocess, 8.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v35f133.jpg: 384x640 2 persons, 8.7ms\n",
            "Speed: 2.3ms preprocess, 8.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v35f165.jpg: 384x640 2 persons, 8.9ms\n",
            "Speed: 2.4ms preprocess, 8.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v35f152.jpg: 384x640 2 persons, 8.6ms\n",
            "Speed: 2.1ms preprocess, 8.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v5f39.jpg: 384x640 4 persons, 14.2ms\n",
            "Speed: 8.7ms preprocess, 14.2ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v5f17.jpg: 384x640 4 persons, 16.0ms\n",
            "Speed: 3.6ms preprocess, 16.0ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v5f50.jpg: 384x640 4 persons, 8.1ms\n",
            "Speed: 2.3ms preprocess, 8.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v5f34.jpg: 384x640 4 persons, 9.4ms\n",
            "Speed: 3.2ms preprocess, 9.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v35f167.jpg: 384x640 4 persons, 8.2ms\n",
            "Speed: 2.3ms preprocess, 8.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v5f19.jpg: 384x640 4 persons, 8.8ms\n",
            "Speed: 2.4ms preprocess, 8.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v5f3.jpg: 384x640 5 persons, 8.3ms\n",
            "Speed: 2.3ms preprocess, 8.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v5f36.jpg: 384x640 4 persons, 8.4ms\n",
            "Speed: 2.4ms preprocess, 8.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v5f40.jpg: 384x640 4 persons, 7.8ms\n",
            "Speed: 2.6ms preprocess, 7.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v5f14.jpg: 384x640 4 persons, 8.3ms\n",
            "Speed: 2.2ms preprocess, 8.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v5f47.jpg: 384x640 4 persons, 8.3ms\n",
            "Speed: 2.3ms preprocess, 8.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v5f28.jpg: 384x640 4 persons, 10.1ms\n",
            "Speed: 2.5ms preprocess, 10.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v5f1.jpg: 384x640 5 persons, 11.1ms\n",
            "Speed: 3.5ms preprocess, 11.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v5f21.jpg: 384x640 4 persons, 8.2ms\n",
            "Speed: 2.2ms preprocess, 8.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v5f11.jpg: 384x640 5 persons, 8.1ms\n",
            "Speed: 2.2ms preprocess, 8.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v5f20.jpg: 384x640 4 persons, 8.4ms\n",
            "Speed: 2.3ms preprocess, 8.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v5f92.jpg: 384x640 4 persons, 8.4ms\n",
            "Speed: 2.3ms preprocess, 8.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v5f73.jpg: 384x640 4 persons, 8.6ms\n",
            "Speed: 2.4ms preprocess, 8.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v5f87.jpg: 384x640 4 persons, 8.3ms\n",
            "Speed: 2.3ms preprocess, 8.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v5f90.jpg: 384x640 4 persons, 8.9ms\n",
            "Speed: 2.5ms preprocess, 8.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v5f64.jpg: 384x640 5 persons, 18.3ms\n",
            "Speed: 6.1ms preprocess, 18.3ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v5f88.jpg: 384x640 4 persons, 8.3ms\n",
            "Speed: 2.1ms preprocess, 8.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v5f68.jpg: 384x640 4 persons, 14.7ms\n",
            "Speed: 3.7ms preprocess, 14.7ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v5f82.jpg: 384x640 4 persons, 8.5ms\n",
            "Speed: 2.5ms preprocess, 8.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v5f62.jpg: 384x640 4 persons, 8.2ms\n",
            "Speed: 2.3ms preprocess, 8.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v5f79.jpg: 384x640 4 persons, 8.1ms\n",
            "Speed: 2.2ms preprocess, 8.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v5f94.jpg: 384x640 3 persons, 7.9ms\n",
            "Speed: 2.3ms preprocess, 7.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v5f95.jpg: 384x640 3 persons, 8.5ms\n",
            "Speed: 2.3ms preprocess, 8.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v5f70.jpg: 384x640 4 persons, 8.4ms\n",
            "Speed: 2.3ms preprocess, 8.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v5f66.jpg: 384x640 4 persons, 15.5ms\n",
            "Speed: 3.6ms preprocess, 15.5ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v5f93.jpg: 384x640 4 persons, 8.3ms\n",
            "Speed: 2.3ms preprocess, 8.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v5f86.jpg: 384x640 4 persons, 7.9ms\n",
            "Speed: 2.2ms preprocess, 7.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v5f100.jpg: 384x640 3 persons, 7.9ms\n",
            "Speed: 2.3ms preprocess, 7.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v5f85.jpg: 384x640 4 persons, 8.2ms\n",
            "Speed: 2.2ms preprocess, 8.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v5f76.jpg: 384x640 4 persons, 8.0ms\n",
            "Speed: 2.3ms preprocess, 8.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v5f120.jpg: 384x640 4 persons, 11.0ms\n",
            "Speed: 3.8ms preprocess, 11.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v5f134.jpg: 384x640 4 persons, 16.8ms\n",
            "Speed: 3.6ms preprocess, 16.8ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v5f113.jpg: 384x640 4 persons, 8.4ms\n",
            "Speed: 2.4ms preprocess, 8.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v5f146.jpg: 384x640 4 persons, 9.4ms\n",
            "Speed: 2.1ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v5f121.jpg: 384x640 4 persons, 8.1ms\n",
            "Speed: 2.2ms preprocess, 8.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v5f139.jpg: 384x640 4 persons, 8.6ms\n",
            "Speed: 2.3ms preprocess, 8.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v5f111.jpg: 384x640 3 persons, 10.5ms\n",
            "Speed: 3.6ms preprocess, 10.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v5f145.jpg: 384x640 4 persons, 8.0ms\n",
            "Speed: 2.4ms preprocess, 8.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v5f106.jpg: 384x640 3 persons, 8.4ms\n",
            "Speed: 2.3ms preprocess, 8.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v5f128.jpg: 384x640 4 persons, 8.2ms\n",
            "Speed: 2.3ms preprocess, 8.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v5f138.jpg: 384x640 4 persons, 8.1ms\n",
            "Speed: 2.1ms preprocess, 8.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v5f129.jpg: 384x640 4 persons, 8.6ms\n",
            "Speed: 2.3ms preprocess, 8.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v5f107.jpg: 384x640 3 persons, 10.5ms\n",
            "Speed: 3.6ms preprocess, 10.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v5f151.jpg: 384x640 4 persons, 13.4ms\n",
            "Speed: 3.6ms preprocess, 13.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v5f153.jpg: 384x640 4 persons, 8.8ms\n",
            "Speed: 2.3ms preprocess, 8.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v5f116.jpg: 384x640 5 persons, 14.3ms\n",
            "Speed: 2.2ms preprocess, 14.3ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v5f105.jpg: 384x640 3 persons, 8.1ms\n",
            "Speed: 2.2ms preprocess, 8.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v22f48.jpg: 384x640 4 persons, 8.4ms\n",
            "Speed: 2.1ms preprocess, 8.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v22f24.jpg: 384x640 4 persons, 10.1ms\n",
            "Speed: 2.5ms preprocess, 10.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v22f25.jpg: 384x640 4 persons, 8.4ms\n",
            "Speed: 2.1ms preprocess, 8.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v22f15.jpg: 384x640 5 persons, 19.7ms\n",
            "Speed: 4.1ms preprocess, 19.7ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v22f34.jpg: 384x640 4 persons, 8.0ms\n",
            "Speed: 2.1ms preprocess, 8.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v22f49.jpg: 384x640 4 persons, 10.1ms\n",
            "Speed: 2.3ms preprocess, 10.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v22f43.jpg: 384x640 3 persons, 8.3ms\n",
            "Speed: 2.2ms preprocess, 8.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v22f10.jpg: 384x640 4 persons, 16.7ms\n",
            "Speed: 3.7ms preprocess, 16.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v22f27.jpg: 384x640 4 persons, 10.0ms\n",
            "Speed: 2.6ms preprocess, 10.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v22f44.jpg: 384x640 3 persons, 8.8ms\n",
            "Speed: 2.4ms preprocess, 8.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v22f65.jpg: 384x640 4 persons, 10.4ms\n",
            "Speed: 3.7ms preprocess, 10.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v22f18.jpg: 384x640 4 persons, 8.7ms\n",
            "Speed: 2.2ms preprocess, 8.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v22f59.jpg: 384x640 4 persons, 8.8ms\n",
            "Speed: 2.2ms preprocess, 8.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v22f14.jpg: 384x640 5 persons, 7.7ms\n",
            "Speed: 2.3ms preprocess, 7.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v22f11.jpg: 384x640 4 persons, 12.6ms\n",
            "Speed: 3.9ms preprocess, 12.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v22f111.jpg: 384x640 4 persons, 8.5ms\n",
            "Speed: 2.2ms preprocess, 8.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v22f80.jpg: 384x640 4 persons, 13.9ms\n",
            "Speed: 3.7ms preprocess, 13.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v22f90.jpg: 384x640 4 persons, 13.8ms\n",
            "Speed: 3.6ms preprocess, 13.8ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v22f102.jpg: 384x640 4 persons, 8.9ms\n",
            "Speed: 3.4ms preprocess, 8.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v22f105.jpg: 384x640 4 persons, 8.5ms\n",
            "Speed: 2.3ms preprocess, 8.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v22f87.jpg: 384x640 4 persons, 8.8ms\n",
            "Speed: 2.4ms preprocess, 8.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v22f77.jpg: 384x640 4 persons, 8.5ms\n",
            "Speed: 2.5ms preprocess, 8.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v22f71.jpg: 384x640 4 persons, 8.5ms\n",
            "Speed: 2.2ms preprocess, 8.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v22f74.jpg: 384x640 4 persons, 10.4ms\n",
            "Speed: 5.4ms preprocess, 10.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v22f75.jpg: 384x640 4 persons, 8.6ms\n",
            "Speed: 2.2ms preprocess, 8.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v22f104.jpg: 384x640 4 persons, 8.5ms\n",
            "Speed: 2.2ms preprocess, 8.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v22f81.jpg: 384x640 5 persons, 8.5ms\n",
            "Speed: 2.3ms preprocess, 8.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v22f78.jpg: 384x640 4 persons, 8.6ms\n",
            "Speed: 2.4ms preprocess, 8.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v22f70.jpg: 384x640 4 persons, 10.3ms\n",
            "Speed: 2.5ms preprocess, 10.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v22f76.jpg: 384x640 4 persons, 9.3ms\n",
            "Speed: 3.2ms preprocess, 9.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v22f83.jpg: 384x640 5 persons, 11.3ms\n",
            "Speed: 3.9ms preprocess, 11.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v22f114.jpg: 384x640 4 persons, 8.3ms\n",
            "Speed: 2.3ms preprocess, 8.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v22f98.jpg: 384x640 5 persons, 8.1ms\n",
            "Speed: 2.3ms preprocess, 8.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v4f9.jpg: 384x640 5 persons, 8.5ms\n",
            "Speed: 2.4ms preprocess, 8.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v22f128.jpg: 384x640 4 persons, 8.4ms\n",
            "Speed: 2.5ms preprocess, 8.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v4f3.jpg: 384x640 5 persons, 8.2ms\n",
            "Speed: 2.4ms preprocess, 8.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v22f121.jpg: 384x640 4 persons, 8.7ms\n",
            "Speed: 2.3ms preprocess, 8.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v4f5.jpg: 384x640 5 persons, 14.8ms\n",
            "Speed: 3.7ms preprocess, 14.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v22f131.jpg: 384x640 4 persons, 8.3ms\n",
            "Speed: 2.2ms preprocess, 8.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v22f125.jpg: 384x640 4 persons, 8.2ms\n",
            "Speed: 2.3ms preprocess, 8.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v22f123.jpg: 384x640 4 persons, 8.3ms\n",
            "Speed: 2.4ms preprocess, 8.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v4f12.jpg: 384x640 6 persons, 9.2ms\n",
            "Speed: 2.2ms preprocess, 9.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v4f16.jpg: 384x640 5 persons, 8.3ms\n",
            "Speed: 2.3ms preprocess, 8.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v4f20.jpg: 384x640 5 persons, 15.2ms\n",
            "Speed: 3.7ms preprocess, 15.2ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v4f35.jpg: 384x640 4 persons, 12.3ms\n",
            "Speed: 3.4ms preprocess, 12.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v4f63.jpg: 384x640 4 persons, 8.5ms\n",
            "Speed: 2.4ms preprocess, 8.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v4f29.jpg: 384x640 4 persons, 8.4ms\n",
            "Speed: 2.3ms preprocess, 8.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v4f34.jpg: 384x640 4 persons, 14.0ms\n",
            "Speed: 3.7ms preprocess, 14.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v4f37.jpg: 384x640 4 persons, 9.0ms\n",
            "Speed: 2.4ms preprocess, 9.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v4f24.jpg: 384x640 5 persons, 12.6ms\n",
            "Speed: 2.3ms preprocess, 12.6ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v4f53.jpg: 384x640 6 persons, 11.1ms\n",
            "Speed: 3.7ms preprocess, 11.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v4f46.jpg: 384x640 5 persons, 8.7ms\n",
            "Speed: 2.5ms preprocess, 8.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v4f60.jpg: 384x640 4 persons, 8.5ms\n",
            "Speed: 2.2ms preprocess, 8.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v4f65.jpg: 384x640 4 persons, 8.2ms\n",
            "Speed: 2.5ms preprocess, 8.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v4f62.jpg: 384x640 5 persons, 8.3ms\n",
            "Speed: 2.3ms preprocess, 8.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v4f52.jpg: 384x640 5 persons, 8.5ms\n",
            "Speed: 2.3ms preprocess, 8.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v4f66.jpg: 384x640 5 persons, 8.3ms\n",
            "Speed: 2.4ms preprocess, 8.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v4f40.jpg: 384x640 4 persons, 12.4ms\n",
            "Speed: 3.8ms preprocess, 12.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v4f48.jpg: 384x640 6 persons, 9.2ms\n",
            "Speed: 2.7ms preprocess, 9.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v4f57.jpg: 384x640 5 persons, 8.3ms\n",
            "Speed: 2.2ms preprocess, 8.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v4f25.jpg: 384x640 5 persons, 8.2ms\n",
            "Speed: 2.2ms preprocess, 8.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v4f49.jpg: 384x640 6 persons, 8.0ms\n",
            "Speed: 2.4ms preprocess, 8.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v4f101.jpg: 384x640 6 persons, 18.1ms\n",
            "Speed: 3.6ms preprocess, 18.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v4f99.jpg: 384x640 6 persons, 8.0ms\n",
            "Speed: 2.2ms preprocess, 8.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v59f1.jpg: 384x640 3 persons, 11.2ms\n",
            "Speed: 3.7ms preprocess, 11.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v4f93.jpg: 384x640 5 persons, 8.3ms\n",
            "Speed: 2.5ms preprocess, 8.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v4f100.jpg: 384x640 6 persons, 9.0ms\n",
            "Speed: 2.3ms preprocess, 9.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v4f68.jpg: 384x640 5 persons, 9.2ms\n",
            "Speed: 3.4ms preprocess, 9.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v4f92.jpg: 384x640 6 persons, 10.4ms\n",
            "Speed: 3.3ms preprocess, 10.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v4f72.jpg: 384x640 5 persons, 8.1ms\n",
            "Speed: 2.3ms preprocess, 8.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v4f104.jpg: 384x640 5 persons, 8.4ms\n",
            "Speed: 2.3ms preprocess, 8.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v4f73.jpg: 384x640 5 persons, 10.3ms\n",
            "Speed: 3.9ms preprocess, 10.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v4f83.jpg: 384x640 5 persons, 8.2ms\n",
            "Speed: 2.4ms preprocess, 8.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v4f90.jpg: 384x640 5 persons, 8.0ms\n",
            "Speed: 2.3ms preprocess, 8.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v4f94.jpg: 384x640 5 persons, 9.0ms\n",
            "Speed: 2.5ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v4f82.jpg: 384x640 6 persons, 9.3ms\n",
            "Speed: 2.6ms preprocess, 9.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v59f0.jpg: 384x640 3 persons, 8.6ms\n",
            "Speed: 2.3ms preprocess, 8.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v4f76.jpg: 384x640 6 persons, 10.3ms\n",
            "Speed: 3.5ms preprocess, 10.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v4f103.jpg: 384x640 5 persons, 8.4ms\n",
            "Speed: 2.2ms preprocess, 8.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v4f84.jpg: 384x640 5 persons, 8.6ms\n",
            "Speed: 2.4ms preprocess, 8.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v4f102.jpg: 384x640 5 persons, 8.4ms\n",
            "Speed: 2.4ms preprocess, 8.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v59f4.jpg: 384x640 3 persons, 8.4ms\n",
            "Speed: 2.4ms preprocess, 8.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v4f70.jpg: 384x640 4 persons, 9.2ms\n",
            "Speed: 3.2ms preprocess, 9.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v59f27.jpg: 384x640 3 persons, 8.1ms\n",
            "Speed: 2.2ms preprocess, 8.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v59f24.jpg: 384x640 3 persons, 11.4ms\n",
            "Speed: 3.7ms preprocess, 11.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v59f54.jpg: 384x640 3 persons, 9.1ms\n",
            "Speed: 2.5ms preprocess, 9.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v59f19.jpg: 384x640 3 persons, 8.3ms\n",
            "Speed: 2.1ms preprocess, 8.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v59f37.jpg: 384x640 3 persons, 8.2ms\n",
            "Speed: 2.4ms preprocess, 8.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v59f28.jpg: 384x640 3 persons, 8.2ms\n",
            "Speed: 2.2ms preprocess, 8.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v59f11.jpg: 384x640 3 persons, 8.6ms\n",
            "Speed: 2.3ms preprocess, 8.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v59f34.jpg: 384x640 3 persons, 11.9ms\n",
            "Speed: 3.9ms preprocess, 11.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v59f18.jpg: 384x640 3 persons, 15.2ms\n",
            "Speed: 3.7ms preprocess, 15.2ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v59f51.jpg: 384x640 3 persons, 8.6ms\n",
            "Speed: 2.2ms preprocess, 8.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v59f41.jpg: 384x640 3 persons, 8.2ms\n",
            "Speed: 2.4ms preprocess, 8.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v59f21.jpg: 384x640 3 persons, 8.1ms\n",
            "Speed: 2.3ms preprocess, 8.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v59f44.jpg: 384x640 3 persons, 8.8ms\n",
            "Speed: 2.6ms preprocess, 8.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v59f23.jpg: 384x640 3 persons, 8.1ms\n",
            "Speed: 2.2ms preprocess, 8.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v59f46.jpg: 384x640 3 persons, 11.9ms\n",
            "Speed: 2.9ms preprocess, 11.9ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v59f36.jpg: 384x640 3 persons, 15.2ms\n",
            "Speed: 3.5ms preprocess, 15.2ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v59f25.jpg: 384x640 3 persons, 8.2ms\n",
            "Speed: 2.2ms preprocess, 8.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v59f13.jpg: 384x640 3 persons, 8.3ms\n",
            "Speed: 2.3ms preprocess, 8.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v59f22.jpg: 384x640 3 persons, 8.5ms\n",
            "Speed: 2.4ms preprocess, 8.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v59f10.jpg: 384x640 3 persons, 8.3ms\n",
            "Speed: 2.2ms preprocess, 8.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v59f17.jpg: 384x640 3 persons, 8.2ms\n",
            "Speed: 2.3ms preprocess, 8.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v59f92.jpg: 384x640 3 persons, 10.8ms\n",
            "Speed: 3.7ms preprocess, 10.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v59f79.jpg: 384x640 3 persons, 8.2ms\n",
            "Speed: 2.2ms preprocess, 8.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v59f77.jpg: 384x640 3 persons, 8.6ms\n",
            "Speed: 2.3ms preprocess, 8.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v59f105.jpg: 384x640 3 persons, 8.2ms\n",
            "Speed: 2.2ms preprocess, 8.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v59f106.jpg: 384x640 3 persons, 8.1ms\n",
            "Speed: 2.2ms preprocess, 8.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v59f112.jpg: 384x640 3 persons, 8.3ms\n",
            "Speed: 2.4ms preprocess, 8.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v59f75.jpg: 384x640 3 persons, 10.0ms\n",
            "Speed: 3.6ms preprocess, 10.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v59f108.jpg: 384x640 3 persons, 12.6ms\n",
            "Speed: 3.9ms preprocess, 12.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v59f60.jpg: 384x640 3 persons, 8.4ms\n",
            "Speed: 2.3ms preprocess, 8.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v59f101.jpg: 384x640 3 persons, 8.6ms\n",
            "Speed: 2.3ms preprocess, 8.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v59f103.jpg: 384x640 3 persons, 8.3ms\n",
            "Speed: 2.2ms preprocess, 8.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v59f104.jpg: 384x640 3 persons, 8.9ms\n",
            "Speed: 2.3ms preprocess, 8.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v59f86.jpg: 384x640 3 persons, 8.0ms\n",
            "Speed: 2.5ms preprocess, 8.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v59f113.jpg: 384x640 3 persons, 10.7ms\n",
            "Speed: 5.5ms preprocess, 10.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v59f91.jpg: 384x640 3 persons, 15.0ms\n",
            "Speed: 3.5ms preprocess, 15.0ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v59f78.jpg: 384x640 3 persons, 9.3ms\n",
            "Speed: 2.3ms preprocess, 9.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v59f114.jpg: 384x640 3 persons, 8.3ms\n",
            "Speed: 2.4ms preprocess, 8.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v59f80.jpg: 384x640 3 persons, 9.2ms\n",
            "Speed: 2.4ms preprocess, 9.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v59f97.jpg: 384x640 3 persons, 8.3ms\n",
            "Speed: 2.2ms preprocess, 8.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v59f94.jpg: 384x640 3 persons, 8.6ms\n",
            "Speed: 2.3ms preprocess, 8.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v59f130.jpg: 384x640 3 persons, 17.2ms\n",
            "Speed: 3.5ms preprocess, 17.2ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v59f140.jpg: 384x640 3 persons, 11.3ms\n",
            "Speed: 3.7ms preprocess, 11.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v59f120.jpg: 384x640 3 persons, 8.5ms\n",
            "Speed: 2.1ms preprocess, 8.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v59f148.jpg: 384x640 3 persons, 8.1ms\n",
            "Speed: 2.2ms preprocess, 8.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v59f136.jpg: 384x640 3 persons, 8.2ms\n",
            "Speed: 2.1ms preprocess, 8.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v59f137.jpg: 384x640 3 persons, 8.6ms\n",
            "Speed: 2.2ms preprocess, 8.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v59f146.jpg: 384x640 3 persons, 8.1ms\n",
            "Speed: 2.1ms preprocess, 8.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v59f144.jpg: 384x640 3 persons, 8.4ms\n",
            "Speed: 2.1ms preprocess, 8.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v59f147.jpg: 384x640 3 persons, 15.9ms\n",
            "Speed: 3.6ms preprocess, 15.9ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v59f118.jpg: 384x640 3 persons, 8.4ms\n",
            "Speed: 2.4ms preprocess, 8.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v59f123.jpg: 384x640 3 persons, 13.1ms\n",
            "Speed: 2.2ms preprocess, 13.1ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v59f152.jpg: 384x640 3 persons, 8.6ms\n",
            "Speed: 2.3ms preprocess, 8.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v59f131.jpg: 384x640 3 persons, 8.2ms\n",
            "Speed: 2.2ms preprocess, 8.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v59f121.jpg: 384x640 3 persons, 8.4ms\n",
            "Speed: 2.2ms preprocess, 8.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v59f155.jpg: 384x640 3 persons, 8.6ms\n",
            "Speed: 2.3ms preprocess, 8.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v59f157.jpg: 384x640 3 persons, 10.6ms\n",
            "Speed: 3.8ms preprocess, 10.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v59f119.jpg: 384x640 3 persons, 8.6ms\n",
            "Speed: 2.2ms preprocess, 8.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v59f138.jpg: 384x640 3 persons, 9.7ms\n",
            "Speed: 2.3ms preprocess, 9.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v59f180.jpg: 384x640 4 persons, 8.9ms\n",
            "Speed: 2.2ms preprocess, 8.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v59f182.jpg: 384x640 3 persons, 8.4ms\n",
            "Speed: 2.2ms preprocess, 8.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v59f163.jpg: 384x640 3 persons, 8.2ms\n",
            "Speed: 2.2ms preprocess, 8.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v59f206.jpg: 384x640 3 persons, 8.4ms\n",
            "Speed: 2.2ms preprocess, 8.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v59f193.jpg: 384x640 3 persons, 12.5ms\n",
            "Speed: 4.1ms preprocess, 12.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v59f211.jpg: 384x640 3 persons, 13.3ms\n",
            "Speed: 2.4ms preprocess, 13.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v59f190.jpg: 384x640 3 persons, 8.0ms\n",
            "Speed: 2.2ms preprocess, 8.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v59f161.jpg: 384x640 3 persons, 8.3ms\n",
            "Speed: 2.2ms preprocess, 8.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v59f203.jpg: 384x640 3 persons, 8.2ms\n",
            "Speed: 2.2ms preprocess, 8.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v59f216.jpg: 384x640 3 persons, 8.3ms\n",
            "Speed: 2.4ms preprocess, 8.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v59f174.jpg: 384x640 3 persons, 8.2ms\n",
            "Speed: 3.1ms preprocess, 8.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v59f213.jpg: 384x640 3 persons, 10.9ms\n",
            "Speed: 3.7ms preprocess, 10.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v59f159.jpg: 384x640 3 persons, 8.5ms\n",
            "Speed: 2.3ms preprocess, 8.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v59f191.jpg: 384x640 3 persons, 8.5ms\n",
            "Speed: 2.3ms preprocess, 8.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v59f183.jpg: 384x640 3 persons, 8.1ms\n",
            "Speed: 2.2ms preprocess, 8.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v47f19.jpg: 384x640 3 persons, 8.2ms\n",
            "Speed: 2.2ms preprocess, 8.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v47f22.jpg: 384x640 3 persons, 8.2ms\n",
            "Speed: 2.6ms preprocess, 8.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v59f234.jpg: 384x640 3 persons, 8.9ms\n",
            "Speed: 2.2ms preprocess, 8.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v47f14.jpg: 384x640 3 persons, 10.9ms\n",
            "Speed: 4.5ms preprocess, 10.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v47f11.jpg: 384x640 3 persons, 8.8ms\n",
            "Speed: 2.7ms preprocess, 8.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v47f16.jpg: 384x640 3 persons, 8.4ms\n",
            "Speed: 2.3ms preprocess, 8.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v59f220.jpg: 384x640 3 persons, 7.9ms\n",
            "Speed: 2.3ms preprocess, 7.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v47f12.jpg: 384x640 3 persons, 10.0ms\n",
            "Speed: 2.3ms preprocess, 10.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v47f9.jpg: 384x640 3 persons, 8.4ms\n",
            "Speed: 2.2ms preprocess, 8.4ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v47f4.jpg: 384x640 3 persons, 8.2ms\n",
            "Speed: 2.4ms preprocess, 8.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v59f223.jpg: 384x640 3 persons, 10.2ms\n",
            "Speed: 3.7ms preprocess, 10.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v59f217.jpg: 384x640 3 persons, 11.0ms\n",
            "Speed: 3.4ms preprocess, 11.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v47f13.jpg: 384x640 3 persons, 15.1ms\n",
            "Speed: 4.1ms preprocess, 15.1ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v59f226.jpg: 384x640 3 persons, 8.8ms\n",
            "Speed: 2.4ms preprocess, 8.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v59f229.jpg: 384x640 3 persons, 8.7ms\n",
            "Speed: 2.3ms preprocess, 8.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v59f221.jpg: 384x640 3 persons, 9.7ms\n",
            "Speed: 2.2ms preprocess, 9.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v47f3.jpg: 384x640 3 persons, 17.0ms\n",
            "Speed: 3.3ms preprocess, 17.0ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v59f227.jpg: 384x640 3 persons, 10.7ms\n",
            "Speed: 3.9ms preprocess, 10.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v47f1.jpg: 384x640 3 persons, 8.1ms\n",
            "Speed: 2.3ms preprocess, 8.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v47f15.jpg: 384x640 3 persons, 8.4ms\n",
            "Speed: 2.2ms preprocess, 8.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v47f10.jpg: 384x640 3 persons, 8.8ms\n",
            "Speed: 2.5ms preprocess, 8.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v47f63.jpg: 384x640 3 persons, 8.1ms\n",
            "Speed: 2.5ms preprocess, 8.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v47f72.jpg: 384x640 2 persons, 8.4ms\n",
            "Speed: 2.4ms preprocess, 8.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v47f48.jpg: 384x640 3 persons, 10.7ms\n",
            "Speed: 3.7ms preprocess, 10.7ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v47f70.jpg: 384x640 2 persons, 10.9ms\n",
            "Speed: 3.8ms preprocess, 10.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v47f38.jpg: 384x640 3 persons, 8.4ms\n",
            "Speed: 2.2ms preprocess, 8.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v47f43.jpg: 384x640 3 persons, 9.4ms\n",
            "Speed: 2.5ms preprocess, 9.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v47f56.jpg: 384x640 3 persons, 8.4ms\n",
            "Speed: 2.1ms preprocess, 8.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v47f69.jpg: 384x640 2 persons, 8.5ms\n",
            "Speed: 2.3ms preprocess, 8.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v47f57.jpg: 384x640 2 persons, 14.3ms\n",
            "Speed: 3.9ms preprocess, 14.3ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v47f37.jpg: 384x640 3 persons, 10.3ms\n",
            "Speed: 3.7ms preprocess, 10.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v47f50.jpg: 384x640 3 persons, 8.0ms\n",
            "Speed: 2.2ms preprocess, 8.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v47f25.jpg: 384x640 3 persons, 8.3ms\n",
            "Speed: 2.3ms preprocess, 8.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v47f39.jpg: 384x640 3 persons, 8.5ms\n",
            "Speed: 2.3ms preprocess, 8.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v47f76.jpg: 384x640 3 persons, 8.5ms\n",
            "Speed: 2.3ms preprocess, 8.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v47f71.jpg: 384x640 3 persons, 8.1ms\n",
            "Speed: 2.2ms preprocess, 8.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v47f26.jpg: 384x640 3 persons, 8.6ms\n",
            "Speed: 2.3ms preprocess, 8.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v47f102.jpg: 384x640 5 persons, 16.2ms\n",
            "Speed: 3.4ms preprocess, 16.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v47f95.jpg: 384x640 3 persons, 8.5ms\n",
            "Speed: 2.5ms preprocess, 8.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v47f109.jpg: 384x640 5 persons, 8.1ms\n",
            "Speed: 2.3ms preprocess, 8.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v47f116.jpg: 384x640 3 persons, 8.6ms\n",
            "Speed: 2.4ms preprocess, 8.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v47f111.jpg: 384x640 3 persons, 8.4ms\n",
            "Speed: 2.2ms preprocess, 8.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v47f101.jpg: 384x640 5 persons, 8.1ms\n",
            "Speed: 2.1ms preprocess, 8.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v47f114.jpg: 384x640 3 persons, 9.7ms\n",
            "Speed: 2.3ms preprocess, 9.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v47f86.jpg: 384x640 4 persons, 10.5ms\n",
            "Speed: 3.6ms preprocess, 10.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v47f108.jpg: 384x640 5 persons, 8.3ms\n",
            "Speed: 2.2ms preprocess, 8.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v47f103.jpg: 384x640 5 persons, 8.2ms\n",
            "Speed: 2.3ms preprocess, 8.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v47f87.jpg: 384x640 4 persons, 8.5ms\n",
            "Speed: 2.2ms preprocess, 8.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v47f129.jpg: 384x640 3 persons, 8.7ms\n",
            "Speed: 2.3ms preprocess, 8.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v47f84.jpg: 384x640 4 persons, 8.2ms\n",
            "Speed: 2.9ms preprocess, 8.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v47f127.jpg: 384x640 3 persons, 8.0ms\n",
            "Speed: 2.4ms preprocess, 8.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v47f115.jpg: 384x640 3 persons, 10.7ms\n",
            "Speed: 3.6ms preprocess, 10.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v47f88.jpg: 384x640 4 persons, 8.2ms\n",
            "Speed: 2.2ms preprocess, 8.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v47f117.jpg: 384x640 3 persons, 8.0ms\n",
            "Speed: 2.1ms preprocess, 8.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v47f161.jpg: 384x640 3 persons, 8.7ms\n",
            "Speed: 2.4ms preprocess, 8.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v47f130.jpg: 384x640 3 persons, 13.5ms\n",
            "Speed: 3.2ms preprocess, 13.5ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v47f153.jpg: 384x640 3 persons, 11.5ms\n",
            "Speed: 2.2ms preprocess, 11.5ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v50f0.jpg: 384x640 3 persons, 7.9ms\n",
            "Speed: 2.2ms preprocess, 7.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v50f2.jpg: 384x640 3 persons, 12.5ms\n",
            "Speed: 3.8ms preprocess, 12.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v47f149.jpg: 384x640 3 persons, 8.5ms\n",
            "Speed: 2.3ms preprocess, 8.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v47f132.jpg: 384x640 3 persons, 8.0ms\n",
            "Speed: 2.2ms preprocess, 8.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v47f154.jpg: 384x640 3 persons, 8.1ms\n",
            "Speed: 2.2ms preprocess, 8.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v47f140.jpg: 384x640 3 persons, 12.3ms\n",
            "Speed: 2.3ms preprocess, 12.3ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v47f138.jpg: 384x640 3 persons, 8.9ms\n",
            "Speed: 2.3ms preprocess, 8.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v50f1.jpg: 384x640 3 persons, 8.2ms\n",
            "Speed: 2.4ms preprocess, 8.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v50f7.jpg: 384x640 3 persons, 11.6ms\n",
            "Speed: 3.6ms preprocess, 11.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v50f5.jpg: 384x640 3 persons, 7.9ms\n",
            "Speed: 2.4ms preprocess, 7.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v47f160.jpg: 384x640 3 persons, 8.3ms\n",
            "Speed: 2.2ms preprocess, 8.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v47f157.jpg: 384x640 3 persons, 8.0ms\n",
            "Speed: 2.3ms preprocess, 8.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v47f136.jpg: 384x640 3 persons, 8.3ms\n",
            "Speed: 2.2ms preprocess, 8.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v50f52.jpg: 384x640 3 persons, 8.5ms\n",
            "Speed: 2.3ms preprocess, 8.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v50f41.jpg: 384x640 3 persons, 8.5ms\n",
            "Speed: 2.2ms preprocess, 8.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v50f21.jpg: 384x640 3 persons, 10.4ms\n",
            "Speed: 3.7ms preprocess, 10.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v50f53.jpg: 384x640 3 persons, 7.9ms\n",
            "Speed: 2.1ms preprocess, 7.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v50f63.jpg: 384x640 3 persons, 11.9ms\n",
            "Speed: 3.5ms preprocess, 11.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v50f42.jpg: 384x640 3 persons, 8.1ms\n",
            "Speed: 2.4ms preprocess, 8.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v50f38.jpg: 384x640 3 persons, 9.0ms\n",
            "Speed: 2.5ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v50f29.jpg: 384x640 3 persons, 9.7ms\n",
            "Speed: 3.5ms preprocess, 9.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v50f50.jpg: 384x640 3 persons, 11.3ms\n",
            "Speed: 3.6ms preprocess, 11.3ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v50f15.jpg: 384x640 3 persons, 8.0ms\n",
            "Speed: 2.3ms preprocess, 8.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v50f30.jpg: 384x640 4 persons, 9.9ms\n",
            "Speed: 2.6ms preprocess, 9.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v50f33.jpg: 384x640 4 persons, 9.7ms\n",
            "Speed: 2.3ms preprocess, 9.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v50f55.jpg: 384x640 3 persons, 8.7ms\n",
            "Speed: 2.3ms preprocess, 8.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v50f28.jpg: 384x640 3 persons, 8.4ms\n",
            "Speed: 3.2ms preprocess, 8.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v50f48.jpg: 384x640 3 persons, 8.4ms\n",
            "Speed: 2.3ms preprocess, 8.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v50f43.jpg: 384x640 3 persons, 13.3ms\n",
            "Speed: 3.7ms preprocess, 13.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v50f23.jpg: 384x640 3 persons, 8.4ms\n",
            "Speed: 2.3ms preprocess, 8.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v50f13.jpg: 384x640 3 persons, 8.2ms\n",
            "Speed: 2.3ms preprocess, 8.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v50f65.jpg: 384x640 3 persons, 9.3ms\n",
            "Speed: 2.3ms preprocess, 9.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v50f31.jpg: 384x640 3 persons, 7.8ms\n",
            "Speed: 2.3ms preprocess, 7.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v50f76.jpg: 384x640 3 persons, 9.4ms\n",
            "Speed: 2.3ms preprocess, 9.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v50f122.jpg: 384x640 3 persons, 8.1ms\n",
            "Speed: 2.3ms preprocess, 8.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v50f72.jpg: 384x640 3 persons, 10.2ms\n",
            "Speed: 3.5ms preprocess, 10.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v50f90.jpg: 384x640 3 persons, 8.1ms\n",
            "Speed: 2.1ms preprocess, 8.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v50f97.jpg: 384x640 3 persons, 9.0ms\n",
            "Speed: 2.3ms preprocess, 9.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v50f96.jpg: 384x640 3 persons, 8.8ms\n",
            "Speed: 2.3ms preprocess, 8.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v50f112.jpg: 384x640 3 persons, 8.5ms\n",
            "Speed: 2.3ms preprocess, 8.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v50f68.jpg: 384x640 3 persons, 10.4ms\n",
            "Speed: 3.8ms preprocess, 10.4ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v50f78.jpg: 384x640 3 persons, 8.2ms\n",
            "Speed: 2.3ms preprocess, 8.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v50f129.jpg: 384x640 3 persons, 8.1ms\n",
            "Speed: 2.2ms preprocess, 8.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v50f110.jpg: 384x640 3 persons, 8.4ms\n",
            "Speed: 2.3ms preprocess, 8.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v50f82.jpg: 384x640 3 persons, 9.0ms\n",
            "Speed: 2.3ms preprocess, 9.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v50f126.jpg: 384x640 3 persons, 8.7ms\n",
            "Speed: 2.5ms preprocess, 8.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v50f101.jpg: 384x640 3 persons, 12.5ms\n",
            "Speed: 3.5ms preprocess, 12.5ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v50f77.jpg: 384x640 3 persons, 8.0ms\n",
            "Speed: 2.3ms preprocess, 8.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v50f79.jpg: 384x640 3 persons, 8.7ms\n",
            "Speed: 2.2ms preprocess, 8.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v50f118.jpg: 384x640 3 persons, 8.1ms\n",
            "Speed: 2.2ms preprocess, 8.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v50f71.jpg: 384x640 3 persons, 8.2ms\n",
            "Speed: 2.1ms preprocess, 8.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v50f100.jpg: 384x640 3 persons, 8.2ms\n",
            "Speed: 2.2ms preprocess, 8.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v50f109.jpg: 384x640 3 persons, 10.2ms\n",
            "Speed: 3.4ms preprocess, 10.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v50f119.jpg: 384x640 3 persons, 8.2ms\n",
            "Speed: 2.4ms preprocess, 8.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v50f120.jpg: 384x640 3 persons, 7.9ms\n",
            "Speed: 2.2ms preprocess, 7.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v50f175.jpg: 384x640 3 persons, 8.3ms\n",
            "Speed: 2.3ms preprocess, 8.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v50f139.jpg: 384x640 3 persons, 8.1ms\n",
            "Speed: 2.2ms preprocess, 8.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v50f155.jpg: 384x640 3 persons, 7.9ms\n",
            "Speed: 2.3ms preprocess, 7.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v50f156.jpg: 384x640 3 persons, 7.9ms\n",
            "Speed: 2.2ms preprocess, 7.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v50f153.jpg: 384x640 3 persons, 15.0ms\n",
            "Speed: 3.4ms preprocess, 15.0ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v50f141.jpg: 384x640 3 persons, 11.0ms\n",
            "Speed: 2.2ms preprocess, 11.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v50f163.jpg: 384x640 3 persons, 8.2ms\n",
            "Speed: 2.2ms preprocess, 8.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v50f151.jpg: 384x640 3 persons, 8.2ms\n",
            "Speed: 2.1ms preprocess, 8.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v50f150.jpg: 384x640 3 persons, 8.5ms\n",
            "Speed: 2.3ms preprocess, 8.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v50f177.jpg: 384x640 3 persons, 18.1ms\n",
            "Speed: 3.9ms preprocess, 18.1ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v50f159.jpg: 384x640 3 persons, 21.1ms\n",
            "Speed: 3.9ms preprocess, 21.1ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v50f130.jpg: 384x640 3 persons, 8.1ms\n",
            "Speed: 2.2ms preprocess, 8.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v50f152.jpg: 384x640 3 persons, 8.2ms\n",
            "Speed: 2.2ms preprocess, 8.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v50f176.jpg: 384x640 3 persons, 8.3ms\n",
            "Speed: 2.2ms preprocess, 8.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v50f164.jpg: 384x640 3 persons, 8.0ms\n",
            "Speed: 2.2ms preprocess, 8.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v50f143.jpg: 384x640 3 persons, 8.6ms\n",
            "Speed: 2.4ms preprocess, 8.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v50f136.jpg: 384x640 3 persons, 17.3ms\n",
            "Speed: 3.5ms preprocess, 17.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v50f157.jpg: 384x640 3 persons, 14.8ms\n",
            "Speed: 7.7ms preprocess, 14.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v50f148.jpg: 384x640 3 persons, 10.6ms\n",
            "Speed: 2.3ms preprocess, 10.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v50f171.jpg: 384x640 3 persons, 8.1ms\n",
            "Speed: 2.2ms preprocess, 8.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v50f138.jpg: 384x640 3 persons, 9.2ms\n",
            "Speed: 2.5ms preprocess, 9.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v38f36.jpg: 384x640 3 persons, 8.3ms\n",
            "Speed: 2.1ms preprocess, 8.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v38f33.jpg: 384x640 3 persons, 11.0ms\n",
            "Speed: 2.4ms preprocess, 11.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v50f180.jpg: 384x640 4 persons, 10.6ms\n",
            "Speed: 3.5ms preprocess, 10.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v38f1.jpg: 384x640 3 persons, 15.6ms\n",
            "Speed: 3.7ms preprocess, 15.6ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v50f181.jpg: 384x640 4 persons, 8.9ms\n",
            "Speed: 2.3ms preprocess, 8.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v38f15.jpg: 384x640 3 persons, 8.8ms\n",
            "Speed: 2.4ms preprocess, 8.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v38f19.jpg: 384x640 3 persons, 8.7ms\n",
            "Speed: 2.2ms preprocess, 8.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v38f4.jpg: 384x640 3 persons, 8.0ms\n",
            "Speed: 2.2ms preprocess, 8.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v38f25.jpg: 384x640 3 persons, 8.4ms\n",
            "Speed: 2.2ms preprocess, 8.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v38f2.jpg: 384x640 3 persons, 11.0ms\n",
            "Speed: 3.6ms preprocess, 11.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v38f37.jpg: 384x640 3 persons, 8.8ms\n",
            "Speed: 2.5ms preprocess, 8.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v38f31.jpg: 384x640 3 persons, 8.5ms\n",
            "Speed: 2.3ms preprocess, 8.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v38f3.jpg: 384x640 3 persons, 8.0ms\n",
            "Speed: 2.2ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v38f17.jpg: 384x640 3 persons, 8.3ms\n",
            "Speed: 2.1ms preprocess, 8.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v38f38.jpg: 384x640 3 persons, 14.2ms\n",
            "Speed: 3.0ms preprocess, 14.2ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v50f189.jpg: 384x640 4 persons, 8.1ms\n",
            "Speed: 2.2ms preprocess, 8.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v38f30.jpg: 384x640 3 persons, 16.6ms\n",
            "Speed: 4.2ms preprocess, 16.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v38f26.jpg: 384x640 3 persons, 8.2ms\n",
            "Speed: 2.4ms preprocess, 8.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v50f187.jpg: 384x640 4 persons, 8.2ms\n",
            "Speed: 2.3ms preprocess, 8.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v38f94.jpg: 384x640 3 persons, 8.7ms\n",
            "Speed: 2.2ms preprocess, 8.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v38f63.jpg: 384x640 3 persons, 9.0ms\n",
            "Speed: 2.3ms preprocess, 9.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v38f59.jpg: 384x640 3 persons, 8.8ms\n",
            "Speed: 2.4ms preprocess, 8.8ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v38f43.jpg: 384x640 3 persons, 10.7ms\n",
            "Speed: 3.5ms preprocess, 10.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v38f52.jpg: 384x640 3 persons, 8.5ms\n",
            "Speed: 2.5ms preprocess, 8.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v38f85.jpg: 384x640 3 persons, 9.0ms\n",
            "Speed: 2.3ms preprocess, 9.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v38f93.jpg: 384x640 4 persons, 8.0ms\n",
            "Speed: 2.4ms preprocess, 8.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v38f91.jpg: 384x640 3 persons, 7.9ms\n",
            "Speed: 2.3ms preprocess, 7.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v38f60.jpg: 384x640 3 persons, 8.6ms\n",
            "Speed: 2.3ms preprocess, 8.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v38f47.jpg: 384x640 3 persons, 14.2ms\n",
            "Speed: 3.4ms preprocess, 14.2ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v38f69.jpg: 384x640 4 persons, 12.9ms\n",
            "Speed: 3.7ms preprocess, 12.9ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v38f79.jpg: 384x640 3 persons, 16.7ms\n",
            "Speed: 6.8ms preprocess, 16.7ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v38f65.jpg: 384x640 3 persons, 10.5ms\n",
            "Speed: 3.4ms preprocess, 10.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v38f68.jpg: 384x640 4 persons, 8.4ms\n",
            "Speed: 2.3ms preprocess, 8.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v38f53.jpg: 384x640 3 persons, 8.2ms\n",
            "Speed: 2.4ms preprocess, 8.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v38f127.jpg: 384x640 2 persons, 8.3ms\n",
            "Speed: 2.1ms preprocess, 8.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v38f150.jpg: 384x640 4 persons, 8.3ms\n",
            "Speed: 2.7ms preprocess, 8.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v38f128.jpg: 384x640 2 persons, 10.7ms\n",
            "Speed: 3.6ms preprocess, 10.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v38f125.jpg: 384x640 2 persons, 15.6ms\n",
            "Speed: 3.5ms preprocess, 15.6ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v38f105.jpg: 384x640 4 persons, 8.7ms\n",
            "Speed: 2.1ms preprocess, 8.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v38f148.jpg: 384x640 3 persons, 8.2ms\n",
            "Speed: 2.3ms preprocess, 8.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v38f121.jpg: 384x640 4 persons, 8.0ms\n",
            "Speed: 2.2ms preprocess, 8.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v38f136.jpg: 384x640 2 persons, 8.6ms\n",
            "Speed: 2.4ms preprocess, 8.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v38f106.jpg: 384x640 4 persons, 8.9ms\n",
            "Speed: 4.2ms preprocess, 8.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v38f144.jpg: 384x640 2 persons, 13.3ms\n",
            "Speed: 4.2ms preprocess, 13.3ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v38f108.jpg: 384x640 4 persons, 16.4ms\n",
            "Speed: 3.4ms preprocess, 16.4ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v38f110.jpg: 384x640 4 persons, 8.5ms\n",
            "Speed: 2.4ms preprocess, 8.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v38f149.jpg: 384x640 3 persons, 9.2ms\n",
            "Speed: 2.3ms preprocess, 9.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v38f141.jpg: 384x640 2 persons, 8.0ms\n",
            "Speed: 2.5ms preprocess, 8.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v38f102.jpg: 384x640 4 persons, 8.0ms\n",
            "Speed: 2.1ms preprocess, 8.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v38f146.jpg: 384x640 3 persons, 7.8ms\n",
            "Speed: 2.5ms preprocess, 7.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v38f99.jpg: 384x640 4 persons, 8.2ms\n",
            "Speed: 2.4ms preprocess, 8.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v38f145.jpg: 384x640 3 persons, 15.0ms\n",
            "Speed: 3.6ms preprocess, 15.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v38f193.jpg: 384x640 3 persons, 8.4ms\n",
            "Speed: 2.1ms preprocess, 8.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v38f186.jpg: 384x640 3 persons, 8.6ms\n",
            "Speed: 2.2ms preprocess, 8.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v38f155.jpg: 384x640 3 persons, 8.1ms\n",
            "Speed: 2.2ms preprocess, 8.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v38f173.jpg: 384x640 2 persons, 8.0ms\n",
            "Speed: 2.4ms preprocess, 8.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v38f190.jpg: 384x640 3 persons, 8.9ms\n",
            "Speed: 2.3ms preprocess, 8.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v38f158.jpg: 384x640 2 persons, 9.5ms\n",
            "Speed: 2.2ms preprocess, 9.5ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v38f159.jpg: 384x640 2 persons, 10.7ms\n",
            "Speed: 3.9ms preprocess, 10.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v38f162.jpg: 384x640 2 persons, 9.9ms\n",
            "Speed: 2.3ms preprocess, 9.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v38f191.jpg: 384x640 3 persons, 8.0ms\n",
            "Speed: 2.3ms preprocess, 8.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v38f194.jpg: 384x640 3 persons, 8.2ms\n",
            "Speed: 2.5ms preprocess, 8.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v38f163.jpg: 384x640 2 persons, 10.6ms\n",
            "Speed: 2.1ms preprocess, 10.6ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v38f156.jpg: 384x640 3 persons, 8.0ms\n",
            "Speed: 2.2ms preprocess, 8.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v38f160.jpg: 384x640 2 persons, 16.0ms\n",
            "Speed: 4.0ms preprocess, 16.0ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v38f154.jpg: 384x640 3 persons, 8.4ms\n",
            "Speed: 2.4ms preprocess, 8.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v38f188.jpg: 384x640 3 persons, 8.2ms\n",
            "Speed: 2.2ms preprocess, 8.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v38f169.jpg: 384x640 2 persons, 12.9ms\n",
            "Speed: 2.2ms preprocess, 12.9ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v38f182.jpg: 384x640 2 persons, 8.6ms\n",
            "Speed: 2.3ms preprocess, 8.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v38f179.jpg: 384x640 2 persons, 8.3ms\n",
            "Speed: 2.4ms preprocess, 8.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v38f178.jpg: 384x640 2 persons, 8.6ms\n",
            "Speed: 2.6ms preprocess, 8.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v53f32.jpg: 384x640 3 persons, 11.0ms\n",
            "Speed: 3.8ms preprocess, 11.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v53f27.jpg: 384x640 3 persons, 10.3ms\n",
            "Speed: 3.4ms preprocess, 10.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v38f195.jpg: 384x640 3 persons, 8.1ms\n",
            "Speed: 2.1ms preprocess, 8.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v53f50.jpg: 384x640 3 persons, 10.6ms\n",
            "Speed: 2.6ms preprocess, 10.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v53f51.jpg: 384x640 3 persons, 11.5ms\n",
            "Speed: 2.5ms preprocess, 11.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v38f197.jpg: 384x640 3 persons, 8.1ms\n",
            "Speed: 2.3ms preprocess, 8.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v53f13.jpg: 384x640 3 persons, 8.5ms\n",
            "Speed: 2.2ms preprocess, 8.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v38f196.jpg: 384x640 3 persons, 8.3ms\n",
            "Speed: 2.2ms preprocess, 8.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v53f42.jpg: 384x640 3 persons, 10.3ms\n",
            "Speed: 3.6ms preprocess, 10.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v53f11.jpg: 384x640 3 persons, 8.1ms\n",
            "Speed: 2.4ms preprocess, 8.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v53f19.jpg: 384x640 3 persons, 8.2ms\n",
            "Speed: 2.4ms preprocess, 8.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v53f7.jpg: 384x640 3 persons, 8.1ms\n",
            "Speed: 2.2ms preprocess, 8.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v53f28.jpg: 384x640 3 persons, 8.5ms\n",
            "Speed: 2.3ms preprocess, 8.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v38f198.jpg: 384x640 3 persons, 8.9ms\n",
            "Speed: 2.8ms preprocess, 8.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v53f21.jpg: 384x640 3 persons, 10.5ms\n",
            "Speed: 3.7ms preprocess, 10.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v53f36.jpg: 384x640 3 persons, 10.8ms\n",
            "Speed: 3.5ms preprocess, 10.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v53f44.jpg: 384x640 3 persons, 8.7ms\n",
            "Speed: 2.2ms preprocess, 8.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v53f31.jpg: 384x640 3 persons, 8.0ms\n",
            "Speed: 2.2ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v53f40.jpg: 384x640 3 persons, 8.2ms\n",
            "Speed: 2.3ms preprocess, 8.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v53f22.jpg: 384x640 3 persons, 8.2ms\n",
            "Speed: 2.1ms preprocess, 8.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v53f65.jpg: 384x640 3 persons, 9.5ms\n",
            "Speed: 2.5ms preprocess, 9.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v53f80.jpg: 384x640 3 persons, 11.6ms\n",
            "Speed: 6.6ms preprocess, 11.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v53f94.jpg: 384x640 3 persons, 8.9ms\n",
            "Speed: 2.5ms preprocess, 8.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v53f102.jpg: 384x640 3 persons, 8.3ms\n",
            "Speed: 2.2ms preprocess, 8.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v53f85.jpg: 384x640 3 persons, 8.3ms\n",
            "Speed: 2.1ms preprocess, 8.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v53f75.jpg: 384x640 2 persons, 8.4ms\n",
            "Speed: 2.3ms preprocess, 8.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v53f67.jpg: 384x640 3 persons, 8.5ms\n",
            "Speed: 2.4ms preprocess, 8.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v53f96.jpg: 384x640 3 persons, 11.1ms\n",
            "Speed: 3.7ms preprocess, 11.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v53f61.jpg: 384x640 3 persons, 17.6ms\n",
            "Speed: 3.7ms preprocess, 17.6ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v53f73.jpg: 384x640 3 persons, 8.5ms\n",
            "Speed: 2.2ms preprocess, 8.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v53f97.jpg: 384x640 3 persons, 8.7ms\n",
            "Speed: 2.3ms preprocess, 8.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v53f101.jpg: 384x640 3 persons, 8.4ms\n",
            "Speed: 2.2ms preprocess, 8.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v53f99.jpg: 384x640 3 persons, 8.4ms\n",
            "Speed: 2.3ms preprocess, 8.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v53f57.jpg: 384x640 3 persons, 10.6ms\n",
            "Speed: 2.3ms preprocess, 10.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v53f88.jpg: 384x640 3 persons, 13.7ms\n",
            "Speed: 3.8ms preprocess, 13.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v53f76.jpg: 384x640 3 persons, 8.0ms\n",
            "Speed: 2.3ms preprocess, 8.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v53f98.jpg: 384x640 3 persons, 8.4ms\n",
            "Speed: 2.2ms preprocess, 8.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v53f90.jpg: 384x640 3 persons, 8.3ms\n",
            "Speed: 2.1ms preprocess, 8.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v53f70.jpg: 384x640 3 persons, 8.2ms\n",
            "Speed: 2.3ms preprocess, 8.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v53f89.jpg: 384x640 3 persons, 8.6ms\n",
            "Speed: 3.2ms preprocess, 8.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v53f60.jpg: 384x640 3 persons, 8.3ms\n",
            "Speed: 2.5ms preprocess, 8.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v42f10.jpg: 384x640 2 persons, 16.6ms\n",
            "Speed: 3.4ms preprocess, 16.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v53f127.jpg: 384x640 3 persons, 8.1ms\n",
            "Speed: 2.1ms preprocess, 8.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v53f123.jpg: 384x640 3 persons, 9.8ms\n",
            "Speed: 2.5ms preprocess, 9.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v53f125.jpg: 384x640 3 persons, 9.2ms\n",
            "Speed: 2.5ms preprocess, 9.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v53f147.jpg: 384x640 3 persons, 16.7ms\n",
            "Speed: 3.7ms preprocess, 16.7ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v42f11.jpg: 384x640 2 persons, 8.5ms\n",
            "Speed: 2.3ms preprocess, 8.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v53f109.jpg: 384x640 3 persons, 12.5ms\n",
            "Speed: 3.7ms preprocess, 12.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v53f108.jpg: 384x640 3 persons, 8.8ms\n",
            "Speed: 2.4ms preprocess, 8.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v53f131.jpg: 384x640 3 persons, 8.0ms\n",
            "Speed: 2.3ms preprocess, 8.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v53f111.jpg: 384x640 3 persons, 8.1ms\n",
            "Speed: 2.4ms preprocess, 8.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v53f148.jpg: 384x640 3 persons, 8.3ms\n",
            "Speed: 2.2ms preprocess, 8.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v53f126.jpg: 384x640 3 persons, 8.4ms\n",
            "Speed: 2.2ms preprocess, 8.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v42f2.jpg: 384x640 2 persons, 8.1ms\n",
            "Speed: 2.2ms preprocess, 8.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v53f149.jpg: 384x640 3 persons, 10.3ms\n",
            "Speed: 5.0ms preprocess, 10.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v53f124.jpg: 384x640 3 persons, 8.3ms\n",
            "Speed: 2.1ms preprocess, 8.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v42f12.jpg: 384x640 2 persons, 8.6ms\n",
            "Speed: 2.2ms preprocess, 8.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v53f137.jpg: 384x640 3 persons, 9.1ms\n",
            "Speed: 2.6ms preprocess, 9.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v53f136.jpg: 384x640 3 persons, 8.6ms\n",
            "Speed: 2.4ms preprocess, 8.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v53f140.jpg: 384x640 3 persons, 8.3ms\n",
            "Speed: 2.2ms preprocess, 8.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v42f38.jpg: 384x640 2 persons, 8.1ms\n",
            "Speed: 2.5ms preprocess, 8.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v42f37.jpg: 384x640 2 persons, 12.7ms\n",
            "Speed: 3.7ms preprocess, 12.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v42f30.jpg: 384x640 2 persons, 8.7ms\n",
            "Speed: 2.4ms preprocess, 8.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v42f25.jpg: 384x640 2 persons, 12.6ms\n",
            "Speed: 3.5ms preprocess, 12.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v42f31.jpg: 384x640 2 persons, 8.7ms\n",
            "Speed: 2.3ms preprocess, 8.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v42f44.jpg: 384x640 2 persons, 8.2ms\n",
            "Speed: 2.3ms preprocess, 8.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v42f20.jpg: 384x640 2 persons, 8.0ms\n",
            "Speed: 2.4ms preprocess, 8.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v42f47.jpg: 384x640 2 persons, 7.8ms\n",
            "Speed: 2.3ms preprocess, 7.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v42f28.jpg: 384x640 2 persons, 11.5ms\n",
            "Speed: 3.7ms preprocess, 11.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v42f21.jpg: 384x640 2 persons, 8.0ms\n",
            "Speed: 2.2ms preprocess, 8.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v42f48.jpg: 384x640 2 persons, 8.7ms\n",
            "Speed: 2.3ms preprocess, 8.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v42f46.jpg: 384x640 2 persons, 8.6ms\n",
            "Speed: 2.3ms preprocess, 8.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v42f26.jpg: 384x640 2 persons, 8.5ms\n",
            "Speed: 2.3ms preprocess, 8.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v42f42.jpg: 384x640 2 persons, 9.6ms\n",
            "Speed: 2.4ms preprocess, 9.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v42f51.jpg: 384x640 2 persons, 7.8ms\n",
            "Speed: 2.3ms preprocess, 7.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v42f17.jpg: 384x640 2 persons, 10.9ms\n",
            "Speed: 3.4ms preprocess, 10.9ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v42f49.jpg: 384x640 2 persons, 8.1ms\n",
            "Speed: 2.3ms preprocess, 8.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v42f60.jpg: 384x640 2 persons, 8.4ms\n",
            "Speed: 2.3ms preprocess, 8.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v42f59.jpg: 384x640 2 persons, 8.8ms\n",
            "Speed: 2.3ms preprocess, 8.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v42f29.jpg: 384x640 2 persons, 8.2ms\n",
            "Speed: 2.5ms preprocess, 8.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v42f56.jpg: 384x640 2 persons, 8.5ms\n",
            "Speed: 2.3ms preprocess, 8.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v42f24.jpg: 384x640 2 persons, 8.2ms\n",
            "Speed: 2.1ms preprocess, 8.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v42f45.jpg: 384x640 2 persons, 10.5ms\n",
            "Speed: 3.6ms preprocess, 10.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v42f52.jpg: 384x640 2 persons, 9.6ms\n",
            "Speed: 2.1ms preprocess, 9.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v42f85.jpg: 384x640 2 persons, 8.4ms\n",
            "Speed: 2.3ms preprocess, 8.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v42f110.jpg: 384x640 2 persons, 8.4ms\n",
            "Speed: 2.3ms preprocess, 8.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v42f68.jpg: 384x640 3 persons, 8.7ms\n",
            "Speed: 3.5ms preprocess, 8.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v42f66.jpg: 384x640 2 persons, 8.3ms\n",
            "Speed: 2.1ms preprocess, 8.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v42f88.jpg: 384x640 2 persons, 8.1ms\n",
            "Speed: 2.3ms preprocess, 8.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v42f108.jpg: 384x640 2 persons, 10.4ms\n",
            "Speed: 3.6ms preprocess, 10.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v42f65.jpg: 384x640 2 persons, 8.6ms\n",
            "Speed: 2.4ms preprocess, 8.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v42f73.jpg: 384x640 2 persons, 8.3ms\n",
            "Speed: 2.3ms preprocess, 8.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v42f89.jpg: 384x640 2 persons, 15.8ms\n",
            "Speed: 3.7ms preprocess, 15.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v42f70.jpg: 384x640 3 persons, 8.4ms\n",
            "Speed: 2.3ms preprocess, 8.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v42f86.jpg: 384x640 2 persons, 9.1ms\n",
            "Speed: 3.0ms preprocess, 9.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v42f92.jpg: 384x640 2 persons, 16.3ms\n",
            "Speed: 3.6ms preprocess, 16.3ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v42f79.jpg: 384x640 2 persons, 14.5ms\n",
            "Speed: 3.7ms preprocess, 14.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v42f100.jpg: 384x640 2 persons, 8.6ms\n",
            "Speed: 2.2ms preprocess, 8.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v42f78.jpg: 384x640 2 persons, 8.4ms\n",
            "Speed: 3.3ms preprocess, 8.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v42f103.jpg: 384x640 2 persons, 8.2ms\n",
            "Speed: 2.1ms preprocess, 8.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v42f96.jpg: 384x640 2 persons, 8.2ms\n",
            "Speed: 2.3ms preprocess, 8.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v42f87.jpg: 384x640 2 persons, 8.2ms\n",
            "Speed: 2.4ms preprocess, 8.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v42f91.jpg: 384x640 2 persons, 15.2ms\n",
            "Speed: 3.7ms preprocess, 15.2ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v42f128.jpg: 384x640 2 persons, 8.3ms\n",
            "Speed: 2.3ms preprocess, 8.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v58f1.jpg: 384x640 3 persons, 8.2ms\n",
            "Speed: 2.4ms preprocess, 8.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v58f5.jpg: 384x640 3 persons, 8.4ms\n",
            "Speed: 2.1ms preprocess, 8.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v58f11.jpg: 384x640 3 persons, 8.4ms\n",
            "Speed: 2.3ms preprocess, 8.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v42f114.jpg: 384x640 2 persons, 8.7ms\n",
            "Speed: 2.4ms preprocess, 8.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v58f4.jpg: 384x640 3 persons, 10.5ms\n",
            "Speed: 3.6ms preprocess, 10.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v58f32.jpg: 384x640 3 persons, 15.2ms\n",
            "Speed: 3.4ms preprocess, 15.2ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v58f19.jpg: 384x640 4 persons, 8.7ms\n",
            "Speed: 2.3ms preprocess, 8.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v58f24.jpg: 384x640 3 persons, 8.0ms\n",
            "Speed: 2.3ms preprocess, 8.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v58f2.jpg: 384x640 3 persons, 9.6ms\n",
            "Speed: 2.4ms preprocess, 9.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v58f6.jpg: 384x640 3 persons, 8.2ms\n",
            "Speed: 2.1ms preprocess, 8.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v42f129.jpg: 384x640 2 persons, 10.9ms\n",
            "Speed: 5.6ms preprocess, 10.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v58f22.jpg: 384x640 3 persons, 15.1ms\n",
            "Speed: 3.6ms preprocess, 15.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v42f132.jpg: 384x640 3 persons, 8.1ms\n",
            "Speed: 2.3ms preprocess, 8.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v58f10.jpg: 384x640 3 persons, 10.0ms\n",
            "Speed: 2.3ms preprocess, 10.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v42f122.jpg: 384x640 2 persons, 8.0ms\n",
            "Speed: 2.4ms preprocess, 8.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v58f23.jpg: 384x640 3 persons, 14.4ms\n",
            "Speed: 2.4ms preprocess, 14.4ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v42f120.jpg: 384x640 2 persons, 13.4ms\n",
            "Speed: 3.3ms preprocess, 13.4ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v58f79.jpg: 384x640 3 persons, 17.1ms\n",
            "Speed: 3.6ms preprocess, 17.1ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v58f62.jpg: 384x640 2 persons, 8.2ms\n",
            "Speed: 2.2ms preprocess, 8.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v58f75.jpg: 384x640 3 persons, 8.1ms\n",
            "Speed: 2.2ms preprocess, 8.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v58f70.jpg: 384x640 3 persons, 8.6ms\n",
            "Speed: 2.3ms preprocess, 8.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v58f54.jpg: 384x640 2 persons, 8.5ms\n",
            "Speed: 2.2ms preprocess, 8.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v58f38.jpg: 384x640 4 persons, 8.3ms\n",
            "Speed: 2.4ms preprocess, 8.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v58f51.jpg: 384x640 3 persons, 8.2ms\n",
            "Speed: 2.1ms preprocess, 8.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v58f72.jpg: 384x640 3 persons, 10.1ms\n",
            "Speed: 3.6ms preprocess, 10.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v58f64.jpg: 384x640 2 persons, 8.0ms\n",
            "Speed: 2.4ms preprocess, 8.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v58f69.jpg: 384x640 3 persons, 8.4ms\n",
            "Speed: 2.2ms preprocess, 8.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v58f78.jpg: 384x640 3 persons, 8.3ms\n",
            "Speed: 2.1ms preprocess, 8.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v58f57.jpg: 384x640 2 persons, 8.3ms\n",
            "Speed: 2.3ms preprocess, 8.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v58f77.jpg: 384x640 3 persons, 8.4ms\n",
            "Speed: 2.4ms preprocess, 8.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v58f65.jpg: 384x640 2 persons, 8.2ms\n",
            "Speed: 2.2ms preprocess, 8.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v58f37.jpg: 384x640 4 persons, 11.1ms\n",
            "Speed: 3.4ms preprocess, 11.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v58f63.jpg: 384x640 2 persons, 8.4ms\n",
            "Speed: 2.4ms preprocess, 8.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v58f74.jpg: 384x640 3 persons, 11.0ms\n",
            "Speed: 3.8ms preprocess, 11.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v58f71.jpg: 384x640 3 persons, 8.4ms\n",
            "Speed: 2.4ms preprocess, 8.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v58f33.jpg: 384x640 3 persons, 8.3ms\n",
            "Speed: 2.2ms preprocess, 8.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v58f76.jpg: 384x640 3 persons, 10.7ms\n",
            "Speed: 2.3ms preprocess, 10.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v58f93.jpg: 384x640 2 persons, 8.4ms\n",
            "Speed: 2.2ms preprocess, 8.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v58f85.jpg: 384x640 2 persons, 11.7ms\n",
            "Speed: 3.4ms preprocess, 11.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v58f103.jpg: 384x640 3 persons, 8.0ms\n",
            "Speed: 2.3ms preprocess, 8.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v58f88.jpg: 384x640 3 persons, 18.3ms\n",
            "Speed: 3.6ms preprocess, 18.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v58f126.jpg: 384x640 3 persons, 8.1ms\n",
            "Speed: 2.4ms preprocess, 8.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v58f113.jpg: 384x640 3 persons, 8.2ms\n",
            "Speed: 2.4ms preprocess, 8.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v58f118.jpg: 384x640 3 persons, 8.1ms\n",
            "Speed: 2.4ms preprocess, 8.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v58f132.jpg: 384x640 3 persons, 8.3ms\n",
            "Speed: 2.4ms preprocess, 8.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v58f101.jpg: 384x640 2 persons, 10.2ms\n",
            "Speed: 3.7ms preprocess, 10.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v58f106.jpg: 384x640 3 persons, 7.9ms\n",
            "Speed: 2.3ms preprocess, 7.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v58f130.jpg: 384x640 3 persons, 10.6ms\n",
            "Speed: 2.2ms preprocess, 10.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v58f111.jpg: 384x640 2 persons, 8.4ms\n",
            "Speed: 2.3ms preprocess, 8.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v58f87.jpg: 384x640 2 persons, 8.0ms\n",
            "Speed: 2.3ms preprocess, 8.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v58f102.jpg: 384x640 3 persons, 8.8ms\n",
            "Speed: 2.5ms preprocess, 8.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v58f90.jpg: 384x640 4 persons, 12.1ms\n",
            "Speed: 3.6ms preprocess, 12.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v58f86.jpg: 384x640 2 persons, 9.0ms\n",
            "Speed: 2.5ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v58f83.jpg: 384x640 2 persons, 8.6ms\n",
            "Speed: 2.3ms preprocess, 8.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v58f112.jpg: 384x640 3 persons, 8.6ms\n",
            "Speed: 2.3ms preprocess, 8.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v58f107.jpg: 384x640 2 persons, 8.2ms\n",
            "Speed: 2.2ms preprocess, 8.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v58f89.jpg: 384x640 3 persons, 8.6ms\n",
            "Speed: 2.5ms preprocess, 8.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v58f133.jpg: 384x640 3 persons, 8.2ms\n",
            "Speed: 2.3ms preprocess, 8.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v19f7.jpg: 384x640 4 persons, 10.8ms\n",
            "Speed: 3.6ms preprocess, 10.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v58f140.jpg: 384x640 3 persons, 13.4ms\n",
            "Speed: 5.4ms preprocess, 13.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v19f16.jpg: 384x640 4 persons, 10.4ms\n",
            "Speed: 3.7ms preprocess, 10.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v19f14.jpg: 384x640 4 persons, 8.5ms\n",
            "Speed: 2.2ms preprocess, 8.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v19f34.jpg: 384x640 4 persons, 8.1ms\n",
            "Speed: 2.4ms preprocess, 8.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v19f35.jpg: 384x640 4 persons, 8.2ms\n",
            "Speed: 2.1ms preprocess, 8.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v19f20.jpg: 384x640 3 persons, 8.2ms\n",
            "Speed: 2.4ms preprocess, 8.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v58f141.jpg: 384x640 3 persons, 16.2ms\n",
            "Speed: 3.5ms preprocess, 16.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v19f33.jpg: 384x640 4 persons, 10.4ms\n",
            "Speed: 3.6ms preprocess, 10.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v19f12.jpg: 384x640 4 persons, 10.0ms\n",
            "Speed: 2.3ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v19f24.jpg: 384x640 3 persons, 8.0ms\n",
            "Speed: 2.3ms preprocess, 8.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v19f17.jpg: 384x640 4 persons, 8.2ms\n",
            "Speed: 2.2ms preprocess, 8.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v19f18.jpg: 384x640 4 persons, 8.2ms\n",
            "Speed: 2.2ms preprocess, 8.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v19f27.jpg: 384x640 3 persons, 8.2ms\n",
            "Speed: 2.2ms preprocess, 8.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v19f1.jpg: 384x640 4 persons, 11.8ms\n",
            "Speed: 3.9ms preprocess, 11.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v19f15.jpg: 384x640 3 persons, 12.1ms\n",
            "Speed: 3.0ms preprocess, 12.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v19f4.jpg: 384x640 4 persons, 8.8ms\n",
            "Speed: 2.3ms preprocess, 8.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v19f58.jpg: 384x640 4 persons, 8.6ms\n",
            "Speed: 2.4ms preprocess, 8.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v19f46.jpg: 384x640 4 persons, 8.6ms\n",
            "Speed: 2.5ms preprocess, 8.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v19f49.jpg: 384x640 4 persons, 8.2ms\n",
            "Speed: 2.3ms preprocess, 8.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v19f56.jpg: 384x640 4 persons, 8.6ms\n",
            "Speed: 2.5ms preprocess, 8.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v19f64.jpg: 384x640 4 persons, 10.9ms\n",
            "Speed: 3.9ms preprocess, 10.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v19f37.jpg: 384x640 6 persons, 8.5ms\n",
            "Speed: 2.4ms preprocess, 8.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v19f69.jpg: 384x640 4 persons, 8.8ms\n",
            "Speed: 2.4ms preprocess, 8.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v19f60.jpg: 384x640 4 persons, 8.5ms\n",
            "Speed: 2.3ms preprocess, 8.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v19f53.jpg: 384x640 4 persons, 9.8ms\n",
            "Speed: 2.3ms preprocess, 9.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v19f63.jpg: 384x640 4 persons, 8.5ms\n",
            "Speed: 2.4ms preprocess, 8.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v19f51.jpg: 384x640 4 persons, 8.7ms\n",
            "Speed: 2.2ms preprocess, 8.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v19f52.jpg: 384x640 4 persons, 10.3ms\n",
            "Speed: 3.5ms preprocess, 10.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v19f62.jpg: 384x640 4 persons, 8.4ms\n",
            "Speed: 2.3ms preprocess, 8.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v37f6.jpg: 384x640 3 persons, 8.6ms\n",
            "Speed: 2.3ms preprocess, 8.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v37f11.jpg: 384x640 3 persons, 8.6ms\n",
            "Speed: 2.3ms preprocess, 8.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v37f50.jpg: 384x640 2 persons, 8.8ms\n",
            "Speed: 2.3ms preprocess, 8.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v37f54.jpg: 384x640 2 persons, 8.3ms\n",
            "Speed: 2.2ms preprocess, 8.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v37f40.jpg: 384x640 3 persons, 8.1ms\n",
            "Speed: 2.7ms preprocess, 8.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v37f39.jpg: 384x640 3 persons, 15.8ms\n",
            "Speed: 3.7ms preprocess, 15.8ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v37f48.jpg: 384x640 2 persons, 8.5ms\n",
            "Speed: 2.3ms preprocess, 8.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v37f24.jpg: 384x640 3 persons, 8.6ms\n",
            "Speed: 2.4ms preprocess, 8.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v37f46.jpg: 384x640 2 persons, 8.7ms\n",
            "Speed: 2.3ms preprocess, 8.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v37f17.jpg: 384x640 3 persons, 8.5ms\n",
            "Speed: 2.2ms preprocess, 8.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v37f59.jpg: 384x640 2 persons, 8.8ms\n",
            "Speed: 2.4ms preprocess, 8.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v37f30.jpg: 384x640 3 persons, 15.3ms\n",
            "Speed: 3.8ms preprocess, 15.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v37f53.jpg: 384x640 2 persons, 8.8ms\n",
            "Speed: 2.4ms preprocess, 8.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v37f10.jpg: 384x640 3 persons, 9.6ms\n",
            "Speed: 2.4ms preprocess, 9.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v37f20.jpg: 384x640 3 persons, 10.0ms\n",
            "Speed: 2.3ms preprocess, 10.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v37f18.jpg: 384x640 3 persons, 10.5ms\n",
            "Speed: 2.3ms preprocess, 10.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v37f34.jpg: 384x640 3 persons, 8.6ms\n",
            "Speed: 2.5ms preprocess, 8.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v37f106.jpg: 384x640 2 persons, 8.7ms\n",
            "Speed: 2.4ms preprocess, 8.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v37f63.jpg: 384x640 2 persons, 11.1ms\n",
            "Speed: 3.7ms preprocess, 11.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v37f66.jpg: 384x640 2 persons, 8.6ms\n",
            "Speed: 2.2ms preprocess, 8.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v37f73.jpg: 384x640 3 persons, 8.6ms\n",
            "Speed: 2.4ms preprocess, 8.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v37f91.jpg: 384x640 2 persons, 8.2ms\n",
            "Speed: 2.4ms preprocess, 8.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v37f105.jpg: 384x640 2 persons, 8.4ms\n",
            "Speed: 2.6ms preprocess, 8.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v37f93.jpg: 384x640 2 persons, 8.1ms\n",
            "Speed: 2.3ms preprocess, 8.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v37f102.jpg: 384x640 2 persons, 8.5ms\n",
            "Speed: 2.4ms preprocess, 8.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v37f88.jpg: 384x640 2 persons, 14.6ms\n",
            "Speed: 3.6ms preprocess, 14.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v37f100.jpg: 384x640 2 persons, 10.1ms\n",
            "Speed: 3.7ms preprocess, 10.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v37f112.jpg: 384x640 2 persons, 8.4ms\n",
            "Speed: 3.6ms preprocess, 8.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v37f113.jpg: 384x640 2 persons, 8.4ms\n",
            "Speed: 2.3ms preprocess, 8.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v37f108.jpg: 384x640 2 persons, 8.2ms\n",
            "Speed: 2.1ms preprocess, 8.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v37f96.jpg: 384x640 2 persons, 8.4ms\n",
            "Speed: 2.2ms preprocess, 8.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v37f110.jpg: 384x640 2 persons, 8.2ms\n",
            "Speed: 2.2ms preprocess, 8.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v37f67.jpg: 384x640 2 persons, 8.1ms\n",
            "Speed: 2.4ms preprocess, 8.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v37f117.jpg: 384x640 2 persons, 14.2ms\n",
            "Speed: 3.4ms preprocess, 14.2ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v37f62.jpg: 384x640 2 persons, 8.7ms\n",
            "Speed: 2.5ms preprocess, 8.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v37f68.jpg: 384x640 2 persons, 8.1ms\n",
            "Speed: 2.4ms preprocess, 8.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v37f104.jpg: 384x640 3 persons, 8.5ms\n",
            "Speed: 2.3ms preprocess, 8.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v37f85.jpg: 384x640 2 persons, 8.9ms\n",
            "Speed: 2.3ms preprocess, 8.9ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v37f121.jpg: 384x640 2 persons, 8.6ms\n",
            "Speed: 2.4ms preprocess, 8.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v37f142.jpg: 384x640 3 persons, 13.4ms\n",
            "Speed: 5.9ms preprocess, 13.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v37f128.jpg: 384x640 2 persons, 9.0ms\n",
            "Speed: 3.9ms preprocess, 9.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v54f14.jpg: 384x640 3 persons, 8.1ms\n",
            "Speed: 2.2ms preprocess, 8.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v37f118.jpg: 384x640 2 persons, 8.5ms\n",
            "Speed: 2.3ms preprocess, 8.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v37f133.jpg: 384x640 2 persons, 8.0ms\n",
            "Speed: 2.5ms preprocess, 8.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v37f138.jpg: 384x640 3 persons, 7.9ms\n",
            "Speed: 2.3ms preprocess, 7.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v54f19.jpg: 384x640 4 persons, 8.6ms\n",
            "Speed: 2.4ms preprocess, 8.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v37f127.jpg: 384x640 2 persons, 14.5ms\n",
            "Speed: 3.9ms preprocess, 14.5ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v54f22.jpg: 384x640 3 persons, 14.9ms\n",
            "Speed: 3.9ms preprocess, 14.9ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v54f20.jpg: 384x640 3 persons, 8.7ms\n",
            "Speed: 2.2ms preprocess, 8.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v37f125.jpg: 384x640 2 persons, 8.1ms\n",
            "Speed: 2.1ms preprocess, 8.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v54f17.jpg: 384x640 3 persons, 8.4ms\n",
            "Speed: 2.1ms preprocess, 8.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v54f10.jpg: 384x640 3 persons, 8.0ms\n",
            "Speed: 2.3ms preprocess, 8.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v54f13.jpg: 384x640 3 persons, 8.4ms\n",
            "Speed: 2.3ms preprocess, 8.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v37f139.jpg: 384x640 3 persons, 14.6ms\n",
            "Speed: 3.6ms preprocess, 14.6ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v37f123.jpg: 384x640 2 persons, 15.7ms\n",
            "Speed: 3.6ms preprocess, 15.7ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v37f136.jpg: 384x640 3 persons, 8.4ms\n",
            "Speed: 2.4ms preprocess, 8.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v54f4.jpg: 384x640 3 persons, 8.6ms\n",
            "Speed: 2.3ms preprocess, 8.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v54f11.jpg: 384x640 3 persons, 8.7ms\n",
            "Speed: 2.4ms preprocess, 8.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v54f21.jpg: 384x640 3 persons, 8.2ms\n",
            "Speed: 2.4ms preprocess, 8.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v54f37.jpg: 384x640 3 persons, 8.6ms\n",
            "Speed: 2.3ms preprocess, 8.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v54f67.jpg: 384x640 4 persons, 10.2ms\n",
            "Speed: 3.6ms preprocess, 10.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v54f61.jpg: 384x640 5 persons, 8.6ms\n",
            "Speed: 2.2ms preprocess, 8.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v54f33.jpg: 384x640 4 persons, 8.5ms\n",
            "Speed: 2.3ms preprocess, 8.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v54f64.jpg: 384x640 3 persons, 8.1ms\n",
            "Speed: 2.2ms preprocess, 8.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v54f44.jpg: 384x640 4 persons, 11.0ms\n",
            "Speed: 2.8ms preprocess, 11.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v54f63.jpg: 384x640 4 persons, 8.5ms\n",
            "Speed: 2.3ms preprocess, 8.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v54f48.jpg: 384x640 4 persons, 8.4ms\n",
            "Speed: 2.3ms preprocess, 8.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v54f68.jpg: 384x640 3 persons, 10.5ms\n",
            "Speed: 3.5ms preprocess, 10.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v54f26.jpg: 384x640 3 persons, 8.3ms\n",
            "Speed: 2.3ms preprocess, 8.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v54f24.jpg: 384x640 4 persons, 8.1ms\n",
            "Speed: 2.3ms preprocess, 8.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v54f46.jpg: 384x640 4 persons, 9.1ms\n",
            "Speed: 2.3ms preprocess, 9.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v54f55.jpg: 384x640 3 persons, 9.3ms\n",
            "Speed: 2.4ms preprocess, 9.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v54f79.jpg: 384x640 3 persons, 8.1ms\n",
            "Speed: 2.4ms preprocess, 8.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v54f36.jpg: 384x640 3 persons, 15.5ms\n",
            "Speed: 3.8ms preprocess, 15.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v54f57.jpg: 384x640 3 persons, 8.2ms\n",
            "Speed: 2.2ms preprocess, 8.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v54f31.jpg: 384x640 4 persons, 8.4ms\n",
            "Speed: 2.4ms preprocess, 8.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v54f74.jpg: 384x640 3 persons, 8.6ms\n",
            "Speed: 2.2ms preprocess, 8.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v54f34.jpg: 384x640 4 persons, 8.1ms\n",
            "Speed: 2.2ms preprocess, 8.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v54f72.jpg: 384x640 4 persons, 8.6ms\n",
            "Speed: 2.3ms preprocess, 8.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v54f71.jpg: 384x640 3 persons, 11.4ms\n",
            "Speed: 3.8ms preprocess, 11.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v54f95.jpg: 384x640 3 persons, 14.5ms\n",
            "Speed: 3.8ms preprocess, 14.5ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v54f85.jpg: 384x640 3 persons, 8.7ms\n",
            "Speed: 2.5ms preprocess, 8.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v54f89.jpg: 384x640 3 persons, 8.6ms\n",
            "Speed: 2.5ms preprocess, 8.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v54f102.jpg: 384x640 4 persons, 8.6ms\n",
            "Speed: 2.5ms preprocess, 8.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v54f104.jpg: 384x640 4 persons, 10.8ms\n",
            "Speed: 3.5ms preprocess, 10.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v54f105.jpg: 384x640 4 persons, 9.2ms\n",
            "Speed: 2.2ms preprocess, 9.2ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v54f92.jpg: 384x640 3 persons, 11.6ms\n",
            "Speed: 3.7ms preprocess, 11.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v54f112.jpg: 384x640 4 persons, 8.4ms\n",
            "Speed: 2.2ms preprocess, 8.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v54f120.jpg: 384x640 3 persons, 8.5ms\n",
            "Speed: 2.3ms preprocess, 8.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v54f113.jpg: 384x640 3 persons, 9.0ms\n",
            "Speed: 2.4ms preprocess, 9.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v54f93.jpg: 384x640 3 persons, 8.7ms\n",
            "Speed: 2.4ms preprocess, 8.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v54f115.jpg: 384x640 4 persons, 8.3ms\n",
            "Speed: 2.2ms preprocess, 8.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v54f114.jpg: 384x640 4 persons, 8.1ms\n",
            "Speed: 2.2ms preprocess, 8.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v54f109.jpg: 384x640 3 persons, 15.4ms\n",
            "Speed: 3.5ms preprocess, 15.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v54f110.jpg: 384x640 3 persons, 8.4ms\n",
            "Speed: 2.3ms preprocess, 8.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v54f91.jpg: 384x640 3 persons, 8.4ms\n",
            "Speed: 2.3ms preprocess, 8.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v54f160.jpg: 384x640 3 persons, 8.3ms\n",
            "Speed: 2.3ms preprocess, 8.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v54f171.jpg: 384x640 3 persons, 8.1ms\n",
            "Speed: 2.2ms preprocess, 8.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v54f156.jpg: 384x640 3 persons, 8.1ms\n",
            "Speed: 2.2ms preprocess, 8.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v54f124.jpg: 384x640 3 persons, 8.3ms\n",
            "Speed: 2.1ms preprocess, 8.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v54f164.jpg: 384x640 3 persons, 14.3ms\n",
            "Speed: 4.7ms preprocess, 14.3ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v54f149.jpg: 384x640 3 persons, 8.8ms\n",
            "Speed: 2.4ms preprocess, 8.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v54f127.jpg: 384x640 3 persons, 9.8ms\n",
            "Speed: 3.7ms preprocess, 9.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v54f141.jpg: 384x640 3 persons, 8.6ms\n",
            "Speed: 2.2ms preprocess, 8.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v54f135.jpg: 384x640 3 persons, 8.2ms\n",
            "Speed: 2.3ms preprocess, 8.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v54f162.jpg: 384x640 4 persons, 8.7ms\n",
            "Speed: 2.4ms preprocess, 8.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v54f143.jpg: 384x640 3 persons, 8.4ms\n",
            "Speed: 2.5ms preprocess, 8.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v54f147.jpg: 384x640 3 persons, 11.1ms\n",
            "Speed: 3.8ms preprocess, 11.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v54f145.jpg: 384x640 3 persons, 8.4ms\n",
            "Speed: 2.4ms preprocess, 8.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v54f167.jpg: 384x640 4 persons, 8.2ms\n",
            "Speed: 2.2ms preprocess, 8.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v54f133.jpg: 384x640 3 persons, 8.5ms\n",
            "Speed: 2.3ms preprocess, 8.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v54f130.jpg: 384x640 3 persons, 8.7ms\n",
            "Speed: 2.4ms preprocess, 8.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v54f159.jpg: 384x640 3 persons, 9.0ms\n",
            "Speed: 2.4ms preprocess, 9.0ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v54f152.jpg: 384x640 3 persons, 19.4ms\n",
            "Speed: 4.0ms preprocess, 19.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v54f166.jpg: 384x640 3 persons, 16.8ms\n",
            "Speed: 3.5ms preprocess, 16.8ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v28f22.jpg: 384x640 2 persons, 9.3ms\n",
            "Speed: 2.4ms preprocess, 9.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v28f6.jpg: 384x640 2 persons, 8.0ms\n",
            "Speed: 2.1ms preprocess, 8.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v28f27.jpg: 384x640 2 persons, 8.1ms\n",
            "Speed: 2.4ms preprocess, 8.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v28f2.jpg: 384x640 2 persons, 8.5ms\n",
            "Speed: 2.3ms preprocess, 8.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v28f40.jpg: 384x640 1 person, 8.4ms\n",
            "Speed: 2.4ms preprocess, 8.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v28f39.jpg: 384x640 1 person, 14.6ms\n",
            "Speed: 4.0ms preprocess, 14.6ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v28f24.jpg: 384x640 2 persons, 8.3ms\n",
            "Speed: 2.2ms preprocess, 8.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v28f26.jpg: 384x640 3 persons, 8.3ms\n",
            "Speed: 2.2ms preprocess, 8.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v54f175.jpg: 384x640 3 persons, 8.3ms\n",
            "Speed: 2.4ms preprocess, 8.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v54f181.jpg: 384x640 3 persons, 8.8ms\n",
            "Speed: 2.5ms preprocess, 8.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v28f17.jpg: 384x640 2 persons, 8.5ms\n",
            "Speed: 2.4ms preprocess, 8.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v28f8.jpg: 384x640 2 persons, 8.9ms\n",
            "Speed: 2.5ms preprocess, 8.9ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v28f29.jpg: 384x640 2 persons, 10.4ms\n",
            "Speed: 3.6ms preprocess, 10.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v28f1.jpg: 384x640 2 persons, 8.0ms\n",
            "Speed: 2.5ms preprocess, 8.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v54f185.jpg: 384x640 3 persons, 8.4ms\n",
            "Speed: 2.4ms preprocess, 8.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v28f33.jpg: 384x640 2 persons, 8.3ms\n",
            "Speed: 2.1ms preprocess, 8.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v28f61.jpg: 384x640 1 person, 8.5ms\n",
            "Speed: 2.2ms preprocess, 8.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v28f58.jpg: 384x640 1 person, 9.1ms\n",
            "Speed: 2.5ms preprocess, 9.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v28f64.jpg: 384x640 1 person, 11.0ms\n",
            "Speed: 3.6ms preprocess, 11.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v28f48.jpg: 384x640 1 person, 11.4ms\n",
            "Speed: 3.7ms preprocess, 11.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v28f50.jpg: 384x640 1 person, 8.3ms\n",
            "Speed: 2.3ms preprocess, 8.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v28f65.jpg: 384x640 1 person, 8.4ms\n",
            "Speed: 2.4ms preprocess, 8.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v28f49.jpg: 384x640 1 person, 8.5ms\n",
            "Speed: 2.4ms preprocess, 8.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v28f91.jpg: 384x640 1 person, 15.8ms\n",
            "Speed: 3.8ms preprocess, 15.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v28f62.jpg: 384x640 1 person, 8.3ms\n",
            "Speed: 2.3ms preprocess, 8.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v28f86.jpg: 384x640 1 person, 14.9ms\n",
            "Speed: 3.7ms preprocess, 14.9ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v28f81.jpg: 384x640 1 person, 15.7ms\n",
            "Speed: 3.5ms preprocess, 15.7ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v28f53.jpg: 384x640 1 person, 8.6ms\n",
            "Speed: 2.4ms preprocess, 8.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v28f83.jpg: 384x640 1 person, 8.8ms\n",
            "Speed: 2.2ms preprocess, 8.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v28f45.jpg: 384x640 1 person, 8.5ms\n",
            "Speed: 2.4ms preprocess, 8.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v28f57.jpg: 384x640 1 person, 8.8ms\n",
            "Speed: 2.4ms preprocess, 8.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v28f75.jpg: 384x640 1 person, 8.5ms\n",
            "Speed: 2.2ms preprocess, 8.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v28f89.jpg: 384x640 1 person, 14.4ms\n",
            "Speed: 3.6ms preprocess, 14.4ms inference, 7.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v28f121.jpg: 384x640 2 persons, 8.2ms\n",
            "Speed: 2.3ms preprocess, 8.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v28f129.jpg: 384x640 2 persons, 9.1ms\n",
            "Speed: 2.3ms preprocess, 9.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v28f104.jpg: 384x640 2 persons, 8.5ms\n",
            "Speed: 2.3ms preprocess, 8.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v28f115.jpg: 384x640 2 persons, 11.2ms\n",
            "Speed: 8.5ms preprocess, 11.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v28f113.jpg: 384x640 2 persons, 8.2ms\n",
            "Speed: 2.2ms preprocess, 8.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v28f132.jpg: 384x640 2 persons, 8.3ms\n",
            "Speed: 2.1ms preprocess, 8.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v28f130.jpg: 384x640 2 persons, 8.8ms\n",
            "Speed: 2.5ms preprocess, 8.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v28f131.jpg: 384x640 2 persons, 8.3ms\n",
            "Speed: 2.3ms preprocess, 8.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v28f97.jpg: 384x640 1 person, 8.5ms\n",
            "Speed: 2.2ms preprocess, 8.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v28f125.jpg: 384x640 2 persons, 8.2ms\n",
            "Speed: 2.2ms preprocess, 8.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v28f112.jpg: 384x640 2 persons, 10.9ms\n",
            "Speed: 4.3ms preprocess, 10.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v28f128.jpg: 384x640 2 persons, 8.7ms\n",
            "Speed: 2.4ms preprocess, 8.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v28f127.jpg: 384x640 2 persons, 16.7ms\n",
            "Speed: 3.8ms preprocess, 16.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v28f107.jpg: 384x640 3 persons, 8.2ms\n",
            "Speed: 2.3ms preprocess, 8.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v28f110.jpg: 384x640 2 persons, 8.1ms\n",
            "Speed: 2.4ms preprocess, 8.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v28f139.jpg: 384x640 2 persons, 8.7ms\n",
            "Speed: 2.4ms preprocess, 8.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v28f118.jpg: 384x640 2 persons, 13.7ms\n",
            "Speed: 4.0ms preprocess, 13.7ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v28f103.jpg: 384x640 2 persons, 8.7ms\n",
            "Speed: 2.4ms preprocess, 8.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v28f96.jpg: 384x640 2 persons, 8.6ms\n",
            "Speed: 2.4ms preprocess, 8.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v49f0.jpg: 384x640 2 persons, 8.6ms\n",
            "Speed: 2.2ms preprocess, 8.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v49f17.jpg: 384x640 2 persons, 8.5ms\n",
            "Speed: 2.5ms preprocess, 8.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v49f20.jpg: 384x640 2 persons, 14.8ms\n",
            "Speed: 3.2ms preprocess, 14.8ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v49f9.jpg: 384x640 2 persons, 8.2ms\n",
            "Speed: 2.4ms preprocess, 8.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v49f8.jpg: 384x640 2 persons, 14.9ms\n",
            "Speed: 3.7ms preprocess, 14.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v49f11.jpg: 384x640 2 persons, 8.3ms\n",
            "Speed: 2.3ms preprocess, 8.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v49f32.jpg: 384x640 2 persons, 8.1ms\n",
            "Speed: 2.2ms preprocess, 8.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v49f23.jpg: 384x640 2 persons, 8.2ms\n",
            "Speed: 2.3ms preprocess, 8.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v49f7.jpg: 384x640 2 persons, 9.0ms\n",
            "Speed: 2.3ms preprocess, 9.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v49f13.jpg: 384x640 2 persons, 8.3ms\n",
            "Speed: 2.4ms preprocess, 8.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v49f24.jpg: 384x640 3 persons, 8.8ms\n",
            "Speed: 2.7ms preprocess, 8.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v49f12.jpg: 384x640 2 persons, 10.5ms\n",
            "Speed: 3.8ms preprocess, 10.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v49f31.jpg: 384x640 2 persons, 9.0ms\n",
            "Speed: 2.3ms preprocess, 9.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v49f21.jpg: 384x640 2 persons, 8.6ms\n",
            "Speed: 2.5ms preprocess, 8.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v49f25.jpg: 384x640 2 persons, 8.4ms\n",
            "Speed: 2.4ms preprocess, 8.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v49f5.jpg: 384x640 2 persons, 8.4ms\n",
            "Speed: 2.3ms preprocess, 8.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v49f16.jpg: 384x640 2 persons, 9.0ms\n",
            "Speed: 2.2ms preprocess, 9.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v49f6.jpg: 384x640 2 persons, 8.5ms\n",
            "Speed: 2.3ms preprocess, 8.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v28f140.jpg: 384x640 2 persons, 11.7ms\n",
            "Speed: 3.7ms preprocess, 11.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v49f3.jpg: 384x640 2 persons, 8.4ms\n",
            "Speed: 2.4ms preprocess, 8.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v49f26.jpg: 384x640 2 persons, 8.7ms\n",
            "Speed: 2.4ms preprocess, 8.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v49f2.jpg: 384x640 3 persons, 8.1ms\n",
            "Speed: 2.4ms preprocess, 8.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v49f37.jpg: 384x640 3 persons, 8.6ms\n",
            "Speed: 2.3ms preprocess, 8.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v49f52.jpg: 384x640 1 person, 8.2ms\n",
            "Speed: 2.3ms preprocess, 8.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v49f77.jpg: 384x640 2 persons, 14.6ms\n",
            "Speed: 3.9ms preprocess, 14.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v49f62.jpg: 384x640 1 person, 17.5ms\n",
            "Speed: 3.6ms preprocess, 17.5ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v49f45.jpg: 384x640 1 person, 8.2ms\n",
            "Speed: 2.4ms preprocess, 8.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v49f34.jpg: 384x640 2 persons, 8.2ms\n",
            "Speed: 2.1ms preprocess, 8.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v49f75.jpg: 384x640 2 persons, 16.3ms\n",
            "Speed: 3.7ms preprocess, 16.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v49f69.jpg: 384x640 1 person, 8.8ms\n",
            "Speed: 2.3ms preprocess, 8.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v49f50.jpg: 384x640 1 person, 8.4ms\n",
            "Speed: 2.4ms preprocess, 8.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v49f63.jpg: 384x640 1 person, 16.1ms\n",
            "Speed: 3.5ms preprocess, 16.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v49f66.jpg: 384x640 1 person, 11.7ms\n",
            "Speed: 3.9ms preprocess, 11.7ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v49f38.jpg: 384x640 3 persons, 8.2ms\n",
            "Speed: 2.2ms preprocess, 8.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v49f61.jpg: 384x640 1 person, 8.9ms\n",
            "Speed: 2.7ms preprocess, 8.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v49f72.jpg: 384x640 1 person, 8.6ms\n",
            "Speed: 2.3ms preprocess, 8.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v49f64.jpg: 384x640 1 person, 8.4ms\n",
            "Speed: 2.2ms preprocess, 8.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v49f44.jpg: 384x640 1 person, 15.9ms\n",
            "Speed: 3.7ms preprocess, 15.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v49f53.jpg: 384x640 1 person, 14.1ms\n",
            "Speed: 3.9ms preprocess, 14.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v49f35.jpg: 384x640 3 persons, 9.2ms\n",
            "Speed: 3.1ms preprocess, 9.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v49f65.jpg: 384x640 1 person, 8.5ms\n",
            "Speed: 2.3ms preprocess, 8.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v49f94.jpg: 384x640 2 persons, 13.9ms\n",
            "Speed: 3.4ms preprocess, 13.9ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v49f98.jpg: 384x640 2 persons, 8.7ms\n",
            "Speed: 2.3ms preprocess, 8.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v49f117.jpg: 384x640 2 persons, 8.2ms\n",
            "Speed: 2.2ms preprocess, 8.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v49f115.jpg: 384x640 2 persons, 8.6ms\n",
            "Speed: 2.2ms preprocess, 8.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v49f114.jpg: 384x640 1 person, 15.3ms\n",
            "Speed: 3.6ms preprocess, 15.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v49f124.jpg: 384x640 3 persons, 8.7ms\n",
            "Speed: 2.3ms preprocess, 8.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v49f82.jpg: 384x640 2 persons, 8.2ms\n",
            "Speed: 2.4ms preprocess, 8.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v49f92.jpg: 384x640 2 persons, 8.7ms\n",
            "Speed: 2.3ms preprocess, 8.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v49f102.jpg: 384x640 2 persons, 8.4ms\n",
            "Speed: 2.5ms preprocess, 8.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v49f87.jpg: 384x640 2 persons, 8.6ms\n",
            "Speed: 2.2ms preprocess, 8.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v49f91.jpg: 384x640 2 persons, 10.2ms\n",
            "Speed: 3.6ms preprocess, 10.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v49f123.jpg: 384x640 2 persons, 8.2ms\n",
            "Speed: 2.3ms preprocess, 8.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v49f110.jpg: 384x640 1 person, 8.7ms\n",
            "Speed: 2.2ms preprocess, 8.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v49f119.jpg: 384x640 3 persons, 8.3ms\n",
            "Speed: 2.2ms preprocess, 8.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v49f118.jpg: 384x640 2 persons, 8.4ms\n",
            "Speed: 2.5ms preprocess, 8.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v49f127.jpg: 384x640 2 persons, 9.6ms\n",
            "Speed: 2.5ms preprocess, 9.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v49f104.jpg: 384x640 3 persons, 8.2ms\n",
            "Speed: 2.4ms preprocess, 8.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v49f101.jpg: 384x640 1 person, 10.4ms\n",
            "Speed: 3.5ms preprocess, 10.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v49f144.jpg: 384x640 2 persons, 8.4ms\n",
            "Speed: 2.4ms preprocess, 8.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v24f4.jpg: 384x640 2 persons, 8.3ms\n",
            "Speed: 2.3ms preprocess, 8.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v24f10.jpg: 384x640 2 persons, 8.9ms\n",
            "Speed: 2.3ms preprocess, 8.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v24f7.jpg: 384x640 2 persons, 8.2ms\n",
            "Speed: 2.1ms preprocess, 8.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v49f141.jpg: 384x640 2 persons, 8.3ms\n",
            "Speed: 2.3ms preprocess, 8.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v49f145.jpg: 384x640 2 persons, 8.3ms\n",
            "Speed: 2.4ms preprocess, 8.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v49f130.jpg: 384x640 3 persons, 10.6ms\n",
            "Speed: 3.6ms preprocess, 10.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v24f28.jpg: 384x640 2 persons, 14.1ms\n",
            "Speed: 3.5ms preprocess, 14.1ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v24f13.jpg: 384x640 2 persons, 8.4ms\n",
            "Speed: 2.4ms preprocess, 8.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v49f131.jpg: 384x640 2 persons, 8.6ms\n",
            "Speed: 2.4ms preprocess, 8.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v49f148.jpg: 384x640 2 persons, 7.9ms\n",
            "Speed: 2.4ms preprocess, 7.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v24f19.jpg: 384x640 2 persons, 8.5ms\n",
            "Speed: 2.1ms preprocess, 8.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v24f5.jpg: 384x640 2 persons, 8.6ms\n",
            "Speed: 2.3ms preprocess, 8.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v49f139.jpg: 384x640 3 persons, 9.4ms\n",
            "Speed: 2.4ms preprocess, 9.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v24f9.jpg: 384x640 2 persons, 13.0ms\n",
            "Speed: 3.7ms preprocess, 13.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v49f128.jpg: 384x640 2 persons, 8.8ms\n",
            "Speed: 2.3ms preprocess, 8.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v24f69.jpg: 384x640 2 persons, 9.2ms\n",
            "Speed: 2.3ms preprocess, 9.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v24f67.jpg: 384x640 2 persons, 8.0ms\n",
            "Speed: 2.4ms preprocess, 8.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v24f56.jpg: 384x640 2 persons, 12.9ms\n",
            "Speed: 5.6ms preprocess, 12.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v24f34.jpg: 384x640 2 persons, 8.7ms\n",
            "Speed: 2.4ms preprocess, 8.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v24f72.jpg: 384x640 2 persons, 11.0ms\n",
            "Speed: 3.6ms preprocess, 11.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v24f63.jpg: 384x640 2 persons, 8.7ms\n",
            "Speed: 2.3ms preprocess, 8.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v24f29.jpg: 384x640 2 persons, 8.6ms\n",
            "Speed: 2.3ms preprocess, 8.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v24f51.jpg: 384x640 2 persons, 8.5ms\n",
            "Speed: 2.3ms preprocess, 8.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v24f53.jpg: 384x640 2 persons, 8.4ms\n",
            "Speed: 2.4ms preprocess, 8.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v24f45.jpg: 384x640 2 persons, 8.6ms\n",
            "Speed: 2.2ms preprocess, 8.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v24f68.jpg: 384x640 2 persons, 8.2ms\n",
            "Speed: 2.5ms preprocess, 8.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v24f46.jpg: 384x640 2 persons, 21.0ms\n",
            "Speed: 9.2ms preprocess, 21.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v24f57.jpg: 384x640 2 persons, 9.3ms\n",
            "Speed: 2.4ms preprocess, 9.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v24f43.jpg: 384x640 2 persons, 8.2ms\n",
            "Speed: 2.4ms preprocess, 8.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v24f30.jpg: 384x640 2 persons, 8.1ms\n",
            "Speed: 2.6ms preprocess, 8.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v24f32.jpg: 384x640 2 persons, 8.4ms\n",
            "Speed: 2.4ms preprocess, 8.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v24f71.jpg: 384x640 2 persons, 8.3ms\n",
            "Speed: 2.5ms preprocess, 8.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v24f60.jpg: 384x640 2 persons, 8.0ms\n",
            "Speed: 2.3ms preprocess, 8.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v24f66.jpg: 384x640 2 persons, 15.9ms\n",
            "Speed: 4.3ms preprocess, 15.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v24f92.jpg: 384x640 2 persons, 8.5ms\n",
            "Speed: 2.3ms preprocess, 8.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v24f93.jpg: 384x640 2 persons, 8.3ms\n",
            "Speed: 2.3ms preprocess, 8.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v24f80.jpg: 384x640 2 persons, 8.2ms\n",
            "Speed: 2.2ms preprocess, 8.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v24f115.jpg: 384x640 2 persons, 8.6ms\n",
            "Speed: 2.5ms preprocess, 8.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v24f74.jpg: 384x640 2 persons, 8.3ms\n",
            "Speed: 2.3ms preprocess, 8.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v24f102.jpg: 384x640 2 persons, 8.6ms\n",
            "Speed: 2.2ms preprocess, 8.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v24f110.jpg: 384x640 2 persons, 8.7ms\n",
            "Speed: 2.3ms preprocess, 8.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v24f107.jpg: 384x640 2 persons, 13.2ms\n",
            "Speed: 3.6ms preprocess, 13.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v24f83.jpg: 384x640 2 persons, 8.8ms\n",
            "Speed: 2.2ms preprocess, 8.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v24f87.jpg: 384x640 2 persons, 8.2ms\n",
            "Speed: 2.4ms preprocess, 8.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v24f119.jpg: 384x640 2 persons, 8.4ms\n",
            "Speed: 2.3ms preprocess, 8.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v24f118.jpg: 384x640 2 persons, 8.5ms\n",
            "Speed: 2.5ms preprocess, 8.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v24f97.jpg: 384x640 2 persons, 8.3ms\n",
            "Speed: 2.2ms preprocess, 8.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v24f96.jpg: 384x640 2 persons, 8.7ms\n",
            "Speed: 2.5ms preprocess, 8.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v24f84.jpg: 384x640 2 persons, 12.2ms\n",
            "Speed: 3.6ms preprocess, 12.2ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v24f106.jpg: 384x640 2 persons, 8.3ms\n",
            "Speed: 2.4ms preprocess, 8.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v24f154.jpg: 384x640 3 persons, 8.5ms\n",
            "Speed: 2.4ms preprocess, 8.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v9f0.jpg: 384x640 4 persons, 9.2ms\n",
            "Speed: 2.5ms preprocess, 9.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v9f10.jpg: 384x640 4 persons, 8.3ms\n",
            "Speed: 2.4ms preprocess, 8.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v24f138.jpg: 384x640 3 persons, 8.1ms\n",
            "Speed: 2.2ms preprocess, 8.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v24f133.jpg: 384x640 3 persons, 10.5ms\n",
            "Speed: 3.6ms preprocess, 10.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v24f144.jpg: 384x640 3 persons, 8.8ms\n",
            "Speed: 2.6ms preprocess, 8.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v24f147.jpg: 384x640 3 persons, 8.4ms\n",
            "Speed: 2.3ms preprocess, 8.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v9f3.jpg: 384x640 4 persons, 8.3ms\n",
            "Speed: 2.3ms preprocess, 8.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v24f128.jpg: 384x640 4 persons, 8.3ms\n",
            "Speed: 2.2ms preprocess, 8.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v24f160.jpg: 384x640 3 persons, 9.1ms\n",
            "Speed: 2.7ms preprocess, 9.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v24f163.jpg: 384x640 3 persons, 8.0ms\n",
            "Speed: 2.4ms preprocess, 8.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v24f161.jpg: 384x640 3 persons, 10.5ms\n",
            "Speed: 3.7ms preprocess, 10.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v24f121.jpg: 384x640 2 persons, 8.9ms\n",
            "Speed: 2.3ms preprocess, 8.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v24f145.jpg: 384x640 3 persons, 8.4ms\n",
            "Speed: 2.4ms preprocess, 8.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v24f125.jpg: 384x640 3 persons, 11.2ms\n",
            "Speed: 2.4ms preprocess, 11.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v24f152.jpg: 384x640 3 persons, 8.9ms\n",
            "Speed: 2.9ms preprocess, 8.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v24f157.jpg: 384x640 3 persons, 8.9ms\n",
            "Speed: 2.3ms preprocess, 8.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v24f148.jpg: 384x640 3 persons, 8.5ms\n",
            "Speed: 2.4ms preprocess, 8.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v24f137.jpg: 384x640 3 persons, 12.7ms\n",
            "Speed: 3.7ms preprocess, 12.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v24f129.jpg: 384x640 3 persons, 8.1ms\n",
            "Speed: 2.2ms preprocess, 8.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v9f30.jpg: 384x640 4 persons, 8.2ms\n",
            "Speed: 2.3ms preprocess, 8.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v9f29.jpg: 384x640 4 persons, 8.3ms\n",
            "Speed: 2.2ms preprocess, 8.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v9f43.jpg: 384x640 4 persons, 9.0ms\n",
            "Speed: 2.5ms preprocess, 9.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v9f12.jpg: 384x640 4 persons, 9.2ms\n",
            "Speed: 2.5ms preprocess, 9.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v9f39.jpg: 384x640 5 persons, 10.6ms\n",
            "Speed: 3.7ms preprocess, 10.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v9f44.jpg: 384x640 4 persons, 8.3ms\n",
            "Speed: 2.4ms preprocess, 8.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v9f36.jpg: 384x640 5 persons, 8.2ms\n",
            "Speed: 2.8ms preprocess, 8.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v9f60.jpg: 384x640 5 persons, 8.4ms\n",
            "Speed: 2.6ms preprocess, 8.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v9f56.jpg: 384x640 5 persons, 8.2ms\n",
            "Speed: 2.3ms preprocess, 8.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v9f11.jpg: 384x640 4 persons, 8.9ms\n",
            "Speed: 2.3ms preprocess, 8.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v9f38.jpg: 384x640 5 persons, 14.2ms\n",
            "Speed: 3.6ms preprocess, 14.2ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v9f54.jpg: 384x640 4 persons, 8.3ms\n",
            "Speed: 2.3ms preprocess, 8.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v9f20.jpg: 384x640 4 persons, 9.2ms\n",
            "Speed: 2.3ms preprocess, 9.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v9f105.jpg: 384x640 3 persons, 8.9ms\n",
            "Speed: 2.5ms preprocess, 8.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v9f76.jpg: 384x640 5 persons, 8.5ms\n",
            "Speed: 2.3ms preprocess, 8.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v9f100.jpg: 384x640 4 persons, 9.0ms\n",
            "Speed: 2.7ms preprocess, 9.0ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v9f94.jpg: 384x640 5 persons, 11.1ms\n",
            "Speed: 3.6ms preprocess, 11.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v9f106.jpg: 384x640 3 persons, 8.6ms\n",
            "Speed: 2.3ms preprocess, 8.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v9f90.jpg: 384x640 4 persons, 10.0ms\n",
            "Speed: 2.6ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v9f99.jpg: 384x640 4 persons, 11.0ms\n",
            "Speed: 3.8ms preprocess, 11.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v9f86.jpg: 384x640 3 persons, 17.1ms\n",
            "Speed: 3.5ms preprocess, 17.1ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v9f69.jpg: 384x640 6 persons, 8.7ms\n",
            "Speed: 2.2ms preprocess, 8.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v9f87.jpg: 384x640 4 persons, 10.3ms\n",
            "Speed: 3.7ms preprocess, 10.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v9f82.jpg: 384x640 3 persons, 9.9ms\n",
            "Speed: 2.5ms preprocess, 9.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v9f102.jpg: 384x640 4 persons, 8.2ms\n",
            "Speed: 2.2ms preprocess, 8.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v9f70.jpg: 384x640 4 persons, 8.3ms\n",
            "Speed: 2.2ms preprocess, 8.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v9f75.jpg: 384x640 4 persons, 8.1ms\n",
            "Speed: 2.4ms preprocess, 8.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v9f67.jpg: 384x640 6 persons, 8.2ms\n",
            "Speed: 2.4ms preprocess, 8.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v9f65.jpg: 384x640 5 persons, 8.2ms\n",
            "Speed: 2.4ms preprocess, 8.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v9f92.jpg: 384x640 5 persons, 8.2ms\n",
            "Speed: 2.3ms preprocess, 8.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v60f18.jpg: 384x640 3 persons, 11.3ms\n",
            "Speed: 3.7ms preprocess, 11.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v60f26.jpg: 384x640 4 persons, 8.3ms\n",
            "Speed: 2.3ms preprocess, 8.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v60f20.jpg: 384x640 3 persons, 8.2ms\n",
            "Speed: 2.2ms preprocess, 8.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v60f12.jpg: 384x640 3 persons, 10.6ms\n",
            "Speed: 2.4ms preprocess, 10.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v9f108.jpg: 384x640 3 persons, 8.6ms\n",
            "Speed: 2.4ms preprocess, 8.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v60f29.jpg: 384x640 3 persons, 9.0ms\n",
            "Speed: 2.6ms preprocess, 9.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v9f117.jpg: 384x640 3 persons, 11.3ms\n",
            "Speed: 3.8ms preprocess, 11.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v9f111.jpg: 384x640 3 persons, 8.3ms\n",
            "Speed: 2.5ms preprocess, 8.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v60f0.jpg: 384x640 5 persons, 8.1ms\n",
            "Speed: 2.1ms preprocess, 8.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v60f3.jpg: 384x640 3 persons, 8.2ms\n",
            "Speed: 2.3ms preprocess, 8.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v60f7.jpg: 384x640 3 persons, 8.4ms\n",
            "Speed: 2.3ms preprocess, 8.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v9f113.jpg: 384x640 3 persons, 8.1ms\n",
            "Speed: 2.4ms preprocess, 8.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v60f10.jpg: 384x640 3 persons, 8.4ms\n",
            "Speed: 2.3ms preprocess, 8.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v60f33.jpg: 384x640 4 persons, 16.7ms\n",
            "Speed: 3.3ms preprocess, 16.7ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v60f27.jpg: 384x640 4 persons, 14.5ms\n",
            "Speed: 6.2ms preprocess, 14.5ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v60f21.jpg: 384x640 3 persons, 8.4ms\n",
            "Speed: 2.2ms preprocess, 8.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v60f9.jpg: 384x640 3 persons, 8.3ms\n",
            "Speed: 2.2ms preprocess, 8.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v60f62.jpg: 384x640 3 persons, 13.7ms\n",
            "Speed: 3.5ms preprocess, 13.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v60f75.jpg: 384x640 3 persons, 8.4ms\n",
            "Speed: 2.3ms preprocess, 8.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v60f40.jpg: 384x640 3 persons, 10.6ms\n",
            "Speed: 2.5ms preprocess, 10.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v60f80.jpg: 384x640 3 persons, 11.0ms\n",
            "Speed: 3.8ms preprocess, 11.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v60f39.jpg: 384x640 3 persons, 15.3ms\n",
            "Speed: 3.7ms preprocess, 15.3ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v60f57.jpg: 384x640 3 persons, 9.1ms\n",
            "Speed: 2.4ms preprocess, 9.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v60f60.jpg: 384x640 3 persons, 8.2ms\n",
            "Speed: 2.2ms preprocess, 8.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v60f35.jpg: 384x640 4 persons, 8.3ms\n",
            "Speed: 2.3ms preprocess, 8.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v60f77.jpg: 384x640 3 persons, 9.6ms\n",
            "Speed: 2.5ms preprocess, 9.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v60f78.jpg: 384x640 3 persons, 8.0ms\n",
            "Speed: 2.3ms preprocess, 8.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v60f64.jpg: 384x640 3 persons, 11.0ms\n",
            "Speed: 3.7ms preprocess, 11.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v60f38.jpg: 384x640 3 persons, 7.8ms\n",
            "Speed: 2.3ms preprocess, 7.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v60f52.jpg: 384x640 3 persons, 8.3ms\n",
            "Speed: 2.2ms preprocess, 8.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v60f46.jpg: 384x640 3 persons, 8.4ms\n",
            "Speed: 2.2ms preprocess, 8.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v60f45.jpg: 384x640 3 persons, 8.3ms\n",
            "Speed: 2.4ms preprocess, 8.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v60f47.jpg: 384x640 3 persons, 8.2ms\n",
            "Speed: 2.3ms preprocess, 8.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v60f56.jpg: 384x640 3 persons, 14.9ms\n",
            "Speed: 3.5ms preprocess, 14.9ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v60f74.jpg: 384x640 3 persons, 9.9ms\n",
            "Speed: 2.9ms preprocess, 9.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v60f42.jpg: 384x640 3 persons, 8.7ms\n",
            "Speed: 2.5ms preprocess, 8.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v60f125.jpg: 384x640 3 persons, 8.1ms\n",
            "Speed: 2.4ms preprocess, 8.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v60f107.jpg: 384x640 3 persons, 8.6ms\n",
            "Speed: 2.4ms preprocess, 8.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v60f98.jpg: 384x640 3 persons, 8.5ms\n",
            "Speed: 2.4ms preprocess, 8.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v60f100.jpg: 384x640 3 persons, 14.0ms\n",
            "Speed: 3.8ms preprocess, 14.0ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v60f103.jpg: 384x640 3 persons, 13.6ms\n",
            "Speed: 3.6ms preprocess, 13.6ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v60f119.jpg: 384x640 3 persons, 8.3ms\n",
            "Speed: 2.4ms preprocess, 8.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v60f112.jpg: 384x640 3 persons, 10.5ms\n",
            "Speed: 2.2ms preprocess, 10.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v60f110.jpg: 384x640 3 persons, 8.5ms\n",
            "Speed: 2.3ms preprocess, 8.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v60f89.jpg: 384x640 3 persons, 8.4ms\n",
            "Speed: 2.1ms preprocess, 8.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v60f120.jpg: 384x640 3 persons, 8.3ms\n",
            "Speed: 2.3ms preprocess, 8.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v60f86.jpg: 384x640 3 persons, 12.8ms\n",
            "Speed: 3.5ms preprocess, 12.8ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v60f102.jpg: 384x640 3 persons, 8.4ms\n",
            "Speed: 2.4ms preprocess, 8.4ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v60f105.jpg: 384x640 3 persons, 8.4ms\n",
            "Speed: 2.4ms preprocess, 8.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v60f124.jpg: 384x640 3 persons, 8.2ms\n",
            "Speed: 2.1ms preprocess, 8.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v60f108.jpg: 384x640 3 persons, 8.3ms\n",
            "Speed: 2.4ms preprocess, 8.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v60f106.jpg: 384x640 3 persons, 8.7ms\n",
            "Speed: 2.3ms preprocess, 8.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v60f94.jpg: 384x640 3 persons, 8.5ms\n",
            "Speed: 2.4ms preprocess, 8.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v60f93.jpg: 384x640 3 persons, 11.3ms\n",
            "Speed: 3.5ms preprocess, 11.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v60f83.jpg: 384x640 3 persons, 7.9ms\n",
            "Speed: 2.3ms preprocess, 7.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v60f181.jpg: 384x640 3 persons, 8.4ms\n",
            "Speed: 2.3ms preprocess, 8.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v60f149.jpg: 384x640 3 persons, 8.9ms\n",
            "Speed: 2.3ms preprocess, 8.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v60f126.jpg: 384x640 3 persons, 11.4ms\n",
            "Speed: 2.8ms preprocess, 11.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v60f155.jpg: 384x640 3 persons, 8.6ms\n",
            "Speed: 2.3ms preprocess, 8.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v60f175.jpg: 384x640 3 persons, 8.6ms\n",
            "Speed: 2.5ms preprocess, 8.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v60f162.jpg: 384x640 3 persons, 10.1ms\n",
            "Speed: 3.7ms preprocess, 10.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v60f177.jpg: 384x640 3 persons, 8.4ms\n",
            "Speed: 2.4ms preprocess, 8.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v60f154.jpg: 384x640 3 persons, 8.5ms\n",
            "Speed: 2.1ms preprocess, 8.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v60f176.jpg: 384x640 3 persons, 8.1ms\n",
            "Speed: 2.2ms preprocess, 8.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v60f130.jpg: 384x640 3 persons, 8.2ms\n",
            "Speed: 2.4ms preprocess, 8.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v60f170.jpg: 384x640 3 persons, 8.1ms\n",
            "Speed: 2.3ms preprocess, 8.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v60f171.jpg: 384x640 3 persons, 8.4ms\n",
            "Speed: 2.2ms preprocess, 8.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v60f144.jpg: 384x640 3 persons, 11.0ms\n",
            "Speed: 3.7ms preprocess, 11.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v60f140.jpg: 384x640 3 persons, 8.4ms\n",
            "Speed: 2.4ms preprocess, 8.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v60f173.jpg: 384x640 3 persons, 8.7ms\n",
            "Speed: 2.2ms preprocess, 8.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v60f169.jpg: 384x640 3 persons, 8.1ms\n",
            "Speed: 2.2ms preprocess, 8.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v60f138.jpg: 384x640 3 persons, 8.0ms\n",
            "Speed: 2.3ms preprocess, 8.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v60f196.jpg: 384x640 3 persons, 8.6ms\n",
            "Speed: 2.2ms preprocess, 8.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v32f0.jpg: 384x640 3 persons, 15.6ms\n",
            "Speed: 3.8ms preprocess, 15.6ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v32f25.jpg: 384x640 3 persons, 8.5ms\n",
            "Speed: 2.1ms preprocess, 8.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v32f15.jpg: 384x640 3 persons, 8.1ms\n",
            "Speed: 3.0ms preprocess, 8.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v32f26.jpg: 384x640 3 persons, 8.2ms\n",
            "Speed: 2.3ms preprocess, 8.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v32f11.jpg: 384x640 3 persons, 8.5ms\n",
            "Speed: 2.2ms preprocess, 8.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v32f4.jpg: 384x640 3 persons, 8.3ms\n",
            "Speed: 2.1ms preprocess, 8.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v32f1.jpg: 384x640 3 persons, 8.7ms\n",
            "Speed: 2.5ms preprocess, 8.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v60f191.jpg: 384x640 3 persons, 10.9ms\n",
            "Speed: 3.9ms preprocess, 10.9ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v60f194.jpg: 384x640 3 persons, 8.2ms\n",
            "Speed: 2.3ms preprocess, 8.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v32f2.jpg: 384x640 3 persons, 7.9ms\n",
            "Speed: 2.3ms preprocess, 7.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v32f16.jpg: 384x640 3 persons, 7.9ms\n",
            "Speed: 2.3ms preprocess, 7.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v32f27.jpg: 384x640 3 persons, 7.9ms\n",
            "Speed: 2.2ms preprocess, 7.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v60f193.jpg: 384x640 3 persons, 8.3ms\n",
            "Speed: 2.4ms preprocess, 8.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v60f197.jpg: 384x640 3 persons, 10.7ms\n",
            "Speed: 4.5ms preprocess, 10.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v32f22.jpg: 384x640 3 persons, 9.0ms\n",
            "Speed: 2.2ms preprocess, 9.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v60f189.jpg: 384x640 3 persons, 9.1ms\n",
            "Speed: 2.3ms preprocess, 9.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v32f7.jpg: 384x640 3 persons, 7.9ms\n",
            "Speed: 2.2ms preprocess, 7.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v32f35.jpg: 384x640 3 persons, 8.0ms\n",
            "Speed: 2.2ms preprocess, 8.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v32f32.jpg: 384x640 3 persons, 8.4ms\n",
            "Speed: 2.2ms preprocess, 8.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v32f60.jpg: 384x640 2 persons, 12.0ms\n",
            "Speed: 2.4ms preprocess, 12.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v32f71.jpg: 384x640 2 persons, 10.2ms\n",
            "Speed: 3.7ms preprocess, 10.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v32f54.jpg: 384x640 2 persons, 8.5ms\n",
            "Speed: 2.4ms preprocess, 8.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v32f38.jpg: 384x640 3 persons, 9.7ms\n",
            "Speed: 2.1ms preprocess, 9.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v32f63.jpg: 384x640 2 persons, 8.1ms\n",
            "Speed: 2.4ms preprocess, 8.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v32f61.jpg: 384x640 2 persons, 10.5ms\n",
            "Speed: 3.8ms preprocess, 10.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v32f45.jpg: 384x640 3 persons, 8.1ms\n",
            "Speed: 2.4ms preprocess, 8.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v32f64.jpg: 384x640 2 persons, 8.2ms\n",
            "Speed: 2.3ms preprocess, 8.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v32f40.jpg: 384x640 3 persons, 11.4ms\n",
            "Speed: 3.5ms preprocess, 11.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v32f77.jpg: 384x640 1 person, 13.9ms\n",
            "Speed: 3.5ms preprocess, 13.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v32f81.jpg: 384x640 1 person, 8.3ms\n",
            "Speed: 2.4ms preprocess, 8.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v32f39.jpg: 384x640 3 persons, 8.2ms\n",
            "Speed: 2.3ms preprocess, 8.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v32f62.jpg: 384x640 2 persons, 8.4ms\n",
            "Speed: 2.2ms preprocess, 8.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v32f52.jpg: 384x640 2 persons, 8.6ms\n",
            "Speed: 2.4ms preprocess, 8.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v32f43.jpg: 384x640 3 persons, 14.5ms\n",
            "Speed: 3.6ms preprocess, 14.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v32f67.jpg: 384x640 2 persons, 11.3ms\n",
            "Speed: 3.8ms preprocess, 11.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v32f80.jpg: 384x640 1 person, 14.0ms\n",
            "Speed: 3.6ms preprocess, 14.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v32f82.jpg: 384x640 1 person, 8.4ms\n",
            "Speed: 2.2ms preprocess, 8.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v32f86.jpg: 384x640 1 person, 8.4ms\n",
            "Speed: 2.3ms preprocess, 8.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v32f100.jpg: 384x640 1 person, 8.6ms\n",
            "Speed: 2.5ms preprocess, 8.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v32f121.jpg: 384x640 1 person, 8.7ms\n",
            "Speed: 2.3ms preprocess, 8.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v32f107.jpg: 384x640 1 person, 8.2ms\n",
            "Speed: 3.2ms preprocess, 8.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v32f132.jpg: 384x640 1 person, 14.0ms\n",
            "Speed: 3.7ms preprocess, 14.0ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v32f99.jpg: 384x640 2 persons, 15.3ms\n",
            "Speed: 4.1ms preprocess, 15.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v32f89.jpg: 384x640 1 person, 8.4ms\n",
            "Speed: 2.3ms preprocess, 8.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v32f88.jpg: 384x640 1 person, 8.1ms\n",
            "Speed: 2.4ms preprocess, 8.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v32f102.jpg: 384x640 1 person, 8.2ms\n",
            "Speed: 2.1ms preprocess, 8.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v32f133.jpg: 384x640 1 person, 8.9ms\n",
            "Speed: 2.3ms preprocess, 8.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v32f93.jpg: 384x640 1 person, 8.3ms\n",
            "Speed: 2.3ms preprocess, 8.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v32f96.jpg: 384x640 2 persons, 12.4ms\n",
            "Speed: 3.7ms preprocess, 12.4ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v32f127.jpg: 384x640 1 person, 8.7ms\n",
            "Speed: 2.4ms preprocess, 8.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v32f130.jpg: 384x640 1 person, 9.0ms\n",
            "Speed: 2.4ms preprocess, 9.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v32f129.jpg: 384x640 1 person, 10.3ms\n",
            "Speed: 2.4ms preprocess, 10.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v32f85.jpg: 384x640 1 person, 8.8ms\n",
            "Speed: 2.4ms preprocess, 8.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v32f173.jpg: 384x640 2 persons, 8.6ms\n",
            "Speed: 2.4ms preprocess, 8.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v32f159.jpg: 384x640 1 person, 8.6ms\n",
            "Speed: 2.2ms preprocess, 8.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v32f138.jpg: 384x640 1 person, 17.2ms\n",
            "Speed: 3.6ms preprocess, 17.2ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v32f141.jpg: 384x640 2 persons, 8.7ms\n",
            "Speed: 2.3ms preprocess, 8.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v32f158.jpg: 384x640 1 person, 8.2ms\n",
            "Speed: 2.2ms preprocess, 8.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v32f169.jpg: 384x640 2 persons, 8.0ms\n",
            "Speed: 2.4ms preprocess, 8.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v32f162.jpg: 384x640 2 persons, 8.2ms\n",
            "Speed: 2.4ms preprocess, 8.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v32f177.jpg: 384x640 2 persons, 8.0ms\n",
            "Speed: 2.3ms preprocess, 8.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v32f160.jpg: 384x640 1 person, 10.6ms\n",
            "Speed: 3.7ms preprocess, 10.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/AIRTLab/train/non-violent/v32f135.jpg: 384x640 1 person, 8.6ms\n",
            "Speed: 2.4ms preprocess, 8.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/skeletons_drawn_keyframes/ /content/drive/MyDrive/"
      ],
      "metadata": {
        "id": "DrEuj9noPMbZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}