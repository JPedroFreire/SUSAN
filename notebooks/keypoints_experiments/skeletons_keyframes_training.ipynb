{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ntUjRKzyDXg",
        "outputId": "d340a3cd-1ec2-4d90-c7d2-9600d199d854"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "\n",
        "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
        "from tensorflow.keras.applications import MobileNetV3Small\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from keras.preprocessing import image"
      ],
      "metadata": {
        "id": "T1Crqiv_yQ3m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATASET_TEST_PATH = '/content/drive/MyDrive/skeletons_drawn_keyframes/test/'\n",
        "\n",
        "DATASET_TRAIN_PATH = '/content/drive/MyDrive/skeletons_drawn_keyframes/train/'\n",
        "\n",
        "TARGET_SIZE = (120,160)\n",
        "\n",
        "DESIRED_ACCURACY = 0.995"
      ],
      "metadata": {
        "id": "23PCurMzyaRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def violence_test_dataset():\n",
        "    return  image_dataset_from_directory(DATASET_TEST_PATH,\n",
        "                                         batch_size=32,\n",
        "                                         label_mode='categorical',\n",
        "                                         image_size=TARGET_SIZE)\n",
        "\n",
        "def violence_train_dataset():\n",
        "    return  image_dataset_from_directory(DATASET_TRAIN_PATH,\n",
        "                                         batch_size=32,\n",
        "                                         label_mode='categorical',\n",
        "                                         image_size=TARGET_SIZE)"
      ],
      "metadata": {
        "id": "HObDvPIO17Qz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = [ 'accuracy']\n",
        "\n",
        "def load_mobilenetv2():\n",
        "    pre_trained_model = MobileNetV2(input_shape = (120, 160, 3),\n",
        "                                    include_top = False)\n",
        "\n",
        "\n",
        "    for layer in pre_trained_model.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    last_layer = pre_trained_model.get_layer('out_relu')\n",
        "    last_output = last_layer.output\n",
        "\n",
        "    x = layers.Flatten()(last_output)\n",
        "    x = layers.Dense(1024, activation='relu')(x)\n",
        "    x = layers.Dropout(0.2)(x)\n",
        "    x = layers.Dense(2, activation='softmax')(x)\n",
        "\n",
        "    model = Model(pre_trained_model.input, x)\n",
        "    model.compile(optimizer=RMSprop(learning_rate=0.0001), loss='categorical_crossentropy', metrics=metrics)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "IkG8QbuJ2KNr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class accCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('accuracy')>0.995):\n",
        "      print(\"\\nReached 99.5% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "    elif(epoch == 10 and logs.get('accuracy')<=0.75):\n",
        "      print(\"\\nModel did not surpass 75% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True"
      ],
      "metadata": {
        "id": "kT28D8k_2la0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "violence_model_mobilenet = load_mobilenetv2()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qBgeZvZZ2l3u",
        "outputId": "6df1d796-0e51-4b3f-f831-2631aa3abaeb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3784493116.py:4: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
            "  pre_trained_model = MobileNetV2(input_shape = (120, 160, 3),\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = violence_train_dataset()\n",
        "test_dataset = violence_test_dataset()\n",
        "\n",
        "normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
        "train_dataset_normalized = train_dataset.map(lambda x, y: (normalization_layer(x), y))\n",
        "test_dataset_normalized = test_dataset.map(lambda x, y: (normalization_layer(x), y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVYTTPUNIBKA",
        "outputId": "fa7b170e-22cc-4e3f-b2dd-8181d6144aaf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2926 files belonging to 2 classes.\n",
            "Found 1252 files belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history_mobilenet = violence_model_mobilenet.fit(\n",
        "    violence_train_dataset(),\n",
        "    epochs=40,\n",
        "    batch_size=32,\n",
        "    validation_data=violence_test_dataset(),\n",
        "    callbacks=[accCallback()]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V7y-lrxp2tXK",
        "outputId": "818ef013-dfdf-4021-a831-b72cb2305896"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2926 files belonging to 2 classes.\n",
            "Found 1252 files belonging to 2 classes.\n",
            "Epoch 1/40\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m680s\u001b[0m 7s/step - accuracy: 0.6406 - loss: 3.3624 - val_accuracy: 0.8610 - val_loss: 0.3285\n",
            "Epoch 2/40\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 2s/step - accuracy: 0.8882 - loss: 0.3412 - val_accuracy: 0.9529 - val_loss: 0.1426\n",
            "Epoch 3/40\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 2s/step - accuracy: 0.9271 - loss: 0.2061 - val_accuracy: 0.9489 - val_loss: 0.1641\n",
            "Epoch 4/40\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 2s/step - accuracy: 0.9417 - loss: 0.1579 - val_accuracy: 0.9417 - val_loss: 0.1475\n",
            "Epoch 5/40\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 2s/step - accuracy: 0.9706 - loss: 0.0872 - val_accuracy: 0.9840 - val_loss: 0.0462\n",
            "Epoch 6/40\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 2s/step - accuracy: 0.9859 - loss: 0.0476 - val_accuracy: 0.9872 - val_loss: 0.0352\n",
            "Epoch 7/40\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 2s/step - accuracy: 0.9876 - loss: 0.0535 - val_accuracy: 0.9880 - val_loss: 0.0361\n",
            "Epoch 8/40\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 2s/step - accuracy: 0.9952 - loss: 0.0224 - val_accuracy: 0.9920 - val_loss: 0.0268\n",
            "Epoch 9/40\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 2s/step - accuracy: 0.9701 - loss: 0.1369 - val_accuracy: 0.9872 - val_loss: 0.0292\n",
            "Epoch 10/40\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9975 - loss: 0.0111\n",
            "Reached 99.5% accuracy so cancelling training!\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m214s\u001b[0m 2s/step - accuracy: 0.9975 - loss: 0.0112 - val_accuracy: 0.9912 - val_loss: 0.0248\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "violence_model_mobilenet.save('skeleton_mobilenet.keras')"
      ],
      "metadata": {
        "id": "ifEWiiweZR1c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "teste = tf.keras.models.load_model('skeleton_mobilenet.keras')"
      ],
      "metadata": {
        "id": "Ia0gkHDlZv-q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "history_dict = history_mobilenet.history\n",
        "json.dump(history_dict, open('history_mobilenet.json', 'w'))"
      ],
      "metadata": {
        "id": "MSOv0SbKaJMF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}